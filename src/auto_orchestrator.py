"""
è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå·¥ä½œæµ
æ•´åˆAIçƒ­ç‚¹åˆ†æã€é•¿æ–‡æœ¬ç”Ÿæˆã€å°çº¢ä¹¦ç²¾ç‚¼å’Œå‘å¸ƒçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import yaml
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

# LangGraph imports
from langgraph.graph import StateGraph, END

# æœ¬åœ°imports
from src.state import create_initial_state, update_state, add_agent_to_order, calculate_execution_time
from src.agents.ai_trend_analyzer_real import RealAITrendAnalyzerAgent
from src.agents.longform_generator import LongFormGeneratorAgent
from src.agents.xiaohongshu_refiner import XiaohongshuRefinerAgent
from src.agents.twitter_generator import TwitterGeneratorAgent
from src.agents.title_optimizer import TitleOptimizerAgent
from src.agents.image_advisor import ImageAdvisorAgent
from src.agents.image_generator import ImageGeneratorAgent
from src.agents.quality_evaluator import QualityEvaluatorAgent
from src.agents.publisher import PublisherAgent
from src.agents.trends_digest_agent import TrendsDigestAgent
from src.utils.storage import get_storage

# æ—¥å¿—é…ç½®
from loguru import logger


class AutoContentOrchestrator:
    """è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆåè°ƒå™¨ - æ–°å·¥ä½œæµ"""

    def __init__(self, config_path: str = "config/config.yaml"):
        """
        åˆå§‹åŒ–è‡ªåŠ¨åŒ–åè°ƒå™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.prompts = self._load_prompts()
        self._setup_logging()

        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨
        self.storage = get_storage(self.config.get("storage", {}).get("base_dir", "data"))

        # åˆå§‹åŒ–Agent
        self.agents = self._init_agents()

        # æ„å»ºå·¥ä½œæµ
        self.workflow = self._build_workflow()

        logger.info("è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆåè°ƒå™¨åˆå§‹åŒ–å®Œæˆï¼ˆæ–°å·¥ä½œæµï¼‰")
        logger.info(f"æ•°æ®å­˜å‚¨ç›®å½•: {self.storage.get_date_dir()}")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
            return config
        except FileNotFoundError:
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            sys.exit(1)
        except yaml.YAMLError as e:
            logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

    def _load_prompts(self) -> Dict[str, Any]:
        """åŠ è½½æç¤ºè¯é…ç½®"""
        prompts_file = self.config.get("prompts", {}).get("template_file", "config/prompts.yaml")
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts = yaml.safe_load(f)
            logger.info(f"æç¤ºè¯æ–‡ä»¶åŠ è½½æˆåŠŸ: {prompts_file}")
            return {"prompts": prompts}
        except FileNotFoundError:
            logger.warning(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompts_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {"prompts": {}}
        except yaml.YAMLError as e:
            logger.warning(f"æç¤ºè¯æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {"prompts": {}}

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ï¼ˆæŒ‰æ—¥æœŸåˆ†å±‚å­˜å‚¨ï¼‰"""
        log_config = self.config.get("logging", {})

        # æ—¥å¿—çº§åˆ«
        level = log_config.get("level", "INFO")
        logger.remove()
        logger.add(sys.stderr, level=level)

        # æ–‡ä»¶æ—¥å¿— - ä½¿ç”¨æ—¥æœŸç›®å½•
        if log_config.get("file", {}).get("enabled", True):
            from datetime import datetime
            date_str = datetime.now().strftime("%Y%m%d")
            log_dir = f"logs/{date_str}"
            os.makedirs(log_dir, exist_ok=True)

            log_file = os.path.join(log_dir, "app.log")
            logger.add(
                log_file,
                rotation=log_config.get("file", {}).get("rotation", "100 MB"),
                retention=log_config.get("file", {}).get("retention", "30 days"),
                level=level
            )

    def _init_agents(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€æœ‰Agent"""
        agents = {}
        agents_config = self.config.get("agents", {})

        # AIçƒ­ç‚¹åˆ†æAgentï¼ˆçœŸå®APIç‰ˆæœ¬ï¼‰
        if agents_config.get("ai_trend_analyzer", {}).get("enabled", True):
            agents["ai_trend_analyzer"] = RealAITrendAnalyzerAgent(self.config, self.prompts)

        # çƒ­ç‚¹æ±‡æ€»Agentï¼ˆæ–°å¢ï¼‰
        if agents_config.get("trends_digest", {}).get("enabled", True):
            agents["trends_digest"] = TrendsDigestAgent(self.config, self.prompts)

        # é•¿æ–‡æœ¬ç”ŸæˆAgent
        if agents_config.get("longform_generator", {}).get("enabled", True):
            agents["longform_generator"] = LongFormGeneratorAgent(self.config, self.prompts)

        # å°çº¢ä¹¦ç¬”è®°ç²¾ç‚¼Agent
        if agents_config.get("xiaohongshu_refiner", {}).get("enabled", True):
            agents["xiaohongshu_refiner"] = XiaohongshuRefinerAgent(self.config, self.prompts)

        # Twitterå¸–å­ç”ŸæˆAgentï¼ˆæ–°å¢ï¼‰
        if agents_config.get("twitter_generator", {}).get("enabled", True):
            agents["twitter_generator"] = TwitterGeneratorAgent(self.config, self.prompts)

        # æ ‡é¢˜ä¼˜åŒ–Agent
        if agents_config.get("title_optimizer", {}).get("enabled", True):
            agents["title_optimizer"] = TitleOptimizerAgent(self.config, self.prompts)

        # å›¾åƒå»ºè®®Agent
        if agents_config.get("image_advisor", {}).get("enabled", True):
            agents["image_advisor"] = ImageAdvisorAgent(self.config, self.prompts)

        # å›¾ç‰‡ç”ŸæˆAgent
        if agents_config.get("image_generator", {}).get("enabled", True):
            agents["image_generator"] = ImageGeneratorAgent(self.config, self.prompts)

        # è´¨é‡è¯„ä¼°Agent
        if agents_config.get("quality_evaluator", {}).get("enabled", True):
            agents["quality_evaluator"] = QualityEvaluatorAgent(self.config, self.prompts)

        # å‘å¸ƒAgent
        if agents_config.get("publisher", {}).get("enabled", True):
            agents["publisher"] = PublisherAgent(self.config, self.prompts)

        logger.info(f"å·²åˆå§‹åŒ– {len(agents)} ä¸ªAgent: {list(agents.keys())}")
        return agents

    def _build_workflow(self) -> StateGraph:
        """æ„å»ºè‡ªåŠ¨åŒ–å·¥ä½œæµ"""
        workflow = StateGraph(dict)

        # æ·»åŠ AgentèŠ‚ç‚¹
        for agent_name, agent in self.agents.items():
            workflow.add_node(agent_name, self._create_agent_node(agent))

        # å®šä¹‰æ‰§è¡Œé¡ºåºï¼š
        # AIçƒ­ç‚¹åˆ†æ â†’ çƒ­ç‚¹æ±‡æ€» â†’ é•¿æ–‡æœ¬ç”Ÿæˆ â†’ å°çº¢ä¹¦ç²¾ç‚¼ â†’ Twitter â†’ ...
        # å…¨éƒ¨é¡ºåºæ‰§è¡Œï¼Œé¿å…å¹¶å‘å†²çª
        if "ai_trend_analyzer" in self.agents:
            workflow.set_entry_point("ai_trend_analyzer")

            # çƒ­ç‚¹æ±‡æ€»Agent
            last_node = "ai_trend_analyzer"
            if "trends_digest" in self.agents:
                workflow.add_edge(last_node, "trends_digest")
                last_node = "trends_digest"

            # é•¿æ–‡æœ¬ç”Ÿæˆæµç¨‹
            if "longform_generator" in self.agents:
                workflow.add_edge(last_node, "longform_generator")
                last_node = "longform_generator"

                # é¡ºåºæ‰§è¡Œï¼šé•¿æ–‡æœ¬ -> å°çº¢ä¹¦ -> Twitter -> æ ‡é¢˜ä¼˜åŒ–
                # é¿å…å¹¶å‘æ›´æ–°stateå¯¼è‡´çš„å†²çª
                has_xiaohongshu = "xiaohongshu_refiner" in self.agents
                has_twitter = "twitter_generator" in self.agents

                if has_xiaohongshu:
                    workflow.add_edge(last_node, "xiaohongshu_refiner")
                    last_node = "xiaohongshu_refiner"

                if has_twitter:
                    workflow.add_edge(last_node, "twitter_generator")
                    last_node = "twitter_generator"

                # æ ‡é¢˜ä¼˜åŒ–è·Ÿåœ¨æœ€å
                if "title_optimizer" in self.agents:
                    workflow.add_edge(last_node, "title_optimizer")
                    last_node = "title_optimizer"

                if "image_advisor" in self.agents:
                    workflow.add_edge(last_node, "image_advisor")
                    last_node = "image_advisor"

                if "image_generator" in self.agents:
                    workflow.add_edge(last_node, "image_generator")
                    last_node = "image_generator"

                if "quality_evaluator" in self.agents:
                    workflow.add_edge(last_node, "quality_evaluator")
                    last_node = "quality_evaluator"

                if "publisher" in self.agents:
                    workflow.add_edge(last_node, "publisher")
                    workflow.add_edge("publisher", END)
                else:
                    workflow.add_edge(last_node, END)
            else:
                workflow.add_edge(last_node, END)

        return workflow.compile()

    def _create_agent_node(self, agent):
        """åˆ›å»ºAgentèŠ‚ç‚¹å‡½æ•°"""
        def node_function(state):
            logger.info(f"æ‰§è¡ŒAgent: {agent.name}")
            try:
                result = agent.execute(state)
                return add_agent_to_order(result, agent.name)
            except Exception as e:
                logger.error(f"Agent {agent.name} æ‰§è¡Œå¤±è´¥: {e}")
                return update_state(state, {
                    "error_message": str(e),
                    "current_step": f"{agent.name}_failed"
                })
        return node_function

    def run(self, topic: str = None, target_audience: str = "æŠ€æœ¯ä»ä¸šè€…",
            content_type: str = "å¹²è´§åˆ†äº«", keywords: list = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´è‡ªåŠ¨åŒ–å·¥ä½œæµ

        Args:
            topic: å†…å®¹ä¸»é¢˜æ ‡è¯†ï¼ˆå¯é€‰ï¼Œç”¨äºæ–‡ä»¶å‘½åï¼Œç•™ç©ºåˆ™åŸºäºå®æ—¶çƒ­ç‚¹è‡ªåŠ¨ç”Ÿæˆï¼‰
            target_audience: ç›®æ ‡å—ä¼—
            content_type: å†…å®¹ç±»å‹
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            Dict[str, Any]: æœ€ç»ˆè¾“å‡º
        """
        # å¦‚æœæ²¡æœ‰æä¾›topicï¼Œä½¿ç”¨autoä½œä¸ºæ ‡è¯†ï¼ˆå®é™…å†…å®¹åŸºäºå®æ—¶çƒ­ç‚¹ï¼‰
        if topic is None:
            topic = "auto"
            logger.info("å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§æµç¨‹ï¼ˆåŸºäºå®æ—¶çƒ­ç‚¹ï¼‰")
        else:
            logger.info(f"å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§æµç¨‹: {topic}")

        # åˆ›å»ºåˆå§‹çŠ¶æ€
        state = create_initial_state(
            topic=topic,
            target_audience=target_audience,
            content_type=content_type,
            keywords=keywords,
            config=self.config
        )

        # æ‰§è¡Œå·¥ä½œæµ
        try:
            result = self.workflow.invoke(state)
            result = calculate_execution_time(result)

            # ä¿å­˜è¾“å‡º
            self._save_output(result)

            # æ‰“å°ç»“æœæ‘˜è¦
            self._print_summary(result)

            logger.success(f"è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§å®Œæˆï¼è€—æ—¶: {result.get('execution_time', 0):.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise

    def _save_output(self, state: Dict[str, Any]):
        """ä¿å­˜è¾“å‡ºç»“æœåˆ°æŒ‰æ—¥æœŸåˆ†å±‚çš„ç›®å½•"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ç¡®å®šæ–‡ä»¶æ ‡è¯†ç¬¦
        topic = state.get("topic", "unknown")
        if topic == "auto":
            # å¦‚æœæ˜¯autoæ¨¡å¼ï¼Œä½¿ç”¨å®é™…çš„çƒ­ç‚¹æ ‡é¢˜
            selected_topic = state.get("selected_ai_topic", {})
            topic = selected_topic.get("title", "auto")

        # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œé™åˆ¶é•¿åº¦ï¼‰
        topic = topic.replace(" ", "_").replace("/", "_").replace("\\", "_")[:30]

        # 1. ä¿å­˜å®Œæ•´å·¥ä½œæµè¾“å‡ºï¼ˆJSONæ ¼å¼ï¼‰
        filename = f"workflow_{topic}_{timestamp}.json"
        output_data = {
            "workflow": "auto_v2",
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "topic": state.get("topic"),
                "selected_ai_topic": state.get("selected_ai_topic", {}).get("title"),
                "execution_time": state.get("execution_time"),
                "agent_execution_order": state.get("agent_execution_order", [])
            },
            "content": {
                "ai_hot_topics": state.get("ai_hot_topics"),
                "longform_article": {
                    "title": state.get("longform_article", {}).get("title"),
                    "word_count": state.get("longform_article", {}).get("word_count"),
                    "reading_time": state.get("longform_article", {}).get("reading_time")
                },
                "xiaohongshu_note": {
                    "title": state.get("xiaohongshu_note", {}).get("title"),
                    "word_count": state.get("xiaohongshu_note", {}).get("word_count"),
                    "compression_ratio": state.get("xiaohongshu_note", {}).get("compression_ratio")
                },
                "optimized_titles": state.get("optimized_titles"),
                "recommended_title": state.get("recommended_title"),
                "image_suggestions": state.get("image_suggestions"),
                "generated_images": state.get("generated_images", []),
                "image_prompts": state.get("image_prompts", []),
                "quality_report": state.get("quality_report")
            },
            "publish": {
                "published": state.get("published", False),
                "publish_result": state.get("publish_result")
            },
            "status": "success" if not state.get("error_message") else "failed"
        }

        # ä¸å†ä¿å­˜å®Œæ•´å·¥ä½œæµJSONæ–‡ä»¶ï¼ˆç²¾ç®€è¾“å‡ºï¼‰

        # 2. ä¿å­˜é•¿æ–‡æœ¬æ–‡ç« ï¼ˆåªä¿å­˜Markdownæ ¼å¼ï¼‰
        if state.get("longform_article"):
            article = state["longform_article"]
            md_filename = f"article_{topic}_{timestamp}.md"
            md_content = f"""# {article['title']}

{article.get('full_content', '')}

---
**å…ƒæ•°æ®**:
- å­—æ•°: {article.get('word_count', 0)}
- é˜…è¯»æ—¶é—´: {article.get('reading_time', 'N/A')}
- æ¥æºçƒ­ç‚¹: {article.get('source_topic', 'N/A')}
- æ ‡ç­¾: {', '.join(article.get('tags', []))}
- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            md_file = self.storage.save_markdown("longform", md_filename, md_content)
            logger.info(f"é•¿æ–‡æœ¬Markdownå·²ä¿å­˜: {md_file}")

        # 3. ä¿å­˜å°çº¢ä¹¦ç¬”è®°ï¼ˆåªä¿å­˜Markdownæ ¼å¼ï¼‰
        if state.get("xiaohongshu_note"):
            note = state["xiaohongshu_note"]
            note_md_filename = f"note_{topic}_{timestamp}.md"
            note_md_content = f"""# {note['title']}

{note.get('intro', '')}

{note.get('body', '')}

{note.get('ending', '')}

---
**æ ‡ç­¾**: {' '.join(note.get('hashtags', []))}
**å­—æ•°**: {note.get('word_count', 0)}
**å‹ç¼©ç‡**: {note.get('compression_ratio', 'N/A')}
"""
            note_md_file = self.storage.save_markdown("xiaohongshu", note_md_filename, note_md_content)
            logger.info(f"å°çº¢ä¹¦ç¬”è®°Markdownå·²ä¿å­˜: {note_md_file}")

        # 4. ä¿å­˜Twitterå¸–å­ï¼ˆåªä¿å­˜Markdownæ ¼å¼ï¼‰
        if state.get("twitter_post"):
            twitter_post = state["twitter_post"]
            # ä¿å­˜Markdownæ ¼å¼ï¼ˆç”¨äºé˜…è¯»ï¼‰
            twitter_md_filename = f"twitter_{topic}_{timestamp}.md"
            twitter_md_content = f"""# Twitter Thread

**åŸæ–‡ç« **: {twitter_post.get('original_article_title', 'N/A')}
**æ¨æ–‡æ•°é‡**: {twitter_post.get('tweet_count', 0)}
**æ€»å­—ç¬¦æ•°**: {twitter_post.get('total_characters', 0)}
**é£æ ¼**: {twitter_post.get('style', 'N/A')}

---

{self._format_twitter_thread(twitter_post.get('tweets', []))}

---
**è¯é¢˜æ ‡ç­¾**: {' '.join(twitter_post.get('hashtags', []))}
**æ˜¯å¦Thread**: {'æ˜¯' if twitter_post.get('is_thread') else 'å¦'}
"""
            twitter_md_file = self.storage.save_markdown("twitter", twitter_md_filename, twitter_md_content)
            logger.info(f"Twitterå¸–å­Markdownå·²ä¿å­˜: {twitter_md_file}")

            # ä¿å­˜å›¾ç‰‡æç¤ºè¯åˆ°twitterç›®å½•ï¼ˆTwitteré…å›¾ï¼‰
            if state.get("image_prompts"):
                twitter_prompts_filename = f"prompts_{topic}_{timestamp}.txt"
                prompts_content = "\n\n".join([
                    f"Tweet {i+1} é…å›¾:\n{prompt}"
                    for i, prompt in enumerate(state["image_prompts"][:twitter_post.get('tweet_count', 1)])
                ])
                twitter_prompts_file = self.storage.save_text("twitter", twitter_prompts_filename, prompts_content)
                logger.info(f"Twitteré…å›¾æç¤ºè¯å·²ä¿å­˜: {twitter_prompts_file}")

        # 5. ä¿å­˜å›¾ç‰‡æç¤ºè¯åˆ°å¯¹åº”ç›®å½•ï¼ˆå°çº¢ä¹¦ï¼‰
        if state.get("image_prompts"):
            # æç¤ºè¯é€šå¸¸ä¸å°çº¢ä¹¦ç¬”è®°å…³è”ï¼Œä¿å­˜åˆ°xiaohongshuç›®å½•
            prompts_filename = f"prompts_{topic}_{timestamp}.txt"
            prompts_content = "\n\n".join([
                f"å›¾ç‰‡ {i+1}:\n{prompt}"
                for i, prompt in enumerate(state["image_prompts"])
            ])
            prompts_file = self.storage.save_text("xiaohongshu", prompts_filename, prompts_content)
            logger.info(f"å›¾ç‰‡æç¤ºè¯å·²ä¿å­˜: {prompts_file}")

        # 5. ä¿å­˜çƒ­ç‚¹ç®€æŠ¥ï¼ˆå¦‚æœæœ‰ï¼‰
        if state.get("trends_digest"):
            self._save_digest(state)

        logger.success(f"æ‰€æœ‰å†…å®¹å·²ä¿å­˜åˆ°æ—¥æœŸç›®å½•: {self.storage.get_date_dir()}")

    def _format_twitter_thread(self, tweets: list) -> str:
        """æ ¼å¼åŒ–Twitter threadä¸ºMarkdown"""
        formatted_tweets = []
        for i, tweet in enumerate(tweets, 1):
            formatted_tweets.append(f"### Tweet {i}\n\n{tweet}\n")
        return "\n".join(formatted_tweets)

    def _save_digest(self, state: Dict[str, Any]):
        """ä¿å­˜çƒ­ç‚¹ç®€æŠ¥åˆ°digestç›®å½•"""
        try:
            digest = state.get("trends_digest")
            if not digest:
                return

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"digest_{digest.get('issue_number', timestamp)}"

            # ä¿å­˜Markdownæ ¼å¼ï¼ˆä¸»è¦æ ¼å¼ï¼‰
            md_filename = f"{base_filename}.md"
            md_file = self.storage.save_markdown("digest", md_filename, digest.get('full_content', ''))
            logger.info(f"çƒ­ç‚¹ç®€æŠ¥Markdownå·²ä¿å­˜: {md_file}")

            # ä¿å­˜JSONæ ¼å¼ï¼ˆç”¨äºç½‘ç«™APIï¼‰
            json_filename = f"{base_filename}.json"
            digest_data = {
                "metadata": {
                    "title": digest.get("title"),
                    "subtitle": digest.get("subtitle"),
                    "issue_number": digest.get("issue_number"),
                    "publish_date": digest.get("publish_date"),
                    "generated_at": datetime.now().isoformat(),
                    "word_count": digest.get("word_count"),
                    "reading_time": digest.get("reading_time"),
                    "total_topics": digest.get("total_topics"),
                    "style": digest.get("style")
                },
                "topics": digest.get("topics", []),
                "summary_analysis": digest.get("summary_analysis"),
                "sources": digest.get("sources")
            }
            json_file = self.storage.save_json("digest", json_filename, digest_data)
            logger.success(f"çƒ­ç‚¹ç®€æŠ¥å·²ä¿å­˜: {md_file} (MD) + {json_file} (JSON)")

        except Exception as e:
            logger.error(f"ä¿å­˜çƒ­ç‚¹ç®€æŠ¥å¤±è´¥: {e}")

    def _print_summary(self, state: Dict[str, Any]):
        """æ‰“å°ç»“æœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“ è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå®Œæˆï¼ˆæ–°å·¥ä½œæµï¼‰")
        print("="*60)

        print(f"ä¸»é¢˜é¢†åŸŸ: {state.get('topic', 'N/A')}")
        print(f"AIçƒ­ç‚¹è¯é¢˜: {state.get('selected_ai_topic', {}).get('title', 'N/A')}")
        print(f"æŠ€æœ¯æ–‡ç« å­—æ•°: {state.get('longform_article', {}).get('word_count', 'N/A')}")
        print(f"å°çº¢ä¹¦ç¬”è®°å­—æ•°: {state.get('xiaohongshu_note', {}).get('word_count', 'N/A')}")
        print(f"å†…å®¹å‹ç¼©ç‡: {state.get('xiaohongshu_note', {}).get('compression_ratio', 'N/A')}")

        # Twitterå¸–å­ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        if state.get('twitter_post'):
            twitter = state['twitter_post']
            print(f"\nğŸ¦ Twitterå¸–å­: {twitter.get('tweet_count', 0)} æ¡æ¨æ–‡")
            print(f"   æ€»å­—ç¬¦æ•°: {twitter.get('total_characters', 0)}")
            print(f"   å¹³å‡å­—ç¬¦: {twitter.get('average_characters', 0)} / æ¡")
            print(f"   é£æ ¼: {twitter.get('style', 'N/A')}")
            print(f"   å½¢å¼: {'Thread' if twitter.get('is_thread') else 'å•æ¡æ¨æ–‡'}")

        # çƒ­ç‚¹ç®€æŠ¥ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        if state.get('trends_digest'):
            digest = state['trends_digest']
            print(f"\nğŸ“° çƒ­ç‚¹ç®€æŠ¥: {digest.get('title', 'N/A')}")
            print(f"   æœŸå·: #{digest.get('issue_number', 'N/A')}")
            print(f"   çƒ­ç‚¹æ•°é‡: {digest.get('total_topics', 0)} ä¸ª")
            print(f"   å­—æ•°: {digest.get('word_count', 0)} å­—")
            print(f"   é˜…è¯»æ—¶é—´: {digest.get('reading_time', 'N/A')}")

        # å›¾ç‰‡ç”Ÿæˆä¿¡æ¯
        generated_images = state.get('generated_images', [])
        if generated_images:
            print(f"ç”Ÿæˆå›¾ç‰‡: {len(generated_images)} å¼ ")
            for i, img in enumerate(generated_images, 1):
                if img.get('local_path'):
                    print(f"  å›¾ç‰‡{i}: {img['local_path']}")
                elif img.get('url'):
                    print(f"  å›¾ç‰‡{i}: {img['url']}")
                else:
                    print(f"  å›¾ç‰‡{i}: æç¤ºè¯å·²ä¿å­˜")
        elif state.get('image_prompts'):
            print(f"å›¾ç‰‡æç¤ºè¯: {len(state.get('image_prompts', []))} ä¸ªï¼ˆå·²ä¿å­˜ï¼‰")

        print(f"è´¨é‡è¯„åˆ†: {state.get('quality_report', {}).get('overall_score', 'N/A')}/10")
        print(f"æ˜¯å¦å‘å¸ƒ: {'æ˜¯' if state.get('published') else 'å¦ï¼ˆå·²ä¿å­˜ä¸ºè‰ç¨¿ï¼‰'}")
        print(f"æ‰§è¡Œè€—æ—¶: {state.get('execution_time', 0):.2f}ç§’")

        if state.get('recommended_title'):
            print(f"\næ¨èæ ‡é¢˜: {state['recommended_title']}")

        print("="*60 + "\n")
