"""
è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå·¥ä½œæµ
æ•´åˆAIçƒ­ç‚¹åˆ†æã€é•¿æ–‡æœ¬ç”Ÿæˆã€å°çº¢ä¹¦ç²¾ç‚¼å’Œå‘å¸ƒçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import yaml
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List

# LangGraph imports
from langgraph.graph import StateGraph, END

# æœ¬åœ°imports
from src.state import create_initial_state, update_state, add_agent_to_order, calculate_execution_time
from src.agents.ai_trend_analyzer_real import RealAITrendAnalyzerAgent
from src.agents.trends_digest_agent import TrendsDigestAgent
from src.utils.storage_v2 import StorageFactory

# æ—¥å¿—é…ç½®
from loguru import logger


class AutoContentOrchestrator:
    """è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆåè°ƒå™¨ - æ–°å·¥ä½œæµ"""

    def __init__(self, config_path: str = "config/config.yaml"):
        """
        åˆå§‹åŒ–è‡ªåŠ¨åŒ–åè°ƒå™¨ï¼ˆAutoæ¨¡å¼ï¼šæ¯æ—¥çƒ­ç‚¹ç®€æŠ¥ï¼‰

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.prompts = self._load_prompts()
        self._setup_logging()

        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆAutoæ¨¡å¼ï¼šæ¯æ—¥çƒ­ç‚¹ï¼‰
        self.storage = StorageFactory.create_daily(
            base_dir=self.config.get("storage", {}).get("base_dir", "data")
        )

        # åˆå§‹åŒ–Agent
        self.agents = self._init_agents()

        # æ„å»ºå·¥ä½œæµ
        self.workflow = self._build_workflow()

        logger.info("è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆåè°ƒå™¨åˆå§‹åŒ–å®Œæˆï¼ˆAutoæ¨¡å¼ï¼šæ¯æ—¥çƒ­ç‚¹ç®€æŠ¥ï¼‰")
        logger.info(f"æ•°æ®å­˜å‚¨ç›®å½•: {self.storage.get_root_dir()}")

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
            return config
        except FileNotFoundError:
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            sys.exit(1)
        except yaml.YAMLError as e:
            logger.error(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

    def _load_prompts(self) -> Dict[str, Any]:
        """åŠ è½½æç¤ºè¯é…ç½®"""
        prompts_file = self.config.get("prompts", {}).get("template_file", "config/prompts.yaml")
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts = yaml.safe_load(f)
            logger.info(f"æç¤ºè¯æ–‡ä»¶åŠ è½½æˆåŠŸ: {prompts_file}")
            return {"prompts": prompts}
        except FileNotFoundError:
            logger.warning(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompts_file}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {"prompts": {}}
        except yaml.YAMLError as e:
            logger.warning(f"æç¤ºè¯æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return {"prompts": {}}

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ï¼ˆæŒ‰æ—¥æœŸåˆ†å±‚å­˜å‚¨ï¼‰"""
        log_config = self.config.get("logging", {})

        # æ—¥å¿—çº§åˆ«
        level = log_config.get("level", "INFO")
        logger.remove()
        logger.add(sys.stderr, level=level)

        # æ–‡ä»¶æ—¥å¿— - ä½¿ç”¨æ—¥æœŸç›®å½•
        if log_config.get("file", {}).get("enabled", True):
            from datetime import datetime
            date_str = datetime.now().strftime("%Y%m%d")
            log_dir = f"logs/{date_str}"
            os.makedirs(log_dir, exist_ok=True)

            log_file = os.path.join(log_dir, "app.log")
            logger.add(
                log_file,
                rotation=log_config.get("file", {}).get("rotation", "100 MB"),
                retention=log_config.get("file", {}).get("retention", "30 days"),
                level=level
            )

    def _init_agents(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–æ‰€æœ‰Agentï¼ˆAutoæ¨¡å¼ï¼šåªç”Ÿæˆç®€æŠ¥ï¼‰"""
        agents = {}
        agents_config = self.config.get("agents", {})

        # Autoæ¨¡å¼åªåˆå§‹åŒ–ç®€æŠ¥ç›¸å…³çš„Agent
        # AIçƒ­ç‚¹åˆ†æAgentï¼ˆçœŸå®APIç‰ˆæœ¬ï¼‰
        if agents_config.get("ai_trend_analyzer", {}).get("enabled", True):
            agents["ai_trend_analyzer"] = RealAITrendAnalyzerAgent(self.config, self.prompts)

        # çƒ­ç‚¹æ±‡æ€»Agent
        if agents_config.get("trends_digest", {}).get("enabled", True):
            agents["trends_digest"] = TrendsDigestAgent(self.config, self.prompts)

        # æ³¨æ„ï¼šAutoæ¨¡å¼ä¸‹ä¸åˆå§‹åŒ–é•¿æ–‡æœ¬ã€å°çº¢ä¹¦ã€Twitterç­‰Agent
        # å¦‚éœ€ç”Ÿæˆå®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ Customã€Refine æˆ– Series æ¨¡å¼

        logger.info(f"Autoæ¨¡å¼å·²åˆå§‹åŒ– {len(agents)} ä¸ªAgent: {list(agents.keys())}")
        return agents

    def _build_workflow(self) -> StateGraph:
        """æ„å»ºè‡ªåŠ¨åŒ–å·¥ä½œæµï¼ˆAutoæ¨¡å¼ï¼šç®€æŠ¥ç”Ÿæˆï¼‰"""
        workflow = StateGraph(dict)

        # æ·»åŠ AgentèŠ‚ç‚¹
        for agent_name, agent in self.agents.items():
            workflow.add_node(agent_name, self._create_agent_node(agent))

        # å®šä¹‰æ‰§è¡Œé¡ºåºï¼šAIçƒ­ç‚¹åˆ†æ â†’ çƒ­ç‚¹æ±‡æ€» â†’ END
        if "ai_trend_analyzer" in self.agents:
            workflow.set_entry_point("ai_trend_analyzer")

            # çƒ­ç‚¹æ±‡æ€»Agent
            last_node = "ai_trend_analyzer"
            if "trends_digest" in self.agents:
                workflow.add_edge(last_node, "trends_digest")
                last_node = "trends_digest"

            workflow.add_edge(last_node, END)

        return workflow.compile()

    def _create_agent_node(self, agent):
        """åˆ›å»ºAgentèŠ‚ç‚¹å‡½æ•°"""
        def node_function(state):
            logger.info(f"æ‰§è¡ŒAgent: {agent.name}")
            try:
                result = agent.execute(state)
                return add_agent_to_order(result, agent.name)
            except Exception as e:
                logger.error(f"Agent {agent.name} æ‰§è¡Œå¤±è´¥: {e}")
                return update_state(state, {
                    "error_message": str(e),
                    "current_step": f"{agent.name}_failed"
                })
        return node_function

    def run(self, topic: str = None, target_audience: str = "æŠ€æœ¯ä»ä¸šè€…",
            content_type: str = "å¹²è´§åˆ†äº«", keywords: list = None,
            user_provided_topic: dict = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´è‡ªåŠ¨åŒ–å·¥ä½œæµ

        Args:
            topic: å†…å®¹ä¸»é¢˜æ ‡è¯†ï¼ˆå¯é€‰ï¼Œç”¨äºæ–‡ä»¶å‘½åï¼Œç•™ç©ºåˆ™åŸºäºå®æ—¶çƒ­ç‚¹è‡ªåŠ¨ç”Ÿæˆï¼‰
            target_audience: ç›®æ ‡å—ä¼—
            content_type: å†…å®¹ç±»å‹
            keywords: å…³é”®è¯åˆ—è¡¨
            user_provided_topic: ç”¨æˆ·æŒ‡å®šçš„å®Œæ•´è¯é¢˜æ•°æ®ï¼ˆåŒ…å«title, description, keywordsç­‰ï¼‰ï¼Œ
                               å¦‚æœæä¾›åˆ™è·³è¿‡AIçƒ­ç‚¹åˆ†æï¼Œç›´æ¥ä½¿ç”¨è¯¥è¯é¢˜

        Returns:
            Dict[str, Any]: æœ€ç»ˆè¾“å‡º
        """
        # åˆ¤æ–­æ˜¯å¦ä¸ºç”¨æˆ·æŒ‡å®šè¯é¢˜æ¨¡å¼
        is_user_topic_mode = user_provided_topic is not None

        if is_user_topic_mode:
            # ç”¨æˆ·æŒ‡å®šè¯é¢˜æ¨¡å¼
            topic = topic or user_provided_topic.get("title", "user_topic")
            logger.info(f"ğŸ¯ ç”¨æˆ·æŒ‡å®šè¯é¢˜æ¨¡å¼: {topic}")
        elif topic is None:
            topic = "auto"
            logger.info("ğŸ“¡ å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§æµç¨‹ï¼ˆåŸºäºå®æ—¶çƒ­ç‚¹ï¼‰")
        else:
            logger.info(f"å¼€å§‹æ‰§è¡Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§æµç¨‹: {topic}")

        # åˆ›å»ºåˆå§‹çŠ¶æ€
        state = create_initial_state(
            topic=topic,
            target_audience=target_audience,
            content_type=content_type,
            keywords=keywords,
            config=self.config
        )

        # å¦‚æœæ˜¯ç”¨æˆ·æŒ‡å®šè¯é¢˜æ¨¡å¼ï¼Œè®¾ç½®é€‰ä¸­çš„è¯é¢˜ï¼Œè·³è¿‡AIçƒ­ç‚¹åˆ†æ
        if is_user_topic_mode:
            state["selected_ai_topic"] = {
                "title": user_provided_topic.get("title", topic),
                "description": user_provided_topic.get("description", ""),
                "source": "user_provided",
                "url": "",
                "tags": user_provided_topic.get("keywords", []),
                "key_points": [user_provided_topic.get("description", "")]
            }
            state["ai_hot_topics"] = [state["selected_ai_topic"]]
            state["current_step"] = "user_topic_set"
            logger.info(f"âœ… å·²è®¾ç½®ç”¨æˆ·æŒ‡å®šè¯é¢˜ï¼Œè·³è¿‡AIçƒ­ç‚¹åˆ†æ")

        # æ‰§è¡Œå·¥ä½œæµ
        try:
            result = self.workflow.invoke(state)
            result = calculate_execution_time(result)

            # ä¿å­˜è¾“å‡º
            self._save_output(result)

            # æ‰“å°ç»“æœæ‘˜è¦
            self._print_summary(result)

            logger.success(f"è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿäº§å®Œæˆï¼è€—æ—¶: {result.get('execution_time', 0):.2f}ç§’")
            return result

        except Exception as e:
            logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise

    def _save_output(self, state: Dict[str, Any]):
        """ä¿å­˜è¾“å‡ºç»“æœåˆ°æŒ‰æ—¥æœŸåˆ†å±‚çš„ç›®å½•ï¼ˆAutoæ¨¡å¼ï¼šåªä¿å­˜åŸå§‹æ•°æ®å’Œç®€æŠ¥ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 1. ä¿å­˜AIçƒ­ç‚¹åŸå§‹æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰
        if state.get("ai_hot_topics"):
            topics = state["ai_hot_topics"]
            raw_filename = f"raw_topics_{timestamp}.json"
            raw_data = {
                "fetched_at": datetime.now().isoformat(),
                "total_topics": len(topics),
                "topics": topics
            }
            raw_file = self.storage.save_json("raw", raw_filename, raw_data)
            logger.info(f"AIçƒ­ç‚¹åŸå§‹æ•°æ®å·²ä¿å­˜: {raw_file}")

        # 2. ä¿å­˜çƒ­ç‚¹ç®€æŠ¥
        if state.get("trends_digest"):
            self._save_digest(state)

        logger.success(f"Autoæ¨¡å¼å†…å®¹å·²ä¿å­˜åˆ°: {self.storage.get_date_dir()}")

    def _format_twitter_thread(self, tweets: list) -> str:
        """æ ¼å¼åŒ–Twitter threadä¸ºMarkdown"""
        formatted_tweets = []
        for i, tweet in enumerate(tweets, 1):
            formatted_tweets.append(f"### Tweet {i}\n\n{tweet}\n")
        return "\n".join(formatted_tweets)

    def _save_digest(self, state: Dict[str, Any]):
        """ä¿å­˜çƒ­ç‚¹ç®€æŠ¥åˆ°digestç›®å½•"""
        try:
            digest = state.get("trends_digest")
            if not digest:
                return

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"digest_{digest.get('issue_number', timestamp)}"

            # ä¿å­˜Markdownæ ¼å¼ï¼ˆä¸»è¦æ ¼å¼ï¼‰
            md_filename = f"{base_filename}.md"
            md_file = self.storage.save_markdown("digest", md_filename, digest.get('full_content', ''))
            logger.info(f"çƒ­ç‚¹ç®€æŠ¥Markdownå·²ä¿å­˜: {md_file}")

            # ä¿å­˜JSONæ ¼å¼ï¼ˆç”¨äºç½‘ç«™APIï¼‰
            json_filename = f"{base_filename}.json"
            digest_data = {
                "metadata": {
                    "title": digest.get("title"),
                    "subtitle": digest.get("subtitle"),
                    "issue_number": digest.get("issue_number"),
                    "publish_date": digest.get("publish_date"),
                    "generated_at": datetime.now().isoformat(),
                    "word_count": digest.get("word_count"),
                    "reading_time": digest.get("reading_time"),
                    "total_topics": digest.get("total_topics"),
                    "style": digest.get("style")
                },
                "topics": digest.get("topics", []),
                "summary_analysis": digest.get("summary_analysis"),
                "sources": digest.get("sources")
            }
            json_file = self.storage.save_json("digest", json_filename, digest_data)
            logger.success(f"çƒ­ç‚¹ç®€æŠ¥å·²ä¿å­˜: {md_file} (MD) + {json_file} (JSON)")

        except Exception as e:
            logger.error(f"ä¿å­˜çƒ­ç‚¹ç®€æŠ¥å¤±è´¥: {e}")

    def _print_summary(self, state: Dict[str, Any]):
        """æ‰“å°ç»“æœæ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“ Autoæ¨¡å¼ - çƒ­ç‚¹ç®€æŠ¥ç”Ÿæˆå®Œæˆ")
        print("="*60)

        # çƒ­ç‚¹ç®€æŠ¥ä¿¡æ¯
        if state.get('trends_digest'):
            digest = state['trends_digest']
            print(f"\nğŸ“° çƒ­ç‚¹ç®€æŠ¥: {digest.get('title', 'N/A')}")
            print(f"   æœŸå·: #{digest.get('issue_number', 'N/A')}")
            print(f"   çƒ­ç‚¹æ•°é‡: {digest.get('total_topics', 0)} ä¸ª")
            print(f"   å­—æ•°: {digest.get('word_count', 0)} å­—")
            print(f"   é˜…è¯»æ—¶é—´: {digest.get('reading_time', 'N/A')}")

        # AIçƒ­ç‚¹ä¿¡æ¯
        hot_topics = state.get('ai_hot_topics', [])
        if hot_topics:
            print(f"\nğŸ”¥ è·å–åˆ° {len(hot_topics)} ä¸ªAIçƒ­ç‚¹")

        print(f"\nâ±ï¸  æ‰§è¡Œè€—æ—¶: {state.get('execution_time', 0):.2f}ç§’")
        print(f"ğŸ“ å­˜å‚¨ä½ç½®: {self.storage.get_date_dir()}")
        print("\nğŸ’¡ æç¤ºï¼šå¦‚éœ€ç”Ÿæˆå®Œæ•´å†…å®¹ï¼Œè¯·ä½¿ç”¨ Customã€Refine æˆ– Series æ¨¡å¼")
        print("="*60 + "\n")
