"""
AIçƒ­ç‚¹æ±‡æ€»Agent v3.0 - ä¸–ç•Œçº§ç§‘æŠ€ç®€æŠ¥ç”Ÿæˆ
ä½¿ç”¨categorized_trendsç”ŸæˆåŒ…å«æ‰€æœ‰æ•°æ®æºå®Œæ•´å†…å®¹çš„ç®€æŠ¥
"""

from typing import Dict, Any, List
import yaml
from pathlib import Path
from datetime import datetime
from src.agents.base import BaseAgent


class NewsDigestAgent(BaseAgent):
    """AIçƒ­ç‚¹æ±‡æ€»Agent v3.0 - æŒ‰åˆ†ç±»ç»„ç»‡çš„ä¸–ç•Œçº§æŠ€æœ¯ç®€æŠ¥"""

    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)

        digest_config = config.get("agents", {}).get("trends_digest", {})
        self.digest_style = digest_config.get("style", "magazine")
        self.include_analysis = digest_config.get("include_analysis", True)
        self.llm.temperature = 0.7

        # åŠ è½½ç®€æŠ¥ Prompt æ¨¡æ¿
        self.digest_prompts = self._load_digest_prompts()

        # 5å¤§åˆ†ç±»é¡ºåº
        self.CATEGORY_ORDER = [
            "ğŸ“ˆ è¡Œä¸šåŠ¨æ€",
            "ğŸ“ å­¦æœ¯çªç ´",
            "ğŸ”¬ æŠ€æœ¯åˆ›æ–°",
            "ğŸ› ï¸ AIå·¥å…·/äº§å“",
            "ğŸ’¼ AIåº”ç”¨"
        ]

        self.log("v3.0ç®€æŠ¥æ ‡å‡†å·²åŠ è½½ - æŒ‰åˆ†ç±»ç»„ç»‡ï¼ŒåŒ…å«æ‰€æœ‰æ•°æ®æºå†…å®¹")

    def _load_digest_prompts(self) -> Dict[str, Any]:
        """åŠ è½½ç®€æŠ¥ Prompt é…ç½®"""
        try:
            if self.prompts and "trends_digest" in self.prompts:
                return self.prompts["trends_digest"]

            config_path = Path(__file__).parent.parent.parent / "config" / "prompts.yaml"
            with open(config_path, 'r', encoding='utf-8') as f:
                prompts = yaml.safe_load(f)
                return prompts.get("trends_digest", {})
        except Exception as e:
            self.log(f"åŠ è½½ trends_digest é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿", "WARNING")
            return self._get_default_prompts()

    def _get_default_prompts(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤ Prompt æ¨¡æ¿"""
        return {
            "category_descriptions": {
                "ğŸ“ˆ è¡Œä¸šåŠ¨æ€": "èšç„¦AIäº§ä¸šæŠ•èµ„ã€å¹¶è´­ã€æˆ˜ç•¥åˆä½œç­‰å•†ä¸šåŠ¨æ€",
                "ğŸ“ å­¦æœ¯çªç ´": "ç²¾é€‰é¡¶çº§æœŸåˆŠè®ºæ–‡ä¸å‰æ²¿ç ”ç©¶æˆæœ",
                "ğŸ”¬ æŠ€æœ¯åˆ›æ–°": "è¿½è¸ªæ¨¡å‹æ¶æ„ã€ç®—æ³•çªç ´ä¸å·¥ç¨‹åˆ›æ–°",
                "ğŸ› ï¸ AIå·¥å…·/äº§å“": "å‘ç°æå‡å¼€å‘æ•ˆç‡çš„å®ç”¨å·¥å…·ä¸äº§å“",
                "ğŸ’¼ AIåº”ç”¨": "å±•ç¤ºAIåœ¨å„è¡Œä¸šçš„åˆ›æ–°åº”ç”¨æ¡ˆä¾‹"
            }
        }

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆçƒ­ç‚¹æ±‡æ€»ç®€æŠ¥"""
        self.log("å¼€å§‹ç”Ÿæˆä¸–ç•Œçº§AIçƒ­ç‚¹ç®€æŠ¥ï¼ˆv3.0 - åˆ†ç±»ç»„ç»‡ç‰ˆï¼‰")

        try:
            categorized_trends = state.get("categorized_trends")
            if not categorized_trends:
                # å¦‚æœæ²¡æœ‰categorized_trendsï¼Œä½¿ç”¨æ—§é€»è¾‘
                self.log("æœªæ‰¾åˆ° categorized_trendsï¼Œä½¿ç”¨æ—§ç‰ˆé€»è¾‘")
                return self._execute_legacy(state)

            total_count = state.get("total_trends_count", 0)
            self.log(f"æ±‡æ€» {total_count} ä¸ªçƒ­ç‚¹è¯é¢˜ï¼ŒæŒ‰5å¤§åˆ†ç±»ç»„ç»‡")

            digest = self._generate_digest_v3(state, categorized_trends, total_count)

            self.log(f"æˆåŠŸç”Ÿæˆä¸–ç•Œçº§çƒ­ç‚¹ç®€æŠ¥ï¼ŒåŒ…å« {total_count} ä¸ªè¯é¢˜")

            return {
                **state,
                "trends_digest": digest,
                "current_step": "trends_digest_completed"
            }
        except Exception as e:
            self.log(f"çƒ­ç‚¹ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {str(e)}", "ERROR")
            return {
                **state,
                "error_message": f"çƒ­ç‚¹ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {str(e)}",
                "current_step": "trends_digest_failed"
            }

    def _execute_legacy(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """å…¼å®¹æ—§ç‰ˆé€»è¾‘"""
        # å¯¼å…¥æ—§ç‰ˆAgent
        from src.agents.trends_digest_agent import TrendsDigestAgent
        legacy_agent = TrendsDigestAgent(self.config, self.prompts)
        return legacy_agent.execute(state)

    def _generate_digest_v3(
        self,
        state: Dict[str, Any],
        categorized_trends: Dict[str, Dict],
        total_count: int
    ) -> Dict[str, Any]:
        """ç”Ÿæˆv3.0æ ¼å¼ç®€æŠ¥"""
        # 1. ç”Ÿæˆå…ƒæ•°æ®
        digest_metadata = self._generate_metadata_v3(total_count)

        # 2. ç”Ÿæˆæ¯ä¸ªåˆ†ç±»çš„å¯¼è¯­
        category_intros = self._generate_category_intros_v3(categorized_trends)

        # 3. ç”Ÿæˆè¶‹åŠ¿åˆ†æ
        trend_analysis = None
        if self.include_analysis:
            trend_analysis = self._generate_trend_analysis_v3(categorized_trends)

        # 4. æå–å…³é”®æ´å¯Ÿ
        key_insights = self._extract_key_insights_v3(categorized_trends)

        # 5. ç»„è£…å®Œæ•´ç®€æŠ¥
        full_content = self._assemble_digest_v3(
            digest_metadata,
            categorized_trends,
            category_intros,
            trend_analysis,
            key_insights
        )

        word_count = len(full_content)

        return {
            "title": digest_metadata["title"],
            "subtitle": digest_metadata["subtitle"],
            "issue_number": digest_metadata["issue_number"],
            "publish_date": digest_metadata["publish_date"],
            "full_content": full_content,
            "category_intros": category_intros,
            "trend_analysis": trend_analysis,
            "key_insights": key_insights,
            "word_count": word_count,
            "reading_time": f"{word_count // 500}-{word_count // 300}åˆ†é’Ÿ",
            "total_topics": total_count,
            "category_stats": digest_metadata["category_stats"],
            "style": self.digest_style,
            "version": "v3.0"
        }

    def _generate_metadata_v3(self, total_count: int) -> Dict[str, Any]:
        """ç”Ÿæˆç®€æŠ¥å…ƒæ•°æ®"""
        today = datetime.now()
        issue_number = today.strftime("%Y%m%d")

        return {
            "title": f"AIæ¯æ—¥çƒ­ç‚¹ Â· {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            "subtitle": f"æ±‡èš8ä¸ªæ•°æ®æºï¼Œå…±è·å–{total_count}æ¡AIèµ„è®¯",
            "issue_number": issue_number,
            "publish_date": today.strftime("%Y-%m-%d"),
            "category_stats": {}
        }

    def _generate_category_intros_v3(self, categorized_trends: Dict[str, Dict]) -> Dict[str, str]:
        """ä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆå¯¼è¯­"""
        intros = {}
        for category in self.CATEGORY_ORDER:
            if category not in categorized_trends:
                continue

            category_data = categorized_trends[category]
            items = category_data.get("items", [])
            count = category_data.get("count", 0)

            if count == 0:
                continue

            intros[category] = self._generate_category_intro_v3(category, items)

        return intros

    def _generate_category_intro_v3(self, category: str, items: List[Dict]) -> str:
        """ä¸ºå•ä¸ªåˆ†ç±»ç”Ÿæˆå¯¼è¯­"""
        try:
            # è·å–å‰5ä¸ªæ ‡é¢˜
            titles = [item.get("title", "") for item in items[:5]]
            titles_text = "\n".join([f"- {title}" for title in titles])

            category_desc = self.digest_prompts.get("category_descriptions", {}).get(category, "")

            template = """ä½ æ˜¯ä¸–ç•Œçº§ç§‘æŠ€åª’ä½“ç¼–è¾‘ã€‚è¯·ä¸º"{category}"åˆ†ç±»æ’°å†™ç®€çŸ­å¯¼è¯­ï¼ˆ30-50å­—ï¼‰

åˆ†ç±»æè¿°ï¼š{category_description}

æœ¬åˆ†ç±»éƒ¨åˆ†çƒ­ç‚¹ï¼š
{topics_list}

å¯¼è¯­ï¼š"""

            prompt = template.format(
                category=category,
                category_description=category_desc,
                topics_list=titles_text
            )

            response = self._call_llm(prompt)
            return response.strip()
        except Exception as e:
            self.log(f"åˆ†ç±»å¯¼è¯­ç”Ÿæˆå¤±è´¥: {e}", "WARNING")
            return category_desc or f"{category}ç²¾é€‰"

    def _generate_trend_analysis_v3(self, categorized_trends: Dict[str, Dict]) -> str:
        """ç”Ÿæˆæ·±åº¦è¶‹åŠ¿åˆ†æ"""
        try:
            # æå–æ‰€æœ‰çƒ­ç‚¹æ ‡é¢˜ï¼ˆæ¯ä¸ªåˆ†ç±»å–å‰5ä¸ªï¼‰
            all_titles = []
            for category in self.CATEGORY_ORDER:
                if category in categorized_trends:
                    items = categorized_trends[category].get("items", [])[:5]
                    all_titles.extend([item.get("title", "") for item in items])

            top_titles = all_titles[:15]

            # ç»Ÿè®¡æ•°æ®æº
            all_sources = []
            for category_data in categorized_trends.values():
                items = category_data.get("items", [])
                all_sources.extend([item.get("source", "") for item in items])

            from collections import Counter
            source_counts = Counter(all_sources)

            # ç»Ÿè®¡åˆ†ç±»
            category_counts = {
                cat: data.get("count", 0)
                for cat, data in categorized_trends.items()
                if data.get("count", 0) > 0
            }

            template = """ä½ æ˜¯ä¸–ç•Œçº§ç§‘æŠ€åª’ä½“èµ„æ·±åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹AIæŠ€æœ¯çƒ­ç‚¹ï¼Œæ’°å†™æ·±åº¦è¶‹åŠ¿åˆ†æï¼ˆ250-350å­—ï¼‰ã€‚

æœ¬æœŸçƒ­ç‚¹åˆ†ç±»ï¼š
{category_distribution}

æ•°æ®æ¥æºï¼š
{sources}

éƒ¨åˆ†çƒ­ç‚¹æ ‡é¢˜ï¼š
{top_titles}

åˆ†æè¦æ±‚ï¼š
1. æ·±åº¦æ´å¯Ÿï¼šé€è¿‡ç°è±¡çœ‹æœ¬è´¨
2. é€»è¾‘æ¸…æ™°ï¼šç°è±¡-åŸå› -å½±å“-å±•æœ›
3. æ•°æ®æ”¯æ’‘ï¼šå¼•ç”¨å…·ä½“åˆ†ç±»å’Œæ¥æº
4. å‰ç»è§‚ç‚¹ï¼šæä¾›è¡Œä¸šå±•æœ›

åˆ†ææ–‡ç« ï¼š"""

            prompt = template.format(
                category_distribution=', '.join([f'{cat}: {count}æ¡' for cat, count in category_counts.items()]),
                sources=', '.join([f'{src}: {cnt}æ¡' for src, cnt in source_counts.most_common(5)]),
                top_titles='\n'.join([f'{i+1}. {title}' for i, title in enumerate(top_titles[:10])])
            )

            response = self._call_llm(prompt)
            return response.strip()
        except Exception as e:
            self.log(f"è¶‹åŠ¿åˆ†æç”Ÿæˆå¤±è´¥: {e}", "WARNING")
            return None

    def _extract_key_insights_v3(self, categorized_trends: Dict[str, Dict]) -> List[str]:
        """æå–å…³é”®æ´å¯Ÿ"""
        try:
            # æå–æ‰€æœ‰é«˜çƒ­åº¦çƒ­ç‚¹
            all_items = []
            for category_data in categorized_trends.values():
                items = category_data.get("items", [])
                all_items.extend(items)

            # æŒ‰çƒ­åº¦æ’åº
            all_items.sort(key=lambda x: x.get("heat_score", 0), reverse=True)
            top_items = all_items[:10]

            titles = [item.get("title", "") for item in top_items]
            titles_text = "\n".join([f"{i+1}. {title}" for i, title in enumerate(titles)])

            template = """ä½ æ˜¯ä¸–ç•Œçº§ç§‘æŠ€åª’ä½“ç¼–è¾‘ã€‚è¯·ä»ä»¥ä¸‹AIçƒ­ç‚¹ä¸­æå–3-5ä¸ªå…³é”®æ´å¯Ÿï¼ˆæ¯æ¡20-30å­—ï¼‰ã€‚

çƒ­ç‚¹åˆ—è¡¨ï¼š
{topics_list}

æ´å¯Ÿè¦æ±‚ï¼š
1. æ´å¯Ÿæ·±åˆ»ï¼Œæ­ç¤ºè¡Œä¸šæœ¬è´¨
2. è§‚ç‚¹é²œæ˜ï¼Œé¿å…æ³›æ³›è€Œè°ˆ
3. è¯­è¨€ç²¾ç‚¼ï¼Œæ¯æ¡20-30å­—
4. ä½¿ç”¨"æ­ç¤ºäº†"ã€"æ ‡å¿—ç€"ç­‰åŠ¨è¯

å…³é”®æ´å¯Ÿï¼ˆæ¯æ¡ä¸€è¡Œï¼‰ï¼š"""

            prompt = template.format(topics_list=titles_text)

            response = self._call_llm(prompt)
            insights = [line.strip() for line in response.strip().split('\n') if line.strip()]

            return insights[:5]
        except Exception as e:
            self.log(f"å…³é”®æ´å¯Ÿæå–å¤±è´¥: {e}", "WARNING")
            return []

    def _assemble_digest_v3(
        self,
        metadata: Dict[str, Any],
        categorized_trends: Dict[str, Dict],
        category_intros: Dict[str, str],
        trend_analysis: str = None,
        key_insights: List[str] = None
    ) -> str:
        """ç»„è£…v3.0ç®€æŠ¥"""
        content_parts = []

        # ========== å¤´éƒ¨ ==========
        content_parts.append(f"# {metadata['title']}\n\n")
        content_parts.append("> ğŸ“¡ æ±‡èš8ä¸ªæ•°æ®æºçš„AIæŠ€æœ¯èµ„è®¯ï¼Œæ¯å¤©ä¸ºä½ ç²¾é€‰è¡Œä¸šå‰æ²¿\n\n")
        content_parts.append(f"**{metadata['subtitle']}**\n\n")
        content_parts.append(f"ğŸ“… {metadata['publish_date']}  Â·  ğŸ†” Issue #{metadata['issue_number']}\n\n")
        content_parts.append("---\n\n")

        # ========== å…³é”®æ´å¯Ÿ ==========
        if key_insights:
            content_parts.append("## ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ\n\n")
            for insight in key_insights:
                content_parts.append(f"- {insight}\n")
            content_parts.append("\n---\n\n")

        # ========== è¶‹åŠ¿åˆ†æ ==========
        if trend_analysis:
            content_parts.append("## ğŸ“° æ·±åº¦è§‚å¯Ÿ\n\n")
            content_parts.append(f"{trend_analysis}\n")
            content_parts.append("\n---\n\n")

        # ========== åˆ†ç±»çƒ­ç‚¹ ==========
        content_parts.append("## ğŸ” æœ¬æœŸçƒ­ç‚¹\n\n")

        # æŒ‰åˆ†ç±»é¡ºåºç»„ç»‡
        for category in self.CATEGORY_ORDER:
            if category not in categorized_trends:
                continue

            category_data = categorized_trends[category]
            items = category_data.get("items", [])
            count = category_data.get("count", 0)

            if count == 0:
                continue

            content_parts.append(f"### {category} ({count}æ¡)\n\n")

            # åˆ†ç±»å¯¼è¯­
            if category in category_intros:
                content_parts.append(f"*{category_intros[category]}*\n\n")

            # è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰çƒ­ç‚¹
            for item in items:
                title = item.get("title", "")
                description = item.get("description", "")
                url = item.get("url", "")
                source = item.get("source", "")
                heat_score = item.get("heat_score", 0)

                # çƒ­ç‚¹è¯¦æƒ…
                content_parts.append(f"#### [{title}]({url})\n\n")

                # æ¥æºå’Œçƒ­åº¦
                content_parts.append(f"**æ¥æº**: {source}  Â·  **çƒ­åº¦**: {heat_score}\n\n")

                # æè¿°ï¼ˆå¦‚æœæœ‰ï¼‰
                if description and len(description) > 20:
                    content_parts.append(f"{description}\n\n")

                content_parts.append("---\n\n")

        # ========== é¡µè„š ==========
        content_parts.append("\n## ğŸ“Š æ•°æ®æ¥æºç»Ÿè®¡\n\n")

        # ç»Ÿè®¡æ¯ä¸ªæ•°æ®æºçš„æ•°é‡
        source_stats = {}
        for category_data in categorized_trends.values():
            items = category_data.get("items", [])
            for item in items:
                source = item.get("source", "æœªçŸ¥")
                source_stats[source] = source_stats.get(source, 0) + 1

        for source, count in sorted(source_stats.items(), key=lambda x: x[1], reverse=True):
            content_parts.append(f"- **{source}**: {count} æ¡\n")

        content_parts.append("\n---\n\n")
        content_parts.append("<div align='center'>\n\n")
        content_parts.append("**AI Daily** Â· ç”± ContentForge AI è‡ªåŠ¨ç”Ÿæˆ\n\n")
        content_parts.append(f"{metadata['publish_date']}\n\n")
        content_parts.append("</div>\n")

        return "".join(content_parts)
