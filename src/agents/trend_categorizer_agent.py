"""
çƒ­ç‚¹åˆ†ç±»Agent v9.2 - å°†æŒ‰æ•°æ®æºç»„ç»‡çš„çƒ­ç‚¹æŒ‰6å¤§åˆ†ç±»é‡æ–°ç»„ç»‡

v9.0 æ›´æ–°:
- 5åˆ†ç±» â†’ 6åˆ†ç±»é‡æž„
- æ–°å¢ž: ðŸ¦¾ AI Agent åˆ†ç±»
- å®žçŽ°Top5æˆªå–é€»è¾‘ï¼ˆå®ç¼ºæ¯‹æ»¥ç­–ç•¥ï¼‰
- 24å°æ—¶ä¸¥æ ¼è¿‡æ»¤
- 30ä¸ªæ•°æ®æºåˆ†ç±»æ˜ å°„

v9.1 æ›´æ–°:
- ä¸¥æ ¼24å°æ—¶æ—¶é—´è¿‡æ»¤ï¼ˆæ—¶é—´è§£æžå¤±è´¥æˆ–è¶…è¿‡24hç›´æŽ¥æŽ’é™¤ï¼‰
- å¢žå¼ºæ—¶é—´æ ¼å¼æ”¯æŒï¼ˆRSS/Atom/HTTP Dateç­‰ï¼‰

v9.2 æ›´æ–°:
- åŽ»é™¤24å°æ—¶æ—¶é—´é™åˆ¶
- ä¼˜å…ˆæœ€æ–°æ•°æ®ï¼ˆæŒ‰æ—¶é—´æˆ³æŽ’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
- ç¡®ä¿æ¯ä¸ªåˆ†ç±»Top5å¡«æ»¡ï¼ˆ6Ã—5=30æ¡ï¼‰
- åªè¿‡æ»¤æŽ‰æ²¡æœ‰æ—¶é—´æˆ³çš„å†…å®¹
"""

from typing import Dict, Any, List
from src.agents.base import BaseAgent
from src.utils.time_filter import TimeFilter


class TrendCategorizerAgent(BaseAgent):
    """çƒ­ç‚¹åˆ†ç±»Agent v9.2 - æŒ‰6å¤§åˆ†ç±»ç»„ç»‡çƒ­ç‚¹ï¼Œä¼˜å…ˆæœ€æ–°æ•°æ®ï¼ŒTop5æˆªå–"""

    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)
        # èŽ·å–é…ç½®
        agent_config = config.get("agents", {}).get("trend_categorizer", {})
        self.max_per_category = agent_config.get("max_per_category", 5)  # Top5æˆªå–

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œçƒ­ç‚¹åˆ†ç±» (v9.2: 6åˆ†ç±» + ä¼˜å…ˆæœ€æ–° + Top5æˆªå–)

        Args:
            state: åŒ…å« trends_by_source çš„çŠ¶æ€

        Returns:
            Dict[str, Any]: æ›´æ–°åŽçš„çŠ¶æ€ï¼ŒåŒ…å« categorized_trends
        """
        self.log("å¼€å§‹æŒ‰6å¤§åˆ†ç±»ç»„ç»‡çƒ­ç‚¹ (v9.2: ä¼˜å…ˆæœ€æ–°ï¼Œç¡®ä¿30æ¡æ»¡)...")

        try:
            trends_by_source = state.get("trends_by_source", {})
            if not trends_by_source:
                self.log("æœªæ‰¾åˆ° trends_by_sourceï¼Œè·³è¿‡åˆ†ç±»")
                return state

            # ========== v9.0: 6å¤§åˆ†ç±»å®šä¹‰ ==========
            categories = {
                "ðŸ“š å­¦æœ¯å‰æ²¿": {
                    "icon": "ðŸ“š",
                    "keywords": [
                        "paper", "research", "study", "arxiv", "publication", "publish",
                        "university", "institute", "lab", "professor", "scientist", "researcher",
                        "conference", "journal", "peer-reviewed", "dataset", "breakthrough",
                        "novel", "state-of-the-art", "sota", "semantic scholar", "openalex",
                        "papers with code", "openreview", "dblp", "citation", "theorem",
                        "algorithm", "machine learning", "deep learning", "neural network"
                    ],
                    "items": []
                },
                "ðŸ› ï¸ å¼€å‘å·¥å…·": {
                    "icon": "ðŸ› ï¸",
                    "keywords": [
                        "library", "framework", "package", "sdk", "api", "tool",
                        "hugging face", "model", "dataset", "pypi", "npm", "github release",
                        "python", "javascript", "typescript", "langchain", "pytorch",
                        "tensorflow", "keras", "scikit-learn", "pandas", "numpy"
                    ],
                    "items": []
                },
                "ðŸ¦¾ AI Agent": {
                    "icon": "ðŸ¦¾",
                    "keywords": [
                        "agent", "autonomous", "multi-agent", "autogpt", "babyagi", "agentgpt",
                        "copilot", "assistant", "chatbot", "langchain agent", "ai agent",
                        "autonomous agent", "workflow", "task", "planning", "reasoning",
                        "tool use", "function calling", "openai function", "claude agent"
                    ],
                    "items": []
                },
                "ðŸ’¼ ä¼ä¸šåº”ç”¨": {
                    "icon": "ðŸ’¼",
                    "keywords": [
                        "enterprise", "b2b", "business", "solution", "deployment",
                        "implementation", "integration", "workflow", "automation",
                        "industry", "sector", "startup", "funding", "investment",
                        "acquisition", "merger", "partnership", "collaboration"
                    ],
                    "items": []
                },
                "ðŸŒ æ¶ˆè´¹äº§å“": {
                    "icon": "ðŸŒ",
                    "keywords": [
                        "product", "app", "service", "launch", "release", "update",
                        "consumer", "user", "mobile", "web", "desktop", "extension",
                        "plugin", "saas", "platform", "tool", "application",
                        "product hunt", "show hn", "startup", "app store", "google play"
                    ],
                    "items": []
                },
                "ðŸ“° è¡Œä¸šèµ„è®¯": {
                    "icon": "ðŸ“°",
                    "keywords": [
                        "news", "report", "analysis", "trend", "forecast", "prediction",
                        "industry", "market", "regulation", "policy", "law", "ethics",
                        "safety", "alignment", "interpretability", "governance",
                        "mit technology review", "stanford hai", "accenture"
                    ],
                    "items": []
                }
            }

            # ========== v9.0: æ•°æ®æºåˆ°åˆ†ç±»çš„æ˜ å°„ï¼ˆ30ä¸ªæ•°æ®æºï¼‰ ==========
            source_category_map = {
                # å­¦æœ¯å‰æ²¿
                "arXiv": "ðŸ“š å­¦æœ¯å‰æ²¿",
                "Semantic Scholar": "ðŸ“š å­¦æœ¯å‰æ²¿",
                "OpenAlex": "ðŸ“š å­¦æœ¯å‰æ²¿",
                "Papers with Code": "ðŸ“š å­¦æœ¯å‰æ²¿",
                "OpenReview": "ðŸ“š å­¦æœ¯å‰æ²¿",
                "DBLP": "ðŸ“š å­¦æœ¯å‰æ²¿",

                # å¼€å‘å·¥å…·
                "Hugging Face": "ðŸ› ï¸ å¼€å‘å·¥å…·",
                "PyPI": "ðŸ› ï¸ å¼€å‘å·¥å…·",
                "npm": "ðŸ› ï¸ å¼€å‘å·¥å…·",
                "GitHub Releases": "ðŸ› ï¸ å¼€å‘å·¥å…·",
                "PyTorch": "ðŸ› ï¸ å¼€å‘å·¥å…·",
                "TensorFlow": "ðŸ› ï¸ å¼€å‘å·¥å…·",

                # AI Agent
                "GitHub Trending": "ðŸ¦¾ AI Agent",
                "Product Hunt": "ðŸ¦¾ AI Agent",
                "Reddit": "ðŸ¦¾ AI Agent",
                "Hacker News": "ðŸ¦¾ AI Agent",

                # ä¼ä¸šåº”ç”¨
                "TechCrunch AI": "ðŸ’¼ ä¼ä¸šåº”ç”¨",
                "VentureBeat AI": "ðŸ’¼ ä¼ä¸šåº”ç”¨",
                "AI Business": "ðŸ’¼ ä¼ä¸šåº”ç”¨",
                "InfoQ AI": "ðŸ’¼ ä¼ä¸šåº”ç”¨",

                # æ¶ˆè´¹äº§å“
                "Product Hunt": "ðŸŒ æ¶ˆè´¹äº§å“",
                "Hacker News": "ðŸŒ æ¶ˆè´¹äº§å“",
                "a16z": "ðŸŒ æ¶ˆè´¹äº§å“",
                "App Store": "ðŸŒ æ¶ˆè´¹äº§å“",
                "Google Play": "ðŸŒ æ¶ˆè´¹äº§å“",

                # è¡Œä¸šèµ„è®¯
                "NewsAPI": "ðŸ“° è¡Œä¸šèµ„è®¯",
                "MIT Tech Review": "ðŸ“° è¡Œä¸šèµ„è®¯",
                "The Gradient": "ðŸ“° è¡Œä¸šèµ„è®¯",
                "MarkTechPost": "ðŸ“° è¡Œä¸šèµ„è®¯",
                "Stanford HAI": "ðŸ“° è¡Œä¸šèµ„è®¯",
                "Accenture": "ðŸ“° è¡Œä¸šèµ„è®¯",
            }

            total_items = 0

            # éåŽ†æ‰€æœ‰æ•°æ®æº
            for source_name, trends in trends_by_source.items():
                if not trends:
                    continue

                # èŽ·å–è¯¥æ•°æ®æºçš„é»˜è®¤åˆ†ç±»
                default_category = source_category_map.get(source_name)

                for trend in trends:
                    # æ ¼å¼åŒ–çƒ­ç‚¹æ¡ç›®
                    formatted_item = self._format_trend_item(trend, source_name)

                    # ç¡®å®šåˆ†ç±»
                    category = self._determine_category(
                        formatted_item,
                        default_category,
                        categories
                    )

                    # æ·»åŠ åˆ°å¯¹åº”åˆ†ç±»
                    categories[category]["items"].append(formatted_item)
                    total_items += 1

            # ========== v9.2: ä¼˜å…ˆæœ€æ–°æ•°æ® + Top5æˆªå– + ç¡®ä¿30æ¡æ»¡ ==========
            categorized_trends = {}
            total_after_top5 = 0
            total_no_timestamp = 0

            for cat_name, cat_data in categories.items():
                items = cat_data["items"]

                # ========== ç¬¬ä¸€æ­¥: åªè¿‡æ»¤æŽ‰æ²¡æœ‰æ—¶é—´æˆ³çš„å†…å®¹ ==========
                valid_items = []
                no_ts_count = 0

                for item in items:
                    timestamp = item.get("timestamp", "")
                    if not timestamp:
                        # v9.2: æ²¡æœ‰æ—¶é—´æˆ³çš„ç›´æŽ¥è¿‡æ»¤æŽ‰ï¼ˆæ— æ³•æŽ’åºï¼‰
                        no_ts_count += 1
                        continue
                    # v9.2: æ‰€æœ‰çš„æœ‰æ—¶é—´çš„éƒ½ä¿ç•™ï¼Œä¸é™åˆ¶24å°æ—¶
                    valid_items.append(item)

                if no_ts_count > 0:
                    self.log(f"  {cat_name}: è¿‡æ»¤æŽ‰{no_ts_count}æ¡æ— æ—¶é—´æˆ³å†…å®¹")

                # ========== ç¬¬äºŒæ­¥: æŒ‰æ—¶é—´æˆ³æŽ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰+ çƒ­åº¦ä½œä¸ºæ¬¡è¦æŽ’åº ==========
                sorted_items = sorted(
                    valid_items,
                    key=lambda x: (x.get("timestamp", ""), x.get("heat_score", 0)),
                    reverse=True
                )

                # ========== ç¬¬ä¸‰æ­¥: æˆªå–Top5ï¼ˆç¡®ä¿æœ‰æ•°æ®ï¼‰ ==========
                top_items = sorted_items[:self.max_per_category]

                categorized_trends[cat_name] = {
                    "icon": cat_data["icon"],
                    "items": top_items,
                    "count": len(top_items)
                }
                total_after_top5 += len(top_items)
                total_no_timestamp += no_ts_count

            self.log(f"åˆ†ç±»å®Œæˆ(ä¼˜å…ˆæœ€æ–°): åŽŸå§‹{total_items}æ¡ -> æ— æ—¶é—´æˆ³{total_no_timestamp}æ¡ -> ä¿ç•™{total_after_top5}æ¡")

            # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„æ•°é‡
            for cat_name, cat_data in categorized_trends.items():
                if cat_data["count"] > 0:
                    self.log(f"  {cat_name}: {cat_data['count']}æ¡")

            return {
                **state,
                "categorized_trends": categorized_trends,
                "total_trends_count": total_after_top5,
                "current_step": "trend_categorized"
            }

        except Exception as e:
            self.log(f"åˆ†ç±»å¤±è´¥: {e}", "ERROR")
            return {
                **state,
                "error_message": f"åˆ†ç±»å¤±è´¥: {e}",
                "current_step": "trend_categorizer_failed"
            }

    def _format_trend_item(self, trend: Dict[str, Any], source_name: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–çƒ­ç‚¹æ¡ç›®ï¼Œæ·»åŠ æ¥æºé“¾æŽ¥ç­‰ä¿¡æ¯"""
        title = trend.get("title", "")
        description = trend.get("description", "")
        url = trend.get("url", "")
        source = trend.get("source", source_name)
        heat_score = trend.get("heat_score", 0)
        tags = trend.get("tags", [])
        timestamp = trend.get("timestamp", "")

        # æå–æ•°æ®æºåç§°ï¼ˆåŽ»æŽ‰æ‹¬å·å†…å®¹ï¼‰
        if "NewsAPI" in source:
            # æ ¼å¼: "NewsAPI (TechCrunch)" -> "NewsAPI"
            clean_source = "NewsAPI"
        elif "GitHub" in source:
            clean_source = "GitHub"
        else:
            clean_source = source

        return {
            "title": title,
            "description": description,
            "url": url,
            "source": clean_source,
            "full_source": source,  # ä¿ç•™å®Œæ•´æ¥æºä¿¡æ¯
            "heat_score": heat_score,
            "tags": tags,
            "timestamp": timestamp
        }

    def _determine_category(
        self,
        item: Dict[str, Any],
        default_category: str,
        categories: Dict[str, Dict]
    ) -> str:
        """
        ç¡®å®šçƒ­ç‚¹æ¡ç›®çš„åˆ†ç±» (v9.0: 6åˆ†ç±»ç³»ç»Ÿ)

        ä¼˜å…ˆçº§:
        1. åŸºäºŽæ•°æ®æºçš„é»˜è®¤åˆ†ç±»
        2. åŸºäºŽå…³é”®è¯åŒ¹é…
        3. å…œåº•åˆ†ç±» (è¡Œä¸šèµ„è®¯)
        """
        title = item.get("title", "").lower()
        description = item.get("description", "").lower()
        text = f"{title} {description}"

        # å¦‚æžœæœ‰é»˜è®¤åˆ†ç±»ä¸”è¯¥åˆ†ç±»ä¸æ˜¯Noneï¼Œä¼˜å…ˆä½¿ç”¨
        if default_category and default_category in categories:
            return default_category

        # åŸºäºŽå…³é”®è¯è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„åŒ¹é…åº¦
        category_scores = {}
        for cat_name, cat_data in categories.items():
            keywords = cat_data["keywords"]
            score = sum(1 for kw in keywords if kw.lower() in text)
            category_scores[cat_name] = score

        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        if category_scores:
            best_category = max(category_scores, key=category_scores.get)
            if category_scores[best_category] > 0:
                return best_category

        # v9.0: å…œåº•åˆ†ç±» - è¡Œä¸šèµ„è®¯ï¼ˆæœ€é€šç”¨ï¼‰
        return "ðŸ“° è¡Œä¸šèµ„è®¯"
