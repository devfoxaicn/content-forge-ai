"""
æ–°é—»é‡è¦æ€§è¯„åˆ†Agent v9.0 - å¯¹åˆ†ç±»åçš„æ–°é—»è¿›è¡Œé‡è¦æ€§è¯„åˆ†å’Œç­›é€‰

è¯„åˆ†ç»´åº¦:
- source_authority: æ¥æºæƒå¨åº¦ (30%) - v9.0æ›´æ–°: 30ä¸ªæ•°æ®æºè¯„åˆ†
- engagement: äº’åŠ¨æ•°æ® (20%)
- freshness: æ—¶æ•ˆæ€§ (15%) - v9.0æ›´æ–°: ä¸¥æ ¼24å°æ—¶è¿‡æ»¤
- category_balance: åˆ†ç±»å¹³è¡¡ (15%) - v9.0æ›´æ–°: 6åˆ†ç±»å¹³è¡¡
- content_quality: å†…å®¹è´¨é‡ (10%)
- diversity: å¤šæ ·æ€§ (10%)

v9.0 æ›´æ–°:
- 6åˆ†ç±»ç³»ç»Ÿæƒå¨åº¦è¯„åˆ†
- 30ä¸ªæ•°æ®æºå®Œæ•´è¦†ç›–
- ä¸¥æ ¼24å°æ—¶æ—¶æ•ˆæ€§è¿‡æ»¤
- å®ç¼ºæ¯‹æ»¥ç­–ç•¥
"""

from typing import Dict, Any, List
from datetime import datetime, timedelta
from collections import defaultdict
from src.agents.base import BaseAgent
import re


# v8.0: AIå…³é”®è¯åˆ—è¡¨ - ç”¨äºè¯†åˆ«é«˜ä»·å€¼å†…å®¹
AI_KEYWORDS_HIGH_VALUE = [
    # æ ¸å¿ƒæŠ€æœ¯
    "GPT", "LLM", "Transformer", "Agent", "RAG", "Fine-tuning", "LoRA",
    "Multi-agent", "Chain of Thought", "Reasoning", "Embedding",
    # å‰æ²¿æŠ€æœ¯
    "Diffusion", "Stable Diffusion", "Midjourney", "DALL-E", "Sora",
    "Whisper", "CLIP", "GLM", "Qwen", "Llama", "Mistral",
    # åº”ç”¨é¢†åŸŸ
    "Code generation", "Copilot", "GitHub Copilot", "ChatGPT",
    "OpenAI", "Anthropic", "Claude", "Gemini", "Hugging Face",
    # æŠ€æœ¯æ¦‚å¿µ
    "Prompt engineering", "In-context learning", "Zero-shot", "Few-shot",
    "Temperature", "Token", "Context window", "Inference",
]

# æ–°å…´æŠ€æœ¯è¶‹åŠ¿ - 2024-2025
EMERGING_TECH_TRENDS = [
    "AI Agent", "Autonomous agent", "Multi-agent system",
    "Video generation", "Text-to-video", "Sora",
    "Real-time voice", "GPT-4o", "GPT-4o mini",
    "Local LLM", "On-device AI", "Edge AI",
    "Open source model", "Llama 3", "Gemma", "Mixtral",
    "AI safety", "Alignment", "Interpretability",
    "Multimodal", "Vision-language", "VLM",
]

# æ•°æ®æºæƒå¨åº¦è¯„åˆ† (0-100) - v9.0 æ›´æ–°: 30ä¸ªæ•°æ®æºæƒå¨åº¦è¯„åˆ†
# è¯„åˆ†æ ‡å‡†:
# - 95-100: é¡¶çº§å®˜æ–¹/å­¦æœ¯æœºæ„ (OpenAI, Google AI, MITç­‰)
# - 85-94: æƒå¨å­¦æœ¯/ç ”ç©¶æœºæ„ (Microsoft Research, BAIR, Stanford HAIç­‰)
# - 75-84: çŸ¥åå­¦æœ¯é¢„å°æœ¬/æ•°æ®åº“ (arXiv, Semantic Scholar, OpenAlexç­‰)
# - 65-74: é¡¶çº§ç§‘æŠ€åª’ä½“/ç¤¾åŒº (Hacker News, MIT Tech Reviewç­‰)
# - 55-64: è¡Œä¸šåª’ä½“/èµ„è®¯ (TechCrunch, VentureBeat, NewsAPIç­‰)
# - 45-54: ä¸“ä¸šåª’ä½“/åšå®¢ (MarkTechPost, KDnuggets, The Gradientç­‰)
# - 35-44: äº§å“å¹³å°/ç¤¾åŒº (Product Hunt, GitHub, Redditç­‰)
# - 25-34: ç”¨æˆ·ç”Ÿæˆå†…å®¹/æ¦œå•

SOURCE_AUTHORITY_SCORES = {
    # ========== ğŸ“š å­¦æœ¯å‰æ²¿ (6ä¸ª) ==========
    "arXiv": 80,                        # å­¦æœ¯é¢„å°æœ¬ - æœ€é«˜æƒå¨
    "Semantic Scholar": 78,             # è®ºæ–‡å…ƒæ•°æ®åº“ - é«˜æƒå¨
    "OpenAlex": 75,                     # å¼€æ”¾å­¦æœ¯æ•°æ®åº“ - é«˜æƒå¨
    "Papers with Code": 72,             # è®ºæ–‡+ä»£ç  - é«˜æƒå¨
    "OpenReview": 70,                   # è®ºæ–‡è¯„å®¡å¹³å° - ä¸­é«˜æƒå¨
    "DBLP": 68,                         # è®¡ç®—æœºç§‘å­¦æ–‡çŒ®åº“ - ä¸­é«˜æƒå¨

    # ========== ğŸ› ï¸ å¼€å‘å·¥å…· (5ä¸ª) ==========
    "Hugging Face": 60,                 # MLæ¨¡å‹å¹³å° - ä¸­é«˜æƒå¨
    "PyPI": 55,                         # PythonåŒ…ç´¢å¼• - ä¸­ç­‰æƒå¨
    "npm": 50,                          # JavaScriptåŒ… - ä¸­ç­‰æƒå¨
    "GitHub Releases": 58,              # GitHubç‰ˆæœ¬å‘å¸ƒ - ä¸­é«˜æƒå¨
    "PyTorch": 75,                      # PyTorchå®˜æ–¹ - é«˜æƒå¨
    "TensorFlow": 75,                   # TensorFlowå®˜æ–¹ - é«˜æƒå¨

    # ========== ğŸ¦¾ AI Agent (5ä¸ª) ==========
    "GitHub Trending": 45,              # GitHubçƒ­é—¨é¡¹ç›® - ä¸­ç­‰æƒå¨
    "Product Hunt": 40,                 # äº§å“å‘å¸ƒå¹³å° - ä¸­ä½æƒå¨
    "Reddit": 50,                       # Redditç¤¾åŒº - ä¸­ç­‰æƒå¨
    "Hacker News": 70,                  # Hacker News - é«˜æƒå¨
    "Awesome AI Agents": 55,            # ç²¾é€‰åˆ—è¡¨ - ä¸­ç­‰æƒå¨

    # ========== ğŸ’¼ ä¼ä¸šåº”ç”¨ (4ä¸ª) ==========
    "TechCrunch AI": 62,                # TechCrunch AI - ä¸­é«˜æƒå¨
    "VentureBeat AI": 58,               # VentureBeat AI - ä¸­ç­‰æƒå¨
    "AI Business": 52,                  # AI Business - ä¸­ç­‰æƒå¨
    "InfoQ AI": 55,                     # InfoQ AI - ä¸­ç­‰æƒå¨

    # ========== ğŸŒ æ¶ˆè´¹äº§å“ (4ä¸ª) ==========
    "Product Hunt": 40,                 # Product Hunt - ä¸­ä½æƒå¨
    "a16z": 70,                         # a16zæŠ¥å‘Š - é«˜æƒå¨
    "Hacker News": 70,                  # Hacker News (Show HN) - é«˜æƒå¨
    "App Store": 45,                    # App Store - ä¸­ç­‰æƒå¨
    "Google Play": 45,                  # Google Play - ä¸­ç­‰æƒå¨

    # ========== ğŸ“° è¡Œä¸šèµ„è®¯ (6ä¸ª) ==========
    "NewsAPI": 55,                      # NewsAPIèšåˆ - ä¸­ç­‰æƒå¨
    "MIT Tech Review": 72,              # MITæŠ€æœ¯è¯„è®º - é«˜æƒå¨
    "The Gradient": 58,                 # The GradientæœŸåˆŠ - ä¸­é«˜æƒå¨
    "MarkTechPost": 52,                 # MarkTechPost - ä¸­ç­‰æƒå¨
    "Stanford HAI": 80,                 # Stanford HAIæŠ¥å‘Š - é«˜æƒå¨
    "Accenture": 65,                    # AccentureæŠ€æœ¯è¶‹åŠ¿ - ä¸­é«˜æƒå¨

    # ========== å…¶ä»–å·²æœ‰æ•°æ®æº ==========
    "OpenAI Blog": 95,                  # OpenAIå®˜æ–¹ - é¡¶çº§æƒå¨
    "Anthropic": 95,                    # Anthropicå®˜æ–¹ - é¡¶çº§æƒå¨
    "Google AI": 90,                    # Google AIå®˜æ–¹ - é¡¶çº§æƒå¨
    "Microsoft Research": 85,           # å¾®è½¯ç ”ç©¶é™¢ - é«˜æƒå¨
    "BAIR Blog": 85,                    # Berkeley AI Research - é«˜æƒå¨
    "MIT": 80,                          # MIT - é«˜æƒå¨
    "The Verge AI": 65,                 # The Verge AI - ä¸­é«˜æƒå¨
    "KDnuggets": 50,                    # KDnuggets - ä¸­ç­‰æƒå¨
}


class NewsScoringAgent(BaseAgent):
    """æ–°é—»é‡è¦æ€§è¯„åˆ†Agent - å¯¹æ–°é—»è¿›è¡Œè¯„åˆ†å’Œç­›é€‰"""

    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)
        self.name = "news_scoring"

        # è·å–é…ç½®
        agent_config = config.get("agents", {}).get("news_scoring", {})
        self.max_items = agent_config.get("max_items", 30)
        self.min_per_category = agent_config.get("min_per_category", 2)
        self.max_per_category = agent_config.get("max_per_category", 8)

        # è¯„åˆ†æƒé‡
        weights = agent_config.get("scoring_weights", {})
        self.weight_source = weights.get("source_authority", 30)
        self.weight_engagement = weights.get("engagement", 20)
        self.weight_freshness = weights.get("freshness", 15)
        self.weight_balance = weights.get("category_balance", 15)
        self.weight_quality = weights.get("content_quality", 10)
        self.weight_diversity = weights.get("diversity", 10)

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–°é—»è¯„åˆ†å’Œç­›é€‰

        Args:
            state: åŒ…å« categorized_trends çš„çŠ¶æ€

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„çŠ¶æ€ï¼ŒåŒ…å« scored_trends
        """
        self.log("å¼€å§‹å¯¹æ–°é—»è¿›è¡Œé‡è¦æ€§è¯„åˆ†å’Œç­›é€‰...")

        try:
            categorized_trends = state.get("categorized_trends", {})
            if not categorized_trends:
                self.log("æœªæ‰¾åˆ° categorized_trendsï¼Œè·³è¿‡è¯„åˆ†")
                return state

            # ç¬¬ä¸€æ­¥: ä¸ºæ¯æ¡æ–°é—»è®¡ç®—ç»¼åˆè¯„åˆ†
            scored_items = self._score_all_items(categorized_trends)
            self.log(f"å®Œæˆ {len(scored_items)} æ¡æ–°é—»çš„è¯„åˆ†")

            # ç¬¬äºŒæ­¥: æŒ‰åˆ†ç±»ç­›é€‰ï¼Œç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘æœ‰ min_per_category æ¡
            balanced_selection = self._balance_categories(
                scored_items,
                categorized_trends
            )

            # ç¬¬ä¸‰æ­¥: æŒ‰è¯„åˆ†æ’åºï¼Œå– Top N
            final_selection = self._select_top_items(balanced_selection)

            # ç¬¬å››æ­¥: æ„å»ºæ–°çš„åˆ†ç±»ç»“æ„
            scored_trends = self._build_scored_structure(
                final_selection,
                categorized_trends
            )

            # ç»Ÿè®¡ä¿¡æ¯
            total_selected = sum(len(cat["items"]) for cat in scored_trends.values())
            self.log(f"è¯„åˆ†å®Œæˆ: ä»åŸå§‹ {len(scored_items)} æ¡ç­›é€‰è‡³ {total_selected} æ¡")

            # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„æ•°é‡
            for cat_name, cat_data in scored_trends.items():
                if cat_data["count"] > 0:
                    self.log(f"  {cat_name}: {cat_data['count']}æ¡")

            # æå–ç¼–è¾‘ç²¾é€‰ (Top 5)
            editors_pick = self._extract_editors_pick(final_selection)

            return {
                **state,
                "scored_trends": scored_trends,
                "editors_pick": editors_pick,
                "total_selected_count": total_selected,
                "current_step": "news_scored"
            }

        except Exception as e:
            self.log(f"è¯„åˆ†å¤±è´¥: {e}", "ERROR")
            return {
                **state,
                "error_message": f"è¯„åˆ†å¤±è´¥: {e}",
                "current_step": "news_scoring_failed"
            }

    def _score_all_items(self, categorized_trends: Dict) -> List[Dict]:
        """ä¸ºæ‰€æœ‰æ–°é—»é¡¹è®¡ç®—ç»¼åˆè¯„åˆ†"""
        scored_items = []
        current_time = datetime.now()

        for cat_name, cat_data in categorized_trends.items():
            items = cat_data.get("items", [])
            for item in items:
                # è®¡ç®—å„é¡¹å¾—åˆ†
                source_score = self._score_source_authority(item)
                engagement_score = self._score_engagement(item)
                freshness_score = self._score_freshness(item, current_time)
                quality_score = self._score_content_quality(item)

                # ç»¼åˆè¯„åˆ†
                total_score = (
                    source_score * self.weight_source / 100 +
                    engagement_score * self.weight_engagement / 100 +
                    freshness_score * self.weight_freshness / 100 +
                    quality_score * self.weight_quality / 100
                )

                scored_item = {
                    **item,
                    "category": cat_name,
                    "importance_score": round(total_score, 2),
                    "score_breakdown": {
                        "source": source_score,
                        "engagement": engagement_score,
                        "freshness": freshness_score,
                        "quality": quality_score
                    }
                }
                scored_items.append(scored_item)

        return scored_items

    def _score_source_authority(self, item: Dict) -> float:
        """æ ¹æ®æ•°æ®æºæƒå¨åº¦è¯„åˆ†"""
        source = item.get("source", "")
        # æŸ¥æ‰¾æœ€åŒ¹é…çš„æ•°æ®æº
        for known_source, score in SOURCE_AUTHORITY_SCORES.items():
            if known_source.lower() in source.lower():
                return float(score)
        return 50.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

    def _score_engagement(self, item: Dict) -> float:
        """æ ¹æ®äº’åŠ¨æ•°æ®è¯„åˆ†"""
        heat_score = item.get("heat_score", 0)

        # Hacker News ç‚¹æ•°é€šå¸¸åœ¨ 0-500+
        if heat_score >= 200:
            return 100.0
        elif heat_score >= 100:
            return 85.0
        elif heat_score >= 50:
            return 70.0
        elif heat_score >= 20:
            return 55.0
        elif heat_score >= 10:
            return 40.0
        else:
            # æ²¡æœ‰äº’åŠ¨æ•°æ®ä¹Ÿç»™åŸºç¡€åˆ†
            return 30.0

    def _score_freshness(self, item: Dict, current_time: datetime) -> float:
        """
        æ ¹æ®æ—¶æ•ˆæ€§è¯„åˆ† (v9.0: ä¸¥æ ¼24å°æ—¶è¿‡æ»¤)

        å®ç¼ºæ¯‹æ»¥ç­–ç•¥:
        - 24å°æ—¶å†…: 70-100åˆ†
        - è¶…è¿‡24å°æ—¶: 0-20åˆ†ï¼ˆåŸºæœ¬è¢«æ·˜æ±°ï¼‰
        """
        timestamp = item.get("timestamp", "")
        if not timestamp:
            return 30.0  # v9.0: æ²¡æœ‰æ—¶é—´æˆ³ç»™ä½åˆ†ï¼ˆå®ç¼ºæ¯‹æ»¥ï¼‰

        try:
            # å°è¯•è§£ææ—¶é—´æˆ³
            if isinstance(timestamp, str):
                # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
                for fmt in ["%Y-%m-%dT%H:%M:%SZ", "%Y-%m-%d %H:%M:%S", "%Y-%m-%d"]:
                    try:
                        pub_time = datetime.strptime(timestamp.split("+")[0].strip(), fmt)
                        break
                    except ValueError:
                        continue
                else:
                    return 30.0  # v9.0: è§£æå¤±è´¥ç»™ä½åˆ†
            else:
                return 30.0

            # è®¡ç®—æ—¶é—´å·®
            time_diff = (current_time - pub_time).total_seconds() / 3600  # å°æ—¶

            # v9.0: ä¸¥æ ¼24å°æ—¶è¿‡æ»¤
            if time_diff <= 6:
                return 100.0
            elif time_diff <= 12:
                return 90.0
            elif time_diff <= 24:
                return 70.0
            elif time_diff <= 36:  # è¶…è¿‡24å°æ—¶ï¼Œå¤§å¹…é™åˆ†
                return 20.0
            elif time_diff <= 48:
                return 10.0
            else:
                return 5.0  # è¶…è¿‡48å°æ—¶ï¼ŒåŸºæœ¬æ·˜æ±°

        except Exception:
            return 30.0

    def _score_content_quality(self, item: Dict) -> float:
        """æ ¹æ®å†…å®¹è´¨é‡è¯„åˆ†ï¼ˆv8.0 - å¢å¼ºç‰ˆï¼ŒåŒ…å«AIå…³é”®è¯è¯†åˆ«ï¼‰"""
        title = item.get("title", "")
        description = item.get("description", "")

        score = 50.0  # åŸºç¡€åˆ†

        # ========== åŸºç¡€è´¨é‡è¯„åˆ† ==========

        # æ ‡é¢˜è´¨é‡
        if len(title) >= 10 and len(title) <= 100:
            score += 15
        elif len(title) >= 5:
            score += 10

        # æè¿°è´¨é‡
        if description:
            if len(description) >= 50 and len(description) <= 500:
                score += 20
            elif len(description) >= 20:
                score += 15
            elif len(description) >= 10:
                score += 10
        else:
            score -= 10

        # æ ‡é¢˜æ˜¯å¦åŒ…å«æ•°å­—ï¼ˆé€šå¸¸æ›´å…·ä½“ï¼‰
        if any(char.isdigit() for char in title):
            score += 5

        # æ ‡é¢˜æ˜¯å¦å…¨å¤§å†™ï¼ˆå¯èƒ½è´¨é‡è¾ƒä½ï¼‰
        if title.isupper():
            score -= 10

        # ========== v8.0: AIå…³é”®è¯å’ŒæŠ€æœ¯è¶‹åŠ¿è¯†åˆ« ==========

        # åˆå¹¶æ ‡é¢˜å’Œæè¿°è¿›è¡Œå…³é”®è¯æ£€æµ‹
        content = f"{title} {description}".lower()

        # æ£€æµ‹é«˜ä»·å€¼AIå…³é”®è¯ï¼ˆæ¯ä¸ª+3åˆ†ï¼Œæœ€å¤š+15åˆ†ï¼‰
        ai_keyword_count = 0
        for keyword in AI_KEYWORDS_HIGH_VALUE:
            if keyword.lower() in content:
                ai_keyword_count += 1
                if ai_keyword_count >= 5:  # æœ€å¤šè®¡ç®—5ä¸ª
                    break
        score += min(15, ai_keyword_count * 3)

        # æ£€æµ‹æ–°å…´æŠ€æœ¯è¶‹åŠ¿ï¼ˆæ¯ä¸ª+5åˆ†ï¼Œæœ€å¤š+10åˆ†ï¼‰
        trend_count = 0
        for trend in EMERGING_TECH_TRENDS:
            if trend.lower() in content:
                trend_count += 1
                if trend_count >= 2:  # æœ€å¤šè®¡ç®—2ä¸ª
                    break
        score += min(10, trend_count * 5)

        # æ£€æµ‹ä¸“ä¸šæœ¯è¯­ï¼ˆæå‡è´¨é‡æ„Ÿï¼‰
        technical_terms = ["API", "SDK", "benchmark", "performance", "architecture",
                          "paper", "research", "model", "training", "inference"]
        tech_term_count = sum(1 for term in technical_terms if term.lower() in content)
        score += min(5, tech_term_count * 1)

        return min(100.0, max(0.0, score))

    def _balance_categories(
        self,
        scored_items: List[Dict],
        categorized_trends: Dict
    ) -> List[Dict]:
        """æŒ‰åˆ†ç±»å¹³è¡¡ï¼Œç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘æœ‰ min_per_category æ¡ï¼Œä¿ç•™æœ€å¤š max_per_category æ¡ä½œä¸ºå€™é€‰"""
        # æŒ‰åˆ†ç±»åˆ†ç»„
        items_by_category = defaultdict(list)
        for item in scored_items:
            cat = item.get("category", "")
            items_by_category[cat].append(item)

        # ä¸ºæ¯ä¸ªåˆ†ç±»ä¿ç•™å€™é€‰ï¼ˆå…ˆä¿ç•™æœ€å¤š max_per_category æ¡ï¼‰
        balanced_items = []

        for cat_name, items in items_by_category.items():
            # æŒ‰è¯„åˆ†æ’åº
            sorted_items = sorted(items, key=lambda x: x.get("importance_score", 0), reverse=True)

            # ä¿ç•™æœ€å¤š max_per_category æ¡ä½œä¸ºå€™é€‰ï¼ˆè€Œä¸æ˜¯åªä¿ç•™ min_per_categoryï¼‰
            max_count = min(len(sorted_items), self.max_per_category)
            balanced_items.extend(sorted_items[:max_count])

        return balanced_items

    def _select_top_items(self, scored_items: List[Dict]) -> List[Dict]:
        """é€‰æ‹©è¯„åˆ†æœ€é«˜çš„ N æ¡æ–°é—»ï¼ŒåŒæ—¶ç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘æœ‰ min_per_category æ¡"""
        # æŒ‰åˆ†ç±»åˆ†ç»„
        items_by_category = defaultdict(list)
        for item in scored_items:
            cat = item.get("category", "")
            items_by_category[cat].append(item)

        # ç¬¬ä¸€æ­¥ï¼šå…ˆç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘æœ‰ min_per_category æ¡
        guaranteed_items = []
        for cat_name, items in items_by_category.items():
            sorted_items = sorted(items, key=lambda x: x.get("importance_score", 0), reverse=True)
            guaranteed_items.extend(sorted_items[:self.min_per_category])

        # ä»å·²é€‰çš„é›†åˆä¸­ç§»é™¤
        selected_ids = set(item.get("url", "") for item in guaranteed_items)
        remaining_items = [item for item in scored_items if item.get("url", "") not in selected_ids]

        # ç¬¬äºŒæ­¥ï¼šæŒ‰è¯„åˆ†æ’åºå‰©ä½™é¡¹ï¼Œé€‰æ‹©å‰©ä½™åé¢
        remaining_quota = self.max_items - len(guaranteed_items)
        if remaining_quota > 0:
            sorted_remaining = sorted(
                remaining_items,
                key=lambda x: x.get("importance_score", 0),
                reverse=True
            )

            # ä½†è¦é™åˆ¶æ¯ä¸ªåˆ†ç±»æ€»æ•°ä¸è¶…è¿‡ max_per_category
            category_counts = defaultdict(int)
            for item in guaranteed_items:
                category_counts[item.get("category", "")] += 1

            for item in sorted_remaining:
                cat = item.get("category", "")
                if category_counts[cat] < self.max_per_category and len(guaranteed_items) < self.max_items:
                    guaranteed_items.append(item)
                    category_counts[cat] += 1

        return guaranteed_items

    def _build_scored_structure(
        self,
        scored_items: List[Dict],
        original_categories: Dict
    ) -> Dict:
        """æ„å»ºç­›é€‰åçš„åˆ†ç±»ç»“æ„"""
        # æŒ‰åˆ†ç±»åˆ†ç»„
        items_by_category = defaultdict(list)
        for item in scored_items:
            cat = item.get("category", "")
            items_by_category[cat].append(item)

        # æ„å»ºæ–°çš„åˆ†ç±»ç»“æ„
        scored_trends = {}
        for cat_name, cat_data in original_categories.items():
            items = items_by_category.get(cat_name, [])
            scored_trends[cat_name] = {
                "icon": cat_data.get("icon", ""),
                "items": items,
                "count": len(items)
            }

        return scored_trends

    def _extract_editors_pick(self, scored_items: List[Dict]) -> List[Dict]:
        """æå–ç¼–è¾‘ç²¾é€‰ (Top 5)"""
        top_items = sorted(
            scored_items,
            key=lambda x: x.get("importance_score", 0),
            reverse=True
        )[:5]

        # ä¸ºç¼–è¾‘ç²¾é€‰æ·»åŠ åºå·
        editors_pick = []
        for i, item in enumerate(top_items, 1):
            editors_pick.append({
                **item,
                "pick_rank": i,
                "id": f"ep_{i:03d}"
            })

        return editors_pick
