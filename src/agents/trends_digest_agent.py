"""
AIçƒ­ç‚¹æ±‡æ€»Agent - ç”Ÿæˆç±»ä¼¼æ‚å¿—/ç®€æŠ¥çš„æ±‡æ€»æ–‡ç« 
å°†å¤šä¸ªçƒ­ç‚¹è¯é¢˜æ•´åˆæˆä¸€ç¯‡ç»“æ„åŒ–çš„ç®€æŠ¥
"""

from typing import Dict, Any, List
import re
from datetime import datetime
from src.agents.base import BaseAgent


class TrendsDigestAgent(BaseAgent):
    """AIçƒ­ç‚¹æ±‡æ€»Agent - ç”ŸæˆæŠ€æœ¯ç®€æŠ¥"""

    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)
        digest_config = config.get("agents", {}).get("trends_digest", {})
        self.digest_style = digest_config.get("style", "professional")  # professional, casual, magazine
        self.include_analysis = digest_config.get("include_analysis", True)
        self.max_topics = digest_config.get("max_topics", 10)
        self.llm.temperature = 0.6  # ç¨ä½æ¸©åº¦ï¼Œä¿è¯å®¢è§‚å‡†ç¡®

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆçƒ­ç‚¹æ±‡æ€»ç®€æŠ¥

        Args:
            state: å½“å‰å·¥ä½œæµçŠ¶æ€

        Returns:
            Dict[str, Any]: æ›´æ–°åçš„çŠ¶æ€
        """
        self.log("å¼€å§‹ç”ŸæˆAIçƒ­ç‚¹æ±‡æ€»ç®€æŠ¥")

        try:
            # è·å–æ‰€æœ‰çƒ­ç‚¹è¯é¢˜
            hot_topics = state.get("ai_hot_topics", [])
            if not hot_topics:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°AIçƒ­ç‚¹è¯é¢˜åˆ—è¡¨")

            # é™åˆ¶çƒ­ç‚¹æ•°é‡
            hot_topics = hot_topics[:self.max_topics]
            self.log(f"æ±‡æ€» {len(hot_topics)} ä¸ªçƒ­ç‚¹è¯é¢˜")

            # ç”Ÿæˆç®€æŠ¥
            digest = self._generate_digest(state, hot_topics)

            self.log(f"æˆåŠŸç”Ÿæˆçƒ­ç‚¹ç®€æŠ¥ï¼ŒåŒ…å« {len(hot_topics)} ä¸ªè¯é¢˜")

            return {
                **state,
                "trends_digest": digest,
                "current_step": "trends_digest_completed"
            }
        except Exception as e:
            self.log(f"çƒ­ç‚¹ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {str(e)}", "ERROR")
            return {
                **state,
                "error_message": f"çƒ­ç‚¹ç®€æŠ¥ç”Ÿæˆå¤±è´¥: {str(e)}",
                "current_step": "trends_digest_failed"
            }

    def _generate_digest(self, state: Dict[str, Any], hot_topics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆçƒ­ç‚¹ç®€æŠ¥å†…å®¹

        Args:
            state: å½“å‰çŠ¶æ€
            hot_topics: çƒ­ç‚¹è¯é¢˜åˆ—è¡¨

        Returns:
            Dict[str, Any]: ç®€æŠ¥å†…å®¹
        """
        # 1. ç”Ÿæˆç®€æŠ¥æ ‡é¢˜å’Œæ¦‚è¿°
        digest_metadata = self._generate_metadata(hot_topics)

        # 2. ä¸ºæ¯ä¸ªçƒ­ç‚¹ç”Ÿæˆç®€çŸ­æ‘˜è¦
        topic_summaries = []
        for idx, topic in enumerate(hot_topics, 1):
            summary = self._generate_topic_summary(topic, idx)
            topic_summaries.append(summary)

        # 3. ç”Ÿæˆæ±‡æ€»åˆ†æï¼ˆå¯é€‰ï¼‰
        summary_analysis = None
        if self.include_analysis:
            summary_analysis = self._generate_summary_analysis(hot_topics, state)

        # 4. ç»„è£…å®Œæ•´ç®€æŠ¥
        full_content = self._assemble_digest_content(
            digest_metadata,
            topic_summaries,
            summary_analysis
        )

        # 5. ç»Ÿè®¡ä¿¡æ¯
        word_count = len(full_content)
        reading_time = f"{word_count // 500}-{word_count // 300}åˆ†é’Ÿ"

        return {
            "title": digest_metadata["title"],
            "subtitle": digest_metadata["subtitle"],
            "issue_number": digest_metadata["issue_number"],
            "publish_date": digest_metadata["publish_date"],
            "full_content": full_content,
            "topics": topic_summaries,
            "summary_analysis": summary_analysis,
            "word_count": word_count,
            "reading_time": reading_time,
            "total_topics": len(hot_topics),
            "sources": self._get_sources(hot_topics),
            "style": self.digest_style
        }

    def _generate_metadata(self, hot_topics: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆç®€æŠ¥å…ƒæ•°æ®"""
        # æ ¹æ®å½“å‰æ—¥æœŸç”ŸæˆæœŸå·
        today = datetime.now()
        issue_number = today.strftime("%Y%m%d")

        # åˆ†æä¸»è¦æ•°æ®æº
        sources = self._get_sources(hot_topics)
        main_sources = ", ".join(list(sources.keys())[:5])

        return {
            "title": f"AIæŠ€æœ¯çƒ­ç‚¹ç®€æŠ¥ - {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}",
            "subtitle": f"æœ¬æœŸç²¾é€‰ {len(hot_topics)} ä¸ªAIæŠ€æœ¯çƒ­ç‚¹ï¼Œæ¥æºï¼š{main_sources}",
            "issue_number": issue_number,
            "publish_date": today.strftime("%Y-%m-%d"),
            "sources": sources
        }

    def _generate_topic_summary(self, topic: Dict[str, Any], index: int) -> Dict[str, Any]:
        """
        ä¸ºå•ä¸ªçƒ­ç‚¹ç”Ÿæˆæ‘˜è¦

        Args:
            topic: çƒ­ç‚¹æ•°æ®
            index: ç´¢å¼•ç¼–å·

        Returns:
            Dict[str, Any]: çƒ­ç‚¹æ‘˜è¦
        """
        # æå–çƒ­ç‚¹ä¿¡æ¯
        title = topic.get("title", "æœªçŸ¥æ ‡é¢˜")
        description = topic.get("description", "")[:300]
        source = topic.get("source", "æœªçŸ¥æ¥æº")
        url = topic.get("url", "")
        heat_score = topic.get("heat_score", 0)
        tags = topic.get("tags", [])
        timestamp = topic.get("timestamp", "")
        metrics = topic.get("metrics", {})

        # ç”Ÿæˆçƒ­åº¦æè¿°
        heat_description = self._describe_heat_score(heat_score, metrics, source)

        # ç”Ÿæˆç®€çŸ­æ‘˜è¦ï¼ˆå¦‚æœæè¿°å¤ªé•¿ï¼Œç”¨LLMå‹ç¼©ï¼‰
        if len(description) > 200:
            description = self._summarize_description(title, description)

        return {
            "index": index,
            "title": title,
            "summary": description,
            "source": source,
            "url": url,
            "heat_score": heat_score,
            "heat_description": heat_description,
            "tags": tags,
            "timestamp": timestamp,
            "metrics": metrics
        }

    def _describe_heat_score(self, heat_score: int, metrics: Dict[str, Any], source: str) -> str:
        """ç”Ÿæˆçƒ­åº¦æè¿°"""
        if source == "Hacker News":
            upvotes = metrics.get("upvotes", 0)
            comments = metrics.get("comments", 0)
            return f"ğŸ”¥ çƒ­åº¦ {heat_score} (ğŸ‘{upvotes} ğŸ’¬{comments})"
        elif source == "arXiv":
            days_ago = metrics.get("days_ago", 0)
            return f"ğŸ“š å­¦æœ¯è®ºæ–‡ (ğŸ“…{days_ago}å¤©å‰å‘å¸ƒ)"
        elif source == "Hugging Face":
            likes = metrics.get("likes", 0)
            return f"ğŸ¤— æ¨¡å‹çƒ­åº¦ (ğŸ‘{likes} likes)"
        elif source == "GitHub Trending":
            stars = metrics.get("stars", "0")
            return f"â­ GitHubçƒ­é—¨ ({stars} stars)"
        elif source == "Stack Overflow":
            score = metrics.get("score", 0)
            answers = metrics.get("answers", 0)
            return f"â“ æŠ€æœ¯é—®ç­” (ğŸ“Š{score}åˆ† ğŸ’¡{answers}ä¸ªå›ç­”)"
        else:
            return f"ğŸ”¥ çƒ­åº¦è¯„åˆ†: {heat_score}"

    def _summarize_description(self, title: str, description: str) -> str:
        """ä½¿ç”¨LLMå‹ç¼©æè¿°"""
        try:
            prompt = f"""è¯·å°†ä»¥ä¸‹æŠ€æœ¯æè¿°å‹ç¼©ä¸º1-2å¥è¯çš„æ‘˜è¦ï¼ˆ50-80å­—ï¼‰ï¼š

æ ‡é¢˜ï¼š{title}

åŸå§‹æè¿°ï¼š
{description}

è¦æ±‚ï¼š
- ä¿ç•™æ ¸å¿ƒä¿¡æ¯
- è¯­è¨€ç®€æ´æ˜äº†
- é€‚åˆå¿«é€Ÿé˜…è¯»
- ä¸è¦ä¸¢å¤±å…³é”®ç»†èŠ‚

æ‘˜è¦ï¼š"""

            response = self._call_llm(prompt)
            return response.strip()
        except:
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›æˆªæ–­çš„æè¿°
            return description[:150] + "..."

    def _generate_summary_analysis(self, hot_topics: List[Dict[str, Any]], state: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆæ±‡æ€»åˆ†æ

        Args:
            hot_topics: çƒ­ç‚¹åˆ—è¡¨
            state: å½“å‰çŠ¶æ€

        Returns:
            str: åˆ†æå†…å®¹
        """
        try:
            # æå–æ‰€æœ‰æ ‡é¢˜å’Œæ ‡ç­¾
            titles = [t["title"] for t in hot_topics[:5]]
            all_tags = []
            for topic in hot_topics:
                all_tags.extend(topic.get("tags", []))

            # ç»Ÿè®¡çƒ­é—¨æ ‡ç­¾
            from collections import Counter
            top_tags = Counter(all_tags).most_common(10)

            # æ„å»ºæç¤ºè¯
            prompt = f"""åŸºäºä»¥ä¸‹AIæŠ€æœ¯çƒ­ç‚¹ï¼Œæ’°å†™ä¸€ç¯‡ç®€çŸ­çš„æ±‡æ€»åˆ†æï¼ˆ200-300å­—ï¼‰ï¼š

æœ¬æœŸçƒ­ç‚¹æ ‡é¢˜ï¼š
{chr(10).join([f'{i+1}. {title}' for i, title in enumerate(titles)])}

ä¸»è¦æŠ€æœ¯é¢†åŸŸï¼š
{', '.join([tag for tag, _ in top_tags[:5]])}

è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š
1. æœ¬æœŸçƒ­ç‚¹çš„ä¸»è¦æŠ€æœ¯è¶‹åŠ¿
2. å€¼å¾—å…³æ³¨çš„æŠ€æœ¯æ–¹å‘
3. å¯¹è¡Œä¸šçš„å½±å“

è¦æ±‚ï¼š
- å®¢è§‚å‡†ç¡®
- ç®€æ´æœ‰åŠ›
- é€‚åˆç®€æŠ¥åˆŠç™»
"""

            analysis = self._call_llm(prompt)
            return analysis.strip()
        except Exception as e:
            self.log(f"ç”Ÿæˆæ±‡æ€»åˆ†æå¤±è´¥: {e}", "WARNING")
            return None

    def _assemble_digest_content(
        self,
        metadata: Dict[str, Any],
        topic_summaries: List[Dict[str, Any]],
        summary_analysis: str = None
    ) -> str:
        """
        ç»„è£…å®Œæ•´çš„ç®€æŠ¥å†…å®¹

        Args:
            metadata: ç®€æŠ¥å…ƒæ•°æ®
            topic_summaries: è¯é¢˜æ‘˜è¦åˆ—è¡¨
            summary_analysis: æ±‡æ€»åˆ†æ

        Returns:
            str: å®Œæ•´çš„Markdownå†…å®¹
        """
        # æ ¹æ®é£æ ¼é€‰æ‹©æ¨¡æ¿
        if self.digest_style == "magazine":
            return self._assemble_magazine_style(metadata, topic_summaries, summary_analysis)
        elif self.digest_style == "casual":
            return self._assemble_casual_style(metadata, topic_summaries, summary_analysis)
        else:  # professional
            return self._assemble_professional_style(metadata, topic_summaries, summary_analysis)

    def _assemble_professional_style(
        self,
        metadata: Dict[str, Any],
        topic_summaries: List[Dict[str, Any]],
        summary_analysis: str = None
    ) -> str:
        """ä¸“ä¸šé£æ ¼ç®€æŠ¥"""
        content_parts = []

        # æ ‡é¢˜
        content_parts.append(f"# {metadata['title']}\n")
        content_parts.append(f"{metadata['subtitle']}\n")
        content_parts.append(f"**å‘å¸ƒæ—¥æœŸ**: {metadata['publish_date']}  |  **æœŸå·**: #{metadata['issue_number']}\n")

        # æ±‡æ€»åˆ†æï¼ˆå¦‚æœæœ‰ï¼‰
        if summary_analysis:
            content_parts.append("\n## ğŸ“Š æœ¬æœŸè¶‹åŠ¿åˆ†æ\n")
            content_parts.append(f"{summary_analysis}\n")

        # çƒ­ç‚¹åˆ—è¡¨
        content_parts.append("\n## ğŸ”¥ æœ¬æœŸçƒ­ç‚¹è¯¦æƒ…\n")

        for topic in topic_summaries:
            content_parts.append(f"\n### {topic['index']}. {topic['title']}\n")
            content_parts.append(f"**æ¥æº**: {topic['source']}  |  {topic['heat_description']}\n")
            content_parts.append(f"**æ‘˜è¦**: {topic['summary']}\n")

            if topic['url']:
                content_parts.append(f"**åŸæ–‡é“¾æ¥**: [{topic['url']}]({topic['url']})\n")

            if topic['tags']:
                tags_str = " ".join([f"#{tag}" for tag in topic['tags'][:5]])
                content_parts.append(f"**æ ‡ç­¾**: {tags_str}\n")

        # æ•°æ®æºç»Ÿè®¡
        sources = metadata['sources']
        content_parts.append("\n---\n")
        content_parts.append("\n## ğŸ“ˆ æ•°æ®æºç»Ÿè®¡\n")
        for source, count in sources.items():
            content_parts.append(f"- **{source}**: {count} æ¡çƒ­ç‚¹\n")

        # é¡µè„š
        content_parts.append("\n---\n")
        content_parts.append(f"\n*æœ¬ç®€æŠ¥ç”± ContentForge AI è‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ¥æº: {', '.join(sources.keys())}*\n")

        return "\n".join(content_parts)

    def _assemble_magazine_style(
        self,
        metadata: Dict[str, Any],
        topic_summaries: List[Dict[str, Any]],
        summary_analysis: str = None
    ) -> str:
        """æ‚å¿—é£æ ¼ç®€æŠ¥"""
        content_parts = []

        # å¤§æ ‡é¢˜
        content_parts.append(f"# {metadata['title']}\n")
        content_parts.append(f"```{metadata['subtitle']}```\n")
        content_parts.append(f"ğŸ“… {metadata['publish_date']}  |  ğŸ†” {metadata['issue_number']}\n")

        # æœ¬æœŸå¯¼è¯»
        content_parts.append("\n## âœ¨ æœ¬æœŸå¯¼è¯»\n")
        for topic in topic_summaries[:5]:
            content_parts.append(f"- **{topic['title']}** ({topic['source']})\n")

        # æ±‡æ€»åˆ†æ
        if summary_analysis:
            content_parts.append("\n## ğŸ“° è¶‹åŠ¿è§‚å¯Ÿ\n")
            content_parts.append(f"{summary_analysis}\n")

        # çƒ­ç‚¹è¯¦æƒ…
        content_parts.append("\n## ğŸ”¥ çƒ­ç‚¹è§£è¯»\n")

        for topic in topic_summaries:
            content_parts.append(f"\n### ğŸ“Œ {topic['index']}. {topic['title']}\n")

            # å…ƒä¿¡æ¯æ¡†
            content_parts.append(f"> ğŸ’¡ **{topic['source']}**  |  {topic['heat_description']}\n")

            content_parts.append(f"\n{topic['summary']}\n")

            if topic['url']:
                content_parts.append(f"\nğŸ”— **[é˜…è¯»åŸæ–‡]({topic['url']})**\n")

            if topic['tags']:
                tags_str = " ".join([f"`{tag}`" for tag in topic['tags'][:5]])
                content_parts.append(f"\nğŸ·ï¸ {tags_str}\n")

        # æ•°æ®æº
        sources = metadata['sources']
        content_parts.append("\n---\n")
        content_parts.append("\n## ğŸ“Š æœ¬æœŸæ•°æ®æ¥æº\n")
        for source, count in sources.items():
            content_parts.append(f"`{source}`: **{count}** æ¡  ")

        content_parts.append("\n\n---\n")
        content_parts.append(f"\n<div align='center'>\n\n**ContentForge AI** Â· è‡ªåŠ¨ç”Ÿæˆ Â· {metadata['publish_date']}\n\n</div>\n")

        return "\n".join(content_parts)

    def _assemble_casual_style(
        self,
        metadata: Dict[str, Any],
        topic_summaries: List[Dict[str, Any]],
        summary_analysis: str = None
    ) -> str:
        """è½»æ¾é£æ ¼ç®€æŠ¥"""
        content_parts = []

        # æ ‡é¢˜
        content_parts.append(f"# ğŸ¤– {metadata['title']}\n")
        content_parts.append(f"{metadata['subtitle']}\n")
        content_parts.append(f"ğŸ“… {metadata['publish_date']}\n")

        # æ±‡æ€»åˆ†æ
        if summary_analysis:
            content_parts.append(f"\n## ğŸ¯ ä¸€å¥è¯æ€»ç»“\n{summary_analysis}\n")

        # çƒ­ç‚¹åˆ—è¡¨
        content_parts.append("\n## ğŸ”¥ ä»Šå¤©çš„çƒ­ç‚¹\n")

        for topic in topic_summaries:
            content_parts.append(f"\n### {topic['index']}. {topic['title']}\n\n")

            content_parts.append(f"{topic['summary']}\n\n")

            content_parts.append(f"ğŸ“ {topic['source']} Â· {topic['heat_description']}\n")

            if topic['url']:
                content_parts.append(f"ğŸ”— [åŸæ–‡]({topic['url']})\n")

        # æ•°æ®æº
        sources = metadata['sources']
        content_parts.append("\n---\n")
        content_parts.append(f"\nğŸ“Š æ•°æ®æ¥æº: {', '.join(sources.keys())}\n")
        content_parts.append(f"\n---\n\nâœ¨ ç”± ContentForge AI è‡ªåŠ¨ç”Ÿæˆ\n")

        return "\n".join(content_parts)

    def _get_sources(self, hot_topics: List[Dict[str, Any]]) -> Dict[str, int]:
        """ç»Ÿè®¡æ•°æ®æº"""
        from collections import Counter
        sources = [topic.get("source", "æœªçŸ¥") for topic in hot_topics]
        return dict(Counter(sources))
