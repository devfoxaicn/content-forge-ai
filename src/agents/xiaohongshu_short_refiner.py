"""
å°çº¢ä¹¦çŸ­ç¬”è®°ç²¾ç‚¼Agentï¼ˆå¿«é€Ÿé˜…è¯»ç‰ˆæœ¬ï¼‰
ç”Ÿæˆ800-1000å­—çš„ç²¾ç®€å°çº¢ä¹¦ç¬”è®°ï¼Œé€‚åˆå¿«é€Ÿæµè§ˆå’Œä¼ æ’­
"""

from typing import Dict, Any
import re
from src.agents.base import BaseAgent


class XiaohongshuShortRefinerAgent(BaseAgent):
    """å°çº¢ä¹¦çŸ­ç¬”è®°ç²¾ç‚¼Agent - å¿«é€Ÿé˜…è¯»ç‰ˆæœ¬ï¼ˆ800-1000å­—ï¼‰"""

    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)
        refiner_config = config.get("agents", {}).get("xiaohongshu_short_refiner", {})
        self.style = refiner_config.get("style", "viral")
        self.max_tokens = refiner_config.get("max_tokens", 4000)  # çŸ­ç¬”è®°éœ€è¦è¾ƒå°‘token
        self.llm.max_tokens = self.max_tokens
        self.llm.temperature = 0.98  # æ›´é«˜çš„åˆ›é€ æ€§ï¼ŒçŸ­å†…å®¹éœ€è¦æ›´å¸å¼•äºº
        self.include_test_case = refiner_config.get("include_test_case", True)
        self.target_word_count = refiner_config.get("target_word_count", 900)  # ç›®æ ‡900å­—ï¼ˆ800-1000ä¸­é—´å€¼ï¼‰
        self.mock_mode = config.get("agents", {}).get("ai_trend_analyzer", {}).get("mock_mode", False)

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºé•¿ç‰ˆæœ¬ç²¾ç‚¼å°çº¢ä¹¦çŸ­ç¬”è®°"""
        self.log("å¼€å§‹åŸºäºé•¿ç‰ˆæœ¬ç²¾ç‚¼å°çº¢ä¹¦çŸ­ç¬”è®°")

        try:
            # ä¼˜å…ˆä½¿ç”¨é•¿ç‰ˆæœ¬ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹æ–‡ç« 
            long_note = state.get("xiaohongshu_long_note")
            article = state.get("longform_article")

            if not long_note and not article:
                raise ValueError("æ²¡æœ‰æ‰¾åˆ°é•¿ç¬”è®°æˆ–åŸå§‹æ–‡ç« ")

            # å¦‚æœæœ‰é•¿ç‰ˆæœ¬ï¼ŒåŸºäºé•¿ç‰ˆæœ¬ç²¾ç‚¼ï¼›å¦åˆ™åŸºäºåŸå§‹æ–‡ç« 
            if long_note:
                self.log(f"åŸºäºé•¿ç‰ˆæœ¬ç²¾ç‚¼çŸ­ç¬”è®°: {long_note['title']}")
                source_content = long_note['full_content']
                source_title = long_note['title']
            else:
                self.log(f"åŸºäºåŸå§‹æ–‡ç« ç²¾ç‚¼çŸ­ç¬”è®°: {article['title']}")
                source_content = article['full_content']
                source_title = article['title']

            # é¢„å¤„ç†ï¼šç§»é™¤é•¿ç¬”è®°ä¸­çš„---åˆ†éš”ç¬¦ï¼Œé¿å…LLMæ¨¡ä»¿åŸæ–‡æ ¼å¼
            source_content = source_content.replace('---', '\n')
            self.log("å·²é¢„å¤„ç†ï¼šç§»é™¤åŸæ–‡åˆ†éš”ç¬¦ä»¥é¿å…æ ¼å¼æ¨¡ä»¿")

            if self.mock_mode:
                self.log("ä½¿ç”¨Mockæ¨¡å¼ç”ŸæˆçŸ­ç¬”è®°")
                xhs_note = self._generate_mock_note(article or {"title": source_title, "full_content": source_content})
            else:
                user_prompt = self._build_prompt(state, source_title, source_content)
                response = self._call_llm(user_prompt)
                xhs_note = self._parse_xiaohongshu_note(response, article or {"title": source_title, "full_content": source_content})

            self.log(f"æˆåŠŸç”ŸæˆçŸ­ç¬”è®°ï¼Œå­—æ•°: {xhs_note['word_count']}")
            return {
                **state,
                "xiaohongshu_short_note": xhs_note,
                "current_step": "xiaohongshu_short_refiner_completed"
            }
        except Exception as e:
            self.log(f"çŸ­ç¬”è®°ç²¾ç‚¼å¤±è´¥: {str(e)}", "ERROR")
            self.log("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ç»§ç»­æµ‹è¯•", "WARNING")
            article = state.get("longform_article", {"title": "AIæŠ€æœ¯", "full_content": "å†…å®¹"})
            xhs_note = self._generate_mock_note(article)
            return {
                **state,
                "xiaohongshu_short_note": xhs_note,
                "current_step": "xiaohongshu_short_refiner_completed"
            }

    def _build_prompt(self, state: Dict[str, Any], source_title: str, source_content: str) -> str:
        """æ„å»ºçŸ­ç¬”è®°æç¤ºè¯ï¼ˆåŸºäºé•¿ç‰ˆæœ¬ï¼Œä¸–ç•Œçº§å°çº¢ä¹¦ä¸“å®¶ï¼‰"""
        prompts = self.prompts.get("prompts", {})
        prompt_template = prompts.get("xiaohongshu_short_refiner", {}).get("user", "")

        target_audience = state.get("target_audience", "æŠ€æœ¯ä»ä¸šè€…")

        if prompt_template:
            return prompt_template.format(
                source_title=source_title,
                source_content=source_content,
                target_audience=target_audience,
                target_word_count=self.target_word_count,
                style=self.style
            )
        else:
            # ä¸–ç•Œçº§å°çº¢ä¹¦ä¸“å®¶çš„çŸ­ç¬”è®°æç¤ºè¯ï¼ˆç²¾ç‚¼ç‰ˆï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯ï¼‰
            return f"""ä½ æ˜¯ä¸–ç•Œé¡¶å°–çš„å°çº¢ä¹¦å†…å®¹ä¸“å®¶ï¼Œç²¾é€šå°†æ·±åº¦é•¿æ–‡ç²¾ç‚¼ä¸ºé«˜ä¼ æ’­çŸ­ç¬”è®°ã€‚

**é•¿ç‰ˆæœ¬æ ‡é¢˜**ï¼š{source_title}

**é•¿ç‰ˆæœ¬å†…å®¹**ï¼š
{source_content[:3000]}

---

## ğŸ¯ çŸ­ç¬”è®°ç²¾ç‚¼ç­–ç•¥ï¼ˆä¸–ç•Œçº§æ ‡å‡†ï¼‰

ä½ çš„ä»»åŠ¡ï¼šå°†é•¿ç¬”è®°ç²¾ç‚¼ä¸º800-1000å­—çš„**ç²¾åç‰ˆ**ï¼Œè¦æ±‚ï¼š

### ğŸ“ ç»“æ„è¦æ±‚ï¼ˆå¿…é¡»ä¿æŒ6ç« èŠ‚ï¼‰
ä½¿ç”¨ `---` åˆ†éš”ä»¥ä¸‹6ä¸ªç« èŠ‚ï¼Œæ¯ä¸ªç« èŠ‚éƒ½è¦å¯¹åº”é•¿ç‰ˆæœ¬ï¼š

**ç¬¬1ç« ï¼šé»„é‡‘3ç§’é’©å­**ï¼ˆ2-3å¥è¯ï¼Œåˆ¶é€ ç´§è¿«æ„Ÿï¼‰
- ä»é•¿ç‰ˆæœ¬å¼€ç¯‡æå–æœ€éœ‡æ’¼çš„ç—›ç‚¹/æ•°æ®/å‘ç°
- å¿…é¡»åŒ…å«ï¼šæ•°å­—/å¯¹æ¯”/æƒ…æ„Ÿå…±é¸£

**ç¬¬2ç« ï¼šæ ¸å¿ƒå‘ç°**ï¼ˆ3-5ä¸ªï¼Œç”¨ | åˆ†éš”ï¼‰
- ä»é•¿ç‰ˆæœ¬æå–æœ€å…³é”®çš„å‘ç°
- æ¯ä¸ªå‘ç°8å­—ä»¥å†…ï¼Œæ•°å­—é©±åŠ¨

**ç¬¬3ç« ï¼šä¸ºä»€ä¹ˆæœ‰æ•ˆ**ï¼ˆ1æ®µæ ¸å¿ƒé€»è¾‘ï¼‰
- ä¿ç•™é•¿ç‰ˆæœ¬çš„æŠ€æœ¯åŸç†/æ ¸å¿ƒä¼˜åŠ¿
- ç²¾ç®€åˆ°3-4å¥è¯ï¼Œåˆ é™¤èƒŒæ™¯æè¿°

**ç¬¬4ç« ï¼šçœŸå®æ•ˆæœ**ï¼ˆä¿ç•™å…³é”®æ•°æ®ï¼‰
- Before/Afterå¯¹æ¯”ï¼ˆå¿…ä¿ç•™ï¼‰
- 1ä¸ªå…·ä½“æ¡ˆä¾‹ï¼ˆä»é•¿ç‰ˆæœ¬é€‰æœ€éœ‡æ’¼çš„ï¼‰
- ç”¨æ•°æ®è¯´è¯ï¼Œæ—¶é—´çº¿å‹ç¼©

**ç¬¬5ç« ï¼šæ ¸å¿ƒæŠ€å·§**ï¼ˆ3ä¸ªæŠ€å·§+2ä¸ªé¿å‘ï¼‰
- æŠ€å·§ï¼šä»é•¿ç‰ˆæœ¬é€‰æœ€é‡è¦çš„3ä¸ª
- é¿å‘ï¼šé€‰æœ€å¸¸è§çš„2ä¸ªé”™è¯¯
- æ¯ä¸ªæŠ€å·§2å¥è¯ï¼Œç›´å‡»è¦ç‚¹

**ç¬¬6ç« ï¼šè¡ŒåŠ¨å·å¬**ï¼ˆ2å¥è¯CTAï¼‰
- æ€»ç»“æ ¸å¿ƒä»·å€¼ï¼ˆ1å¥ï¼‰
- å¼ºæœ‰åŠ›çš„è¡ŒåŠ¨å·å¬ï¼ˆ1å¥ï¼‰

### âœï¸ å†™ä½œæ ‡å‡†
- **æ ‡é¢˜**ï¼š15å­—ä»¥å†…ï¼Œå«emojiï¼Œåˆ¶é€ å¥½å¥‡
- **å­—æ•°**ï¼š800-1000å­—ï¼Œç²¾å‡†æ§åˆ¶
- **emoji**ï¼š8-12ä¸ªï¼Œç‚¹ç¼€å…³é”®ç‚¹
- **çŸ­å¥ä¸ºä¸»**ï¼šæ¯æ®µ1-2å¥è¯ï¼ŒèŠ‚å¥å¿«
- **æ•°å­—é©±åŠ¨**ï¼šä¿ç•™æ‰€æœ‰æ•°æ®å¯¹æ¯”
- **æƒ…æ„Ÿå…±é¸£**ï¼šç´§è¿«æ„Ÿ+è·å¾—æ„Ÿ

### ğŸš« åˆ å‡åŸåˆ™
âŒ åˆ é™¤ï¼šèƒŒæ™¯é“ºå«ã€å†—ä½™æ¡ˆä¾‹ã€è¿‡æ¸¡å¥ã€é‡å¤è¡¨è¾¾
âœ… ä¿ç•™ï¼šæ ¸å¿ƒæ•°æ®ã€å…³é”®ç»“è®ºã€å®ç”¨æŠ€å·§ã€å¯¹æ¯”æ•ˆæœ

### ğŸ”¥ ä¸–ç•Œçº§æ ‡å‡†
- å¼€ç¯‡3ç§’å†…æŠ“ä½æ³¨æ„åŠ›
- æ¯ä¸ªç« èŠ‚éƒ½æœ‰ä¿¡æ¯å¢é‡
- æ•°æ®çœŸå®ï¼Œå¯¹æ¯”å¼ºçƒˆ
- å¯æ“ä½œæ€§å¼ºï¼Œæ‹¿æ¥å³ç”¨
- ç»“å°¾CTAæœ‰åŠ›ï¼Œå¼•å‘è¡ŒåŠ¨

**ç°åœ¨å¼€å§‹ç²¾ç‚¼ï¼Œè®°ä½ï¼šè¿™æ˜¯é•¿ç¬”è®°çš„ç²¾åæµ“ç¼©ï¼Œä¸æ˜¯ç®€å•åˆ å‡ï¼**
"""

    def _parse_xiaohongshu_note(self, response: str, article: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æå°çº¢ä¹¦çŸ­ç¬”è®°"""
        # æå–markdownä»£ç å—å†…å®¹ï¼ˆå¦‚æœè¢«```markdownåŒ…è£¹ï¼‰
        markdown_match = re.search(r'```markdown\n(.*?)```', response, re.DOTALL)
        if markdown_match:
            content = markdown_match.group(1).strip()
        else:
            content = response.strip()

        # åå¤„ç†ï¼šå°†---åˆ†éš”ç¬¦è½¬æ¢ä¸º## 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ç¼–å·æ ¼å¼
        content = self._convert_to_numbered_format(content)
        self.log("å·²åå¤„ç†ï¼šè½¬æ¢åˆ†éš”ç¬¦ä¸ºç¼–å·æ ¼å¼")

    def _convert_to_numbered_format(self, content: str) -> str:
        """å°†---åˆ†éš”ç¬¦è½¬æ¢ä¸º## 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ç¼–å·æ ¼å¼"""
        # å®šä¹‰ç« èŠ‚ç¼–å·emoji
        number_emojis = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£']
        # å®šä¹‰ç« èŠ‚ç±»å‹æ˜ å°„ï¼ˆæ ¹æ®å†…å®¹ç‰¹å¾ï¼‰
        section_types = [
            'æ ¸å¿ƒå‘ç°',      # ç¬¬1èŠ‚
            'æ¶æ„è®¾è®¡',      # ç¬¬2èŠ‚
            'å®æµ‹æ•ˆæœ',      # ç¬¬3èŠ‚
            'å®æˆ˜æŠ€å·§',      # ç¬¬4èŠ‚
            'é¿å‘æŒ‡å—',      # ç¬¬5èŠ‚
            'æ€»ç»“'          # ç¬¬6èŠ‚
        ]

        # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²å†…å®¹
        parts = content.split('---')

        # è¿‡æ»¤ç©ºéƒ¨åˆ†
        parts = [p.strip() for p in parts if p.strip()]

        # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œè¿”å›åŸå†…å®¹
        if len(parts) <= 1:
            return content

        # ç¬¬ä¸€éƒ¨åˆ†æ˜¯æ ‡é¢˜å’Œå¼€å¤´ï¼Œä¿æŒä¸å˜
        result = parts[0].strip() + '\n\n'

        # æ£€æŸ¥æ˜¯å¦æœ‰"## å¼€å¤´å…ˆè¯´ç—›ç‚¹"ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ·»åŠ 
        if '## å¼€å¤´å…ˆè¯´ç—›ç‚¹' not in result and 'æœ‰æ²¡æœ‰å‘ç°' in result:
            # æ‰¾åˆ°å¼€å¤´çš„ä½ç½®ï¼Œåœ¨å…¶å‰æ’å…¥æ ‡é¢˜
            lines = result.split('\n')
            for i, line in enumerate(lines):
                if 'æœ‰æ²¡æœ‰å‘ç°' in line or 'å‡Œæ™¨' in line or 'ä»Šå¤©åˆ†äº«' in line:
                    lines.insert(i, '## å¼€å¤´å…ˆè¯´ç—›ç‚¹')
                    lines.insert(i + 1, '')
                    break
            result = '\n'.join(lines)

        # å¤„ç†åç»­éƒ¨åˆ†ï¼Œæ·»åŠ ç¼–å·
        for i, part in enumerate(parts[1:], start=1):
            if i > len(number_emojis):
                break

            # è·³è¿‡ç©ºè¡Œ
            if not part.strip():
                continue

            # æå–ç¬¬ä¸€è¡Œä½œä¸ºå°æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ç±»å‹
            part_lines = part.strip().split('\n')
            first_line = part_lines[0].strip() if part_lines else ''

            # åˆ¤æ–­ç¬¬ä¸€è¡Œæ˜¯å¦åƒæ ‡é¢˜ï¼ˆçŸ­ä¸”æ²¡æœ‰å¥å·ï¼‰
            if len(first_line) < 30 and 'ã€‚' not in first_line and 'ï¼' not in first_line and first_line and not first_line.startswith('#'):
                # ç¬¬ä¸€è¡Œä½œä¸ºå°æ ‡é¢˜
                section_title = first_line
                remaining_content = '\n'.join(part_lines[1:]) if len(part_lines) > 1 else ''
            else:
                # ä½¿ç”¨é»˜è®¤ç±»å‹
                section_title = section_types[min(i-1, len(section_types)-1)]
                remaining_content = part.strip()

            # æ·»åŠ ç¼–å·ç« èŠ‚
            result += f'## {number_emojis[i-1]} {section_title}\n\n'
            if remaining_content.strip():
                result += remaining_content.strip() + '\n\n'

        # ç¡®ä¿ç»“å°¾æœ‰"## æ€»ç»“ä¸€ä¸‹"
        if '## æ€»ç»“ä¸€ä¸‹' not in result:
            # æ£€æŸ¥æœ€åä¸€æ®µæ˜¯å¦åƒæ€»ç»“
            last_part = parts[-1].strip() if parts else ''
            if last_part and len(last_part) < 200 and ('æ•ˆç‡' in last_part or 'å·¥å…·' in last_part or 'ç«‹åˆ»' in last_part):
                # æœ€åä¸€æ®µä½œä¸ºæ€»ç»“
                result = result.rstrip() + '\n\n## æ€»ç»“ä¸€ä¸‹\n\n' + last_part + '\n\n'

        return result.rstrip()

    def _parse_xiaohongshu_note(self, response: str, article: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æå°çº¢ä¹¦çŸ­ç¬”è®°"""
        # æå–markdownä»£ç å—å†…å®¹ï¼ˆå¦‚æœè¢«```markdownåŒ…è£¹ï¼‰
        markdown_match = re.search(r'```markdown\n(.*?)```', response, re.DOTALL)
        if markdown_match:
            content = markdown_match.group(1).strip()
        else:
            content = response.strip()

        # åå¤„ç†ï¼šå°†---åˆ†éš”ç¬¦è½¬æ¢ä¸º## 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ç¼–å·æ ¼å¼
        content = self._convert_to_numbered_format(content)
        self.log("å·²åå¤„ç†ï¼šè½¬æ¢åˆ†éš”ç¬¦ä¸ºç¼–å·æ ¼å¼")

        # æå–æ ‡é¢˜ï¼ˆä½¿ç”¨è½¬æ¢åçš„contentï¼‰
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        title = title_match.group(1).strip() if title_match else article['title']

        # æå–æ ‡ç­¾
        hashtags = []
        hashtag_match = re.search(r'æ ‡ç­¾[:ï¼š](.+)', content)
        if hashtag_match:
            hashtag_text = hashtag_match.group(1).strip()
            hashtags = [tag.strip() for tag in re.findall(r'#[\w\u4e00-\u9fff]+', hashtag_text)]

        if not hashtags:
            hashtags = re.findall(r'#[\w\u4e00-\u9fff]+', content)

        # ç»§æ‰¿åŸæ–‡ç« çš„æ ‡ç­¾
        original_tags = article.get('tags', [])
        all_tags = list(set(hashtags + [f"#{tag}" for tag in original_tags]))[:5]

        # è®¡ç®—å­—æ•°
        word_count = len(content)

        # è®¡ç®—emojiæ•°é‡
        emoji_count = len(re.findall(r'[ğŸš€ğŸ”¥ğŸ’¡âš¡âœ…ğŸ“ŠğŸ“ˆğŸ’°â±ï¸ğŸ¯ğŸ“ŒâŒâš ï¸ğŸš¨ğŸâœ¨ğŸ†ğŸ’ªğŸ‘‡ğŸ’¬ğŸ”„â¤ï¸ğŸ˜­ğŸ˜±]', content))

        return {
            "title": title,
            "full_content": content,
            "hashtags": all_tags,
            "word_count": word_count,
            "original_article_word_count": article.get('word_count', 0),
            "compression_ratio": f"{(1 - word_count / article.get('word_count', 1)) * 100:.1f}%",
            "emoji_count": emoji_count,
            "note_type": "short",
            "target_word_count": self.target_word_count
        }

    def _convert_to_numbered_format(self, content: str) -> str:
        """å°†---åˆ†éš”ç¬¦è½¬æ¢ä¸º## 1ï¸âƒ£ 2ï¸âƒ£ 3ï¸âƒ£ç¼–å·æ ¼å¼"""
        # å®šä¹‰ç« èŠ‚ç¼–å·emoji
        number_emojis = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£']
        # å®šä¹‰ç« èŠ‚ç±»å‹æ˜ å°„ï¼ˆæ ¹æ®å†…å®¹ç‰¹å¾ï¼‰
        section_types = [
            'æ ¸å¿ƒå‘ç°',      # ç¬¬1èŠ‚
            'æ¶æ„è®¾è®¡',      # ç¬¬2èŠ‚
            'å®æµ‹æ•ˆæœ',      # ç¬¬3èŠ‚
            'å®æˆ˜æŠ€å·§',      # ç¬¬4èŠ‚
            'é¿å‘æŒ‡å—',      # ç¬¬5èŠ‚
            'æ€»ç»“'          # ç¬¬6èŠ‚
        ]

        # æŒ‰åˆ†éš”ç¬¦åˆ†å‰²å†…å®¹
        parts = content.split('---')

        # è¿‡æ»¤ç©ºéƒ¨åˆ†
        parts = [p.strip() for p in parts if p.strip()]

        # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œè¿”å›åŸå†…å®¹
        if len(parts) <= 1:
            return content

        # ç¬¬ä¸€éƒ¨åˆ†æ˜¯æ ‡é¢˜å’Œå¼€å¤´ï¼Œä¿æŒä¸å˜
        result = parts[0].strip() + '\n\n'

        # æ£€æŸ¥æ˜¯å¦æœ‰"## å¼€å¤´å…ˆè¯´ç—›ç‚¹"ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ·»åŠ 
        if '## å¼€å¤´å…ˆè¯´ç—›ç‚¹' not in result and 'æœ‰æ²¡æœ‰å‘ç°' in result:
            # æ‰¾åˆ°å¼€å¤´çš„ä½ç½®ï¼Œåœ¨å…¶å‰æ’å…¥æ ‡é¢˜
            lines = result.split('\n')
            for i, line in enumerate(lines):
                if 'æœ‰æ²¡æœ‰å‘ç°' in line or 'å‡Œæ™¨' in line or 'ä»Šå¤©åˆ†äº«' in line:
                    lines.insert(i, '## å¼€å¤´å…ˆè¯´ç—›ç‚¹')
                    lines.insert(i + 1, '')
                    break
            result = '\n'.join(lines)

        # å¤„ç†åç»­éƒ¨åˆ†ï¼Œæ·»åŠ ç¼–å·
        for i, part in enumerate(parts[1:], start=1):
            if i > len(number_emojis):
                break

            # è·³è¿‡ç©ºè¡Œ
            if not part.strip():
                continue

            # æå–ç¬¬ä¸€è¡Œä½œä¸ºå°æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤ç±»å‹
            part_lines = part.strip().split('\n')
            first_line = part_lines[0].strip() if part_lines else ''

            # åˆ¤æ–­ç¬¬ä¸€è¡Œæ˜¯å¦åƒæ ‡é¢˜ï¼ˆçŸ­ä¸”æ²¡æœ‰å¥å·ï¼‰
            if len(first_line) < 30 and 'ã€‚' not in first_line and 'ï¼' not in first_line and first_line and not first_line.startswith('#'):
                # ç¬¬ä¸€è¡Œä½œä¸ºå°æ ‡é¢˜
                section_title = first_line
                remaining_content = '\n'.join(part_lines[1:]) if len(part_lines) > 1 else ''
            else:
                # ä½¿ç”¨é»˜è®¤ç±»å‹
                section_title = section_types[min(i-1, len(section_types)-1)]
                remaining_content = part.strip()

            # æ·»åŠ ç¼–å·ç« èŠ‚
            result += f'## {number_emojis[i-1]} {section_title}\n\n'
            if remaining_content.strip():
                result += remaining_content.strip() + '\n\n'

        # ç¡®ä¿ç»“å°¾æœ‰"## æ€»ç»“ä¸€ä¸‹"
        if '## æ€»ç»“ä¸€ä¸‹' not in result:
            # æ£€æŸ¥æœ€åä¸€æ®µæ˜¯å¦åƒæ€»ç»“
            last_part = parts[-1].strip() if parts else ''
            if last_part and len(last_part) < 200 and ('æ•ˆç‡' in last_part or 'å·¥å…·' in last_part or 'ç«‹åˆ»' in last_part):
                # æœ€åä¸€æ®µä½œä¸ºæ€»ç»“
                result = result.rstrip() + '\n\n## æ€»ç»“ä¸€ä¸‹\n\n' + last_part + '\n\n'

        return result.rstrip()

    def _generate_mock_note(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿå°çº¢ä¹¦çŸ­ç¬”è®°ï¼ˆä¸–ç•Œçº§æ ‡å‡†ï¼‰"""
        title = article.get('title', 'AIæŠ€æœ¯çªç ´')
        main_title = title.split('ï¼š')[0].split(':')[0]

        mock_content = f"""# 7å¤©ä¸Šæ‰‹ï¼{main_title}çœŸé¦™ğŸ’¥

æ¯å¤©åŠ ç­åˆ°10ç‚¹ï¼Ÿç”¨äº†ä¸€å‘¨ç›´æ¥æ—©ä¸‹ç­2å°æ—¶ğŸ˜­

---

## âœ¨ æ ¸å¿ƒå‘ç°

200Kä¸Šä¸‹æ–‡ä¸€å£æ°”è¯»å®Œé¡¹ç›®ï½œåƒçœŸåŒäº‹ä¸€æ ·ä¸»åŠ¨å¹²æ´»ï½œç¼–ç æ•ˆç‡ç›´æ¥ç¿»å€

---

## ğŸ’¡ ä¸ºä»€ä¹ˆå¥½ç”¨

ä¼ ç»ŸAIè¦åå¤è§£é‡Šä¸Šä¸‹æ–‡ï¼Œæ¯æ¬¡å¤åˆ¶ç²˜è´´åˆ°æ‰‹é…¸

è¿™ä¸ªç›´æ¥è¯»é¡¹ç›®æ–‡ä»¶ï¼Œè‡ªåŠ¨ç†è§£ä¾èµ–å…³ç³»ï¼Œä¸ç”¨ä½ è¯´å®ƒå°±æ‡‚

---

## ğŸ“Š çœŸå®æ•°æ®

ç¼–ç ï¼š4hâ†’2hï¼ˆâ†“50%ï¼‰
Bugä¿®å¤ï¼š1.5hâ†’0.5hï¼ˆâ†“67%ï¼‰

**çœŸå®æ¡ˆä¾‹**ï¼šé‡æ„1000è¡Œè€ä»£ç 
ä¼ ç»Ÿæ–¹æ³•7å°æ—¶ï½œç”¨å®ƒ2å°æ—¶æå®š

---

## ğŸ“Œ 3ä¸ªæŠ€å·§

1ï¸âƒ£ åƒåŒäº‹ä¸€æ ·æ²Ÿé€š
åˆ«è¯´"å¸®æˆ‘X"ï¼Œè¯´"æˆ‘ä»¬ä¸€èµ·è§£å†³X"

2ï¸âƒ£ ç¬¬ä¸€æ¬¡å°±ç»™å®Œæ•´ä¸Šä¸‹æ–‡
ä¸Šä¼ é¡¹ç›®ç»“æ„ï¼Œä¸ç”¨åå¤è¯´

3ï¸âƒ£ å»ºç«‹æ ‡å‡†æµç¨‹
éœ€æ±‚â†’ä»£ç â†’æµ‹è¯•â†’æ–‡æ¡£ï¼Œä¸€å¥—æ¨¡æ¿

âŒ åˆ«æŒ‡æœ›ä¸€æ¬¡å®Œç¾ï¼Œè¦è¿­ä»£ä¼˜åŒ–

---

## ğŸ’¬ æ€»ç»“

ä¸æ˜¯AIå–ä»£ä½ ï¼Œæ˜¯ä¼šç”¨AIçš„äººå–ä»£ä½ ï¼æ—©ç”¨æ—©äº«å—ğŸ”¥

ğŸ”— æœç´¢ `{main_title}`

#AIç¼–ç¨‹ #ç¨‹åºå‘˜ #æ•ˆç‡ç¥å™¨
"""

        word_count = len(mock_content)
        emoji_count = len(re.findall(r'[ğŸš€ğŸ”¥ğŸ’¡âš¡âœ…ğŸ“ŠğŸ“ˆğŸ’°â±ï¸ğŸ¯ğŸ“ŒâŒâš ï¸ğŸš¨ğŸâœ¨ğŸ†ğŸ’ªğŸ‘‡ğŸ’¬ğŸ”„â¤ï¸ğŸ˜­ğŸ˜±]', mock_content))

        return {
            "title": f"7å¤©ä¸Šæ‰‹ï¼{main_title}çœŸé¦™ğŸ’¥",
            "full_content": mock_content,
            "hashtags": ["#AIç¼–ç¨‹", "#ç¨‹åºå‘˜", "#æ•ˆç‡ç¥å™¨"],
            "word_count": word_count,
            "original_article_word_count": article.get('word_count', 40000),
            "compression_ratio": f"{(1 - word_count / article.get('word_count', 40000)) * 100:.1f}%",
            "emoji_count": emoji_count,
            "note_type": "short",
            "target_word_count": 900
        }
