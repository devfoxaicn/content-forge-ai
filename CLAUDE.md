# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

**IMPORTANT**: Always run commands with PYTHONPATH set to the project root directory.

**Project Root**: `/Users/z/Documents/work/content-forge-ai` (adjust if different)

**Quick Setup**:
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Copy environment template
cp .env.example .env

# 3. Edit .env and add ZHIPUAI_API_KEY
# Get key from: https://open.bigmodel.cn/
```

## Quick Reference

**Essential Commands**:
```bash
# Set PYTHONPATH (required for all commands - adjust path to your project root)
export PYTHONPATH=/Users/z/Documents/work/content-forge-ai

# ========== Auto Mode (Chinese AI News Digest with Scoring) ==========
# Run once (recommended for daily AI news digest)
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode auto --once

# ========== Series Mode (Two 100-episode series: LLM + ML) ==========
# View progress (LLM series - default)
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode series --progress
# View progress (ML series)
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode series --progress --series-config config/ml_topics_100_complete.json
# Generate single episode (LLM series)
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode series --episode 1
# Generate single episode (ML series)
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode series --episode 1 --series-config config/ml_topics_100_complete.json
# Generate range
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python src/main.py --mode series --all --start 1 --end 10

# ========== Batch Generation (ML Series - Parallel Execution) ==========
# Run batch generation script (3 parallel processes)
./batch_generate_ml_series.sh

# ========== Tests ==========
cd test
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_ai_trends.py --source hackernews
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_storage.py
```

**Core Files**:
- `src/main.py` - Unified entry point (use `--mode` to switch)
- `src/auto_orchestrator.py` - LangGraph workflow orchestration (auto mode)
- `src/series_orchestrator.py` - Series mode orchestrator
- `src/state.py` - State definition (WorkflowState TypedDict)
- `src/agents/` - 20+ agent implementations (base, trend analyzers, generators, quality checkers)
- `src/utils/storage_v2.py` - Unified storage (StorageFactory)
- `src/utils/series_manager.py` - Series management tools
- `src/utils/api_config.py` - API configuration manager
- `src/utils/time_filter.py` - Time parsing utility (supports RSS/Atom/HTTP Date formats)
- `config/config.yaml` - Main config (LLM, agents, data sources) - **Note: Header shows v2.5 but actual implementation is v11.0**
- `config/blog_topics_100_complete.json` - LLM 100-episode content plan
- `config/ml_topics_100_complete.json` - ML 100-episode content plan
- `config/prompts.yaml` - Agent system prompt templates
- `docs/DATA_SOURCES.md` - Complete data source documentation (30 sources across 6 categories)
- `batch_generate_ml_series.sh` - Parallel ML episode generation (3 concurrent processes)
- `monitor_and_launch_next.sh` - Workflow monitoring with auto-launch

**Key Architecture Points**:
1. **Two-Mode Architecture** (only 2 implemented): Auto (Chinese digest), Series (200 episodes across 2 series)
2. **Dual Series Structure**: LLM Series (100 episodes) + ML Series (100 episodes)
3. **Auto Mode** (v11.0): 26 data sources â†’ concurrent fetch â†’ time-weighted â†’ fact-check â†’ content enhance â†’ translation refine â†’ 6-category organization â†’ 7-dimensional scoring â†’ å…¨ä¸­æ–‡ç®€æŠ¥
4. **Series Mode**: 8-agent quality pipeline with staged longform generation
5. **v9.2 Category System**: 6 categories (ğŸ“š å­¦æœ¯å‰æ²¿, ğŸ› ï¸ å¼€å‘å·¥å…·, ğŸ¦¾ AI Agent, ğŸ’¼ ä¼ä¸šåº”ç”¨, ğŸŒ æ¶ˆè´¹äº§å“, ğŸ“° è¡Œä¸šèµ„è®¯)
6. **Data Source Integration**: Integrated into `RealAITrendAnalyzerAgent` (NOT a separate `src/data_sources/` directory)
7. **DailyStorage**: Only creates `raw/` and `digest/` directories
8. **Immutable State Updates**: Use `{**state, **updates}` pattern
9. **Claude Code Skills**: `.claude/skills/` contains custom skills for enhanced Claude Code functionality

## Deployment Automation

**GitHub Actions** - Automated deployment (3x daily):
- **Schedule**: 6:00, 12:00, 18:00 Beijing Time (via `.github/workflows/daily-digest.yml`)
- **Workflow**: Runs auto mode â†’ commits changes â†’ pushes to GitHub â†’ triggers ai-insights sync
- **Timeout**: 90 minutes (configured in workflow YAML)
- **AI Insights Sync**: Uses repository_dispatch to trigger content sync to external repo (Ming-H/ai-insights)

**Commit Message Pattern**:
```bash
# Format used by GitHub Actions and run_and_commit.sh
feat: AIå†…å®¹è‡ªåŠ¨ç”Ÿæˆ - YYYY-MM-DD

ç”Ÿæˆæ—¶é—´: HH:MM:SS (åŒ—äº¬æ—¶é—´)

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**run_and_commit.sh** - Manual deployment script:
```bash
# Location: /path/to/content-forge-ai/run_and_commit.sh
# Purpose: Auto-generate content and commit to GitHub

# Script workflow:
# 1. Sets PYTHONPATH
# 2. Runs auto mode once: python src/main.py --mode auto --once
# 3. Stages data/ directory changes
# 4. Creates structured commit message with date
# 5. Pushes to remote repository
```

## Project Overview

ContentForge AI is a LangChain/LangGraph-based automated content production system that generates AI-focused content.

**Auto Mode** (v11.0):
- **Multiple Data Sources**: 26 enabled sources (TechCrunch, NewsAPI, Hacker News, MIT, OpenAI, BAIR, Microsoft Research, arXiv, MarkTechPost, KDnuggets, AI Business, The Gradient, InfoQ, Hugging Face, NewsData.io, Reddit, GitHub Trending, **AI News, The Decoder, é‡å­ä½, æœºå™¨ä¹‹å¿ƒ, Wired AI, VentureBeat AI, Google AI Blog, DeepMind Blog, arXiv CL/CV/LG, Reddit ML/AI RSS, Towards Data Science (v10.1)**)
- **9 Agents**: Concurrent Fetch â†’ Time Weight â†’ Auto Fact Check â†’ Content Enhancer â†’ Translation Refiner â†’ Trend Categorizer â†’ News Scoring â†’ World Class Digest (å…¨ä¸­æ–‡)
- **6 Categories** (v9.2): ğŸ“š å­¦æœ¯å‰æ²¿, ğŸ› ï¸ å¼€å‘å·¥å…·, ğŸ¦¾ AI Agent, ğŸ’¼ ä¼ä¸šåº”ç”¨, ğŸŒ æ¶ˆè´¹äº§å“, ğŸ“° è¡Œä¸šèµ„è®¯
- **Scoring System** (v11.0): 7-dimensional scoring (source_authority 25%, engagement 15%, freshness 25%, category_balance 10%, content_quality 15%, diversity 5%, fact_confidence 5%)
- **Time Filtering** (v9.2): No 24h restriction - prioritizes latest data by timestamp, filters only items without timestamps
- **Concurrent Fetch** (v11.0): 10x performance improvement with concurrent data fetching
- **Time Weight** (v11.0): Dynamic time-weighted scoring ensures latest content priority
- **Auto Fact Check** (v11.0): Lightweight fact-checking for Top 10 items using LLM built-in knowledge
- **Content Enhancer** (v11.0): Background and impact analysis for important news (score >= 70)
- **Translation Refiner** (v11.0): Strunk rules application for improved readability
- **Real-time Sources** (v10.0): NewsData.io (ç§’çº§æ›´æ–°), Reddit Stream (å®æ—¶ç¤¾åŒºè®¨è®º), GitHub Trending (å¼€å‘è€…å…³æ³¨)
- **Output**: `data/daily/YYYYMMDD/digest/digest_YYYYMMDD.md` (å…¨ä¸­æ–‡, with structured JSON)

**Series Mode**:
- **Two 100-episode series**: LLM Series (episodes 1-100) + ML Series (episodes 1-100)
- **8-agent quality pipeline**: research â†’ longform â†’ code review â†’ fact check â†’ quality evaluation â†’ consistency check â†’ visualization â†’ citation formatting
- **Staged longform generation** (outline â†’ sections â†’ summary)
- **Configurable via `--series-config` flag** to switch between LLM and ML series

## Environment Setup

**Required API Keys** (`.env`):
- `ZHIPUAI_API_KEY` - Primary LLM provider (https://open.bigmodel.cn/)

**Optional Keys** (existing):
- `TAVILY_API_KEY` - Web search (for ResearchAgent)
- `NEWSAPI_KEY` - NewsAPI.org data source
- `OPENAI_API_KEY` - Backup LLM

**Optional Keys** (NEW 2026-02-01):
- `PRODUCT_HUNT_API_KEY` - Product Hunt OAuth token (https://api.producthunt.com/v2/docs)
- `GITHUB_TOKEN` - GitHub Personal Access Token (https://github.com/settings/tokens)
- `HUGGINGFACE_TOKEN` - Hugging Face token (https://huggingface.co/settings/tokens)
- `SEMANTIC_SCHOLAR_API_KEY` - Semantic Scholar API key (https://www.semanticscholar.org/product/api)
- `OPENALEX_EMAIL` - OpenAlex email (free, recommended)
- `REDDIT_CLIENT_ID/SECRET` - Reddit API credentials (https://www.reddit.com/prefs/apps)

**Optional Keys** (NEW v10.0 - Real-time data sources):
- `NEWSDATA_IO_API_KEY` - NewsData.io real-time news API (æ¨è, free 200 requests/day, https://newsdata.io/register)
- `REDDIT_CLIENT_ID/SECRET` - Reddit Stream API for real-time community discussions (already listed above, same credentials)

**Dependencies**:
```bash
# Core dependencies from requirements.txt
pip install langgraph>=0.2.0 langchain>=0.3.0 langchain-openai>=0.2.0
pip install loguru pyyaml python-dotenv pydantic>=2.0.0
pip install arxiv>=2.1.0 feedparser>=6.0.10 praw>=7.7.0

# New data sources (2026-02-01)
pip install requests beautifulsoup4
```

**New Data Sources (2026-02-01)**:
The system now integrates **30 data sources** across 6 categories:
- **ğŸ“š Academic Frontier** (6): arXiv, Semantic Scholar, OpenAlex, Papers with Code, OpenReview, DBLP
- **ğŸ› ï¸ Dev Tools** (5): Hugging Face Hub, PyPI, npm, GitHub Releases, Framework RSS
- **ğŸ¦¾ AI Agent** (5): GitHub Trending, Product Hunt, Reddit AI, Hacker News, Awesome AI Agents
- **ğŸ’¼ Enterprise AI** (4): TechCrunch, VentureBeat, AI Business, InfoQ
- **ğŸŒ Consumer Apps** (4): Product Hunt, a16z Top 100, Hacker News, App Stores
- **ğŸ“° Industry News** (6): NewsAPI, MIT Review, The Gradient, MarkTechPost, Stanford HAI, Accenture

See `docs/DATA_SOURCES.md` for complete API documentation and implementation details.

## Auto Mode Architecture

**Workflow** (v11.0):
```
1. ConcurrentFetchAgent (v11.0: å¹¶å‘æ•°æ®è·å–ï¼Œ10å€æ€§èƒ½æå‡)
   - ä»26ä¸ªæ•°æ®æºå¹¶å‘è·å–çƒ­ç‚¹
   - ä¿ç•™æ‰€æœ‰å†…å®¹ï¼ˆä¸å»é‡ã€ä¸æ’åºï¼‰
   - è¾“å‡º: trends_by_source

2. TimeWeightAgent (v11.0: æ—¶æ•ˆæ€§æ™ºèƒ½åŠ æƒ)
   - åŠ¨æ€æ¨èæ—¶é—´æƒé‡ï¼ˆdynamic/linear/exponentialï¼‰
   - è¶…è¿‡72å°æ—¶æ–°é—»æ—¶æ•ˆåˆ†ä¸º0
   - 1å°æ—¶å†…æ–°é—»è·å¾—2å€åŠ æˆ
   - è¾“å‡º: time_weighted_trends

3. AutoFactCheckAgent (v11.0: è½»é‡çº§äº‹å®æ ¸æŸ¥)
   - ä»…æ ¸æŸ¥Top 10æ–°é—»
   - ä½¿ç”¨LLMå†…ç½®çŸ¥è¯†ï¼ˆæ— éœ€Tavilyï¼‰
   - ç½®ä¿¡åº¦é˜ˆå€¼0.7
   - è¾“å‡º: fact_checked_trends

4. ContentEnhancerAgent (v11.0: å†…å®¹å¢å¼º)
   - ä½¿ç”¨trafilaturaæå–å®Œæ•´å†…å®¹
   - ä¸ºé‡è¦æ€§>=70çš„æ–°é—»ç”ŸæˆèƒŒæ™¯åˆ†æ
   - ç”Ÿæˆå½±å“åˆ†æ
   - è¾“å‡º: enhanced_trends

5. TranslationRefinerAgent (v11.0: ç¿»è¯‘ç²¾ç‚¼)
   - åº”ç”¨StrunkåŸåˆ™æå‡å¯è¯»æ€§
   - æœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥
   - ç›®æ ‡å¯è¯»æ€§åˆ†æ•°60
   - è¾“å‡º: refined_trends

6. TrendCategorizerAgent (v9.2: 6åˆ†ç±»ç³»ç»Ÿ)
   - æŒ‰åˆ†ç±»ç»„ç»‡çƒ­ç‚¹
   - 6å¤§åˆ†ç±»ï¼šğŸ“š å­¦æœ¯å‰æ²¿, ğŸ› ï¸ å¼€å‘å·¥å…·, ğŸ¦¾ AI Agent, ğŸ’¼ ä¼ä¸šåº”ç”¨, ğŸŒ æ¶ˆè´¹äº§å“, ğŸ“° è¡Œä¸šèµ„è®¯
   - ä¼˜å…ˆæœ€æ–°æ•°æ®ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
   - Top5æˆªå–ï¼ˆæ¯ä¸ªåˆ†ç±»æœ€å¤š5æ¡ï¼‰
   - åªè¿‡æ»¤æ²¡æœ‰æ—¶é—´æˆ³çš„å†…å®¹ï¼ˆæ— 24hé™åˆ¶ï¼‰
   - è¾“å‡º: categorized_trends

7. NewsScoringAgent (v11.0: 7ç»´åº¦è¯„åˆ†)
   - å¯¹æ–°é—»è¿›è¡Œ7ç»´åº¦è¯„åˆ†
   - æ™ºèƒ½ç­›é€‰ï¼Œä¿ç•™é«˜ä»·å€¼å†…å®¹
   - è¾“å‡º: scored_trends

8. WorldClassDigestAgentV9
   - ç”Ÿæˆå…¨ä¸­æ–‡ä¸–ç•Œé¡¶çº§æ–°é—»ç®€æŠ¥
   - ç¿»è¯‘æ‰€æœ‰æ ‡é¢˜ã€æè¿°
   - ç”Ÿæˆæ ¸å¿ƒæ´å¯Ÿå’Œæ·±åº¦è§‚å¯Ÿ
   - è¾“å‡º: news_digest (å…¨ä¸­æ–‡ + ç»“æ„åŒ–JSON)
```

**Data Sources** (26 enabled sources):
| æ•°æ®æº | ç±»å‹ | å†…å®¹ | ç‰ˆæœ¬ |
|--------|------|------|------|
| TechCrunch AI | æ–°é—» | AIè¡Œä¸šæ–°é—»RSS | - |
| NewsAPI.org | æ–°é—» | å…¨çƒAIæ–°é—»èšåˆï¼ˆéœ€API keyï¼‰ | - |
| Hacker News | ç¤¾åŒº | ç§‘æŠ€çƒ­ç‚¹è®¨è®ºAPI | - |
| MIT Tech Review | æ–°é—» | MITæŠ€æœ¯è¯„è®ºRSS | - |
| OpenAI Blog | å®˜æ–¹ | OpenAIå®˜æ–¹åŠ¨æ€RSS | - |
| BAIR Blog | å­¦æœ¯ | UC Berkeley AIç ”ç©¶RSS | - |
| Microsoft Research | å­¦æœ¯ | å¾®è½¯ç ”ç©¶é™¢åšå®¢RSS | - |
| arXiv | å­¦æœ¯ | AIé‡å¤§è®ºæ–‡API | - |
| MarkTechPost | æ–°é—» | AIç ”ç©¶æ–°é—»RSS | - |
| KDnuggets | æ–°é—» | æ•°æ®ç§‘å­¦æƒå¨RSS | - |
| AI Business | æ–°é—» | AIè¡Œä¸šæ–°é—»RSS | - |
| The Gradient | æœŸåˆŠ | AIç ”ç©¶æœŸåˆŠRSS | - |
| InfoQ AI | æŠ€æœ¯ | æŠ€æœ¯åª’ä½“RSS | - |
| Hugging Face | å®˜æ–¹ | Hugging Faceå®˜æ–¹åšå®¢RSS | - |
| **NewsData.io** â­ | **å®æ—¶** | **ç§’çº§æ–°é—»æ›´æ–°ï¼ˆå…è´¹200æ¬¡/å¤©ï¼‰** | **v10.0** |
| **Reddit Stream** â­ | **å®æ—¶** | **ç¤¾åŒºå®æ—¶è®¨è®ºï¼ˆr/MachineLearningç­‰ï¼‰** | **v10.0** |
| **GitHub Trending** â­ | **å®æ—¶** | **å¼€å‘è€…å…³æ³¨çƒ­ç‚¹** | **v10.0** |
| **AI News** | æ–°é—» | é¡¶çº§AIæ–°é—»åª’ä½“ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **The Decoder** | æ–°é—» | AIä¸“ä¸šæ–°é—»ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **é‡å­ä½ (qbitai)** | æ–°é—» | ä¸­æ–‡AIç¬¬ä¸€åª’ä½“ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **æœºå™¨ä¹‹å¿ƒ (jiqizhixin)** | æ–°é—» | æ·±åº¦AIæŠ¥é“ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **Wired AI** | æ–°é—» | AIä¸“é¢˜æ–°é—»ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **VentureBeat AI** | æ–°é—» | AIå•†ä¸šæ–°é—»ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **Google AI Blog** | å®˜æ–¹ | Google AIå®˜æ–¹åŠ¨æ€ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **DeepMind Blog** | å­¦æœ¯ | Google DeepMindé¡¶çº§ç ”ç©¶ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **arXiv CL/CV/LG** | å­¦æœ¯ | NLP/CV/MLè®ºæ–‡ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **Reddit ML/AI RSS** | ç¤¾åŒº | ML/AIè®¨è®ºç¤¾åŒºï¼ˆå…è´¹RSSï¼‰ | **v10.1** |
| **Towards Data Science** | æ–°é—» | æ•°æ®ç§‘å­¦æ–‡ç« ï¼ˆå…è´¹RSSï¼‰ | **v10.1** |

**Scoring System** (NewsScoringAgent v11.0):
- `source_authority` (25%): æ¥æºæƒå¨åº¦ï¼ŒåŸºäºé¢„å®šä¹‰è¯„åˆ†è¡¨
- `engagement` (15%): äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€è¯„è®ºã€åˆ†äº«ï¼‰
- `freshness` (25%): æ—¶æ•ˆæ€§ï¼ˆ24å°æ—¶å†…å‘å¸ƒåŠ åˆ†ï¼‰â¬†ï¸
- `category_balance` (10%): ç¡®ä¿å„åˆ†ç±»å¹³è¡¡
- `content_quality` (15%): æ ‡é¢˜è´¨é‡ã€å†…å®¹å®Œæ•´æ€§â¬†ï¸
- `diversity` (5%): ç¡®ä¿æ¥æºå¤šæ ·æ€§
- `fact_confidence` (5%): äº‹å®ç½®ä¿¡åº¦ï¼ˆæ–°å¢ï¼‰â¬†ï¸

**Output Format**:
```markdown
# AIæ¯æ—¥çƒ­ç‚¹ Â· 2026å¹´02æœˆ03æ—¥

## ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿ
- å¤šæ™ºèƒ½ä½“åä½œèŒƒå¼ç¡®ç«‹...

## ğŸ“° æ·±åº¦è§‚å¯Ÿ
**AIäº§ä¸šè§‚å¯Ÿï¼šä»äº‘ç«¯ç«é€åˆ°ç«¯ä¾§é‡æ„çš„èŒƒå¼è½¬ç§»**

## ğŸ” æœ¬æœŸçƒ­ç‚¹
### ğŸ“š å­¦æœ¯å‰æ²¿ï¼ˆ5æ¡ï¼Œä¼˜å…ˆæœ€æ–°ï¼‰
#### [æ®æŠ¥Appleç ”å‘AIå¯ç©¿æˆ´è®¾å¤‡](é“¾æ¥)
**æ¥æº**ï¼šTechCrunch AI  Â·  **çƒ­åº¦**ï¼š70  Â·  **è¯„åˆ†**ï¼š82
...
```

## ML Series Architecture

The ML Series (`config/ml_topics_100_complete.json`) provides 100 episodes covering machine learning and deep learning, organized into 10 sub-series:

**ML Series Structure**:
| Sub-series | Episodes | Focus |
|------------|----------|-------|
| `ml_series_1_foundation` | 1-10 | æœºå™¨å­¦ä¹ åŸºç¡€ (Math foundations, algorithms) |
| `ml_series_2_deep_learning` | 11-20 | æ·±åº¦å­¦ä¹ åŸºç¡€ (Neural networks, training) |
| `ml_series_3_computer_vision` | 21-30 | è®¡ç®—æœºè§†è§‰ (CNNs, image processing) |
| `ml_series_4_nlp` | 31-40 | è‡ªç„¶è¯­è¨€å¤„ç† (Text processing, NLP basics) |
| `ml_series_5_rl` | 41-50 | å¼ºåŒ–å­¦ä¹  (RL agents, policies) |
| `ml_series_6_recommendation` | 51-60 | æ¨èç³»ç»Ÿ (Collaborative filtering, deep learning) |
| `ml_series_7_optimization` | 61-70 | æ¨¡å‹ä¼˜åŒ– (Hyperparameter tuning) |
| `ml_series_8_traditional_ml` | 71-80 | ä¼ ç»Ÿæœºå™¨å­¦ä¹  (SVM, trees, clustering) |
| `ml_series_9_feature_eng` | 81-90 | ç‰¹å¾å·¥ç¨‹ (Feature selection, extraction) |
| `ml_series_10_advanced` | 91-100 | é«˜çº§MLä¸»é¢˜ (Ensemble, interpretability) |

**Storage Structure for ML Series**:
```
data/series/ML_series/
â”œâ”€â”€ ml_series_1_ml_foundation/
â”‚   â”œâ”€â”€ episode_001/
â”‚   â”‚   â””â”€â”€ longform/
â”‚   â”‚       â””â”€â”€ ep001_..._article.md
â”‚   â””â”€â”€ series_metadata.json
â””â”€â”€ ...
```

**Path Management**: ML series use `ml_series_X` IDs with paths managed by `SeriesPathManager`. The category is automatically detected (`get_series_category()` returns "ML_series" for `ml_series_*` IDs).

## Batch Generation Scripts

**`batch_generate_ml_series.sh`** - Parallel ML episode generation:
```bash
# Run batch generation (3 parallel processes by default)
./batch_generate_ml_series.sh

# Features:
# - Configurable parallelism (PARALLELISM=3)
# - PID tracking for process management
# - Automatic retry on failure
# - Progress logging to logs/batch_generate/
# - Episode list configurable via EPISODES array
```

**`monitor_and_launch_next.sh`** - Workflow monitoring script:
```bash
# Monitors running tasks and auto-launches next episodes
# when previous ones complete
./monitor_and_launch_next.sh

# Features:
# - Checks task completion by scanning output files
# - Auto-launches next episodes from NEXT_EPISODES array
# - 30-second polling interval
# - Marks completed/failed tasks for tracking
```

## Command Reference

**Auto Mode**:
- `--mode auto --once` - ç”Ÿæˆä¸€æ¬¡ç®€æŠ¥
- `--topic STR` - æ–‡ä»¶å‘½åï¼ˆä¸å½±å“å†…å®¹ï¼‰

**Series Mode**:
- `--mode series --progress` - æŸ¥çœ‹è¿›åº¦
- `--mode series --episode INT` - ç”ŸæˆæŒ‡å®šé›†
- `--mode series --episode INT --series-config PATH` - ç”ŸæˆæŒ‡å®šç³»åˆ— (LLM/ML)
- `--mode series --all` - ç”Ÿæˆå…¨éƒ¨
- `--start INT` - Start episode (default: 1)
- `--end INT` - End episode (default: 100)
- `--series-config PATH` - æŒ‡å®šé…ç½®æ–‡ä»¶ (default: `config/blog_topics_100_complete.json`)

## Architecture Overview

### Big Picture: Multi-Orchestrator Architecture

This system uses a **multi-orchestrator pattern** where each mode has its own orchestrator implementing a different content generation strategy:

```
src/main.py (CLI entry point)
    â”‚
    â”œâ”€â†’ AutoContentOrchestrator (src/auto_orchestrator.py)
    â”‚   â””â”€â†’ LangGraph StateGraph workflow
    â”‚       â””â”€â†’ Agent chain: trend_analyzer â†’ categorizer â†’ scorer â†’ digest
    â”‚
    â””â”€â†’ SeriesOrchestrator (src/series_orchestrator.py)
        â””â”€â†’ Sequential execution with error recovery
            â””â”€â†’ Agent chain: research â†’ longform â†’ quality check â†’ social content
```

**Key Insight**: The LangGraph StateGraph in Auto mode vs sequential execution in Series mode represents a fundamental architectural difference - Auto mode uses graph-based state management while Series mode uses traditional sequential flows.

### Design Patterns

**1. Multi-Orchestrator Pattern**
- Two orchestrators implement different content generation strategies
- Runtime switching via strategy pattern
- Each manages its own workflow and storage

**2. Factory Pattern**
- `StorageFactory` creates storage instances based on mode
- Supports: `DailyStorage` (by date) and `SeriesStorage` (by series)

**3. Chain of Responsibility**
- LangGraph workflow implements agent chain
- Each agent processes and passes state
- Immutable state updates: `{**state, **updates}`

**4. Template Method Pattern**
- All agents inherit from `BaseAgent`
- Implement standard `execute(state: Dict) -> Dict` interface
- Unified logging, error handling, LLM calls

### Two-Orchestrator Comparison

| Feature | AutoContentOrchestrator | SeriesOrchestrator |
|---------|-------------------------|-------------------|
| **File** | `src/auto_orchestrator.py` | `src/series_orchestrator.py` |
| **Data Source** | Multiple real-time APIs | 100 preset topics |
| **Trigger** | Scheduled or manual | Manual execution |
| **Storage** | `data/daily/YYYYMMDD/` | `data/series/{id}/episode_{xxx}/` |
| **Output** | Raw data + Digest | Longform articles |
| **Workflow** | LangGraph graph execution | Sequential with error recovery |
| **State Fields** | Uses `trends_by_source` | Uses `current_topic` + `selected_ai_topic` |
| **Primary Use** | Daily trend tracking | Systematic content library |
| **Storage Format** | `YYYYMMDD/` | `series_X_name/episode_XXX/` |

### Auto Workflow Agent Chain

The LangGraph StateGraph builds a directed acyclic graph (DAG) of agents:

```python
# From src/auto_orchestrator.py:_build_workflow()
workflow = StateGraph(dict)
workflow.add_entry_point("ai_trend_analyzer")
workflow.add_edge("ai_trend_analyzer", "trend_categorizer")
workflow.add_edge("trend_categorizer", "news_scoring")
workflow.add_edge("news_scoring", "world_class_digest")
workflow.add_edge("world_class_digest", END)
```

**Data Flow**:
```
ai_trend_analyzer (multiple data sources aggregation)
  â†“ state["trends_by_source"] = {...}

trend_categorizer (v9.2: 6å¤§åˆ†ç±»é‡æ–°ç»„ç»‡ + ä¼˜å…ˆæœ€æ–° + Top5æˆªå–)
  â†“ state["categorized_trends"] = {...}

news_scoring (v7.0: 6ç»´åº¦æ™ºèƒ½è¯„åˆ†ç­›é€‰)
  â†“ state["scored_trends"] = {...}

world_class_digest_v9 (ç”Ÿæˆå…¨ä¸­æ–‡ä¸–ç•Œé¡¶çº§æ–°é—»ç®€æŠ¥)
  â†“ state["news_digest"] = {...}
```

### Storage Structure

```
data/
â”œâ”€â”€ daily/                     # Autoæ¨¡å¼
â”‚   â””â”€â”€ YYYYMMDD/
â”‚       â”œâ”€â”€ raw/              # åŸå§‹æ•°æ®ï¼ˆæŒ‰æ•°æ®æºï¼‰
â”‚       â””â”€â”€ digest/           # å…¨ä¸­æ–‡ç®€æŠ¥
â”‚           â”œâ”€â”€ digest_YYYYMMDD.md
â”‚           â””â”€â”€ digest_YYYYMMDD.json
â”‚
â””â”€â”€ series/                    # Seriesæ¨¡å¼
    â””â”€â”€ {series_id}/
        â””â”€â”€ episode_{xxx}/
            â””â”€â”€ longform/     # é•¿æ–‡æœ¬æ–‡ç« 
```

**Note**: Only Auto and Series modes are implemented. Custom/Refine modes documented in config.yaml are NOT available in the current codebase.

### AI Trend Data Sources (config.yaml:69-105)

**Currently Enabled (26 sources)**:
- `techcrunch_ai` - TechCrunch AI RSS
- `newsapi` - NewsAPI.org (å…¨çƒAIæ–°é—»èšåˆ)
- `hackernews` - Hacker News API
- `mit_tech_review` - MIT Technology Review RSS
- `openai_blog` - OpenAI Blog RSS
- `bair_blog` - Berkeley AI Research Blog (é¡¶çº§å­¦æœ¯)
- `microsoft_research` - Microsoft Research Blog (å®˜æ–¹)
- `arxiv_news` - arXiv API
- `marktechpost` - MarkTechPost (AIç ”ç©¶æ–°é—»)
- `kdnuggets` - KDnuggets (æ•°æ®ç§‘å­¦æƒå¨)
- `ai_business` - AI Business (è¡Œä¸šæ–°é—»)
- `the_gradient` - The Gradient (AIç ”ç©¶æœŸåˆŠ)
- `infoq_ai` - InfoQ AI (æŠ€æœ¯åª’ä½“)
- `hugging_face_blog` - Hugging Face Blog (å®˜æ–¹)
- **`newsdata_io`** â­ - **NewsData.io (å®æ—¶æ–°é—»APIï¼Œç§’çº§æ›´æ–°ï¼Œå…è´¹200æ¬¡/å¤©ï¼Œv10.0æ–°å¢)**
- **`reddit_stream`** â­ - **Reddit (å®æ—¶ç¤¾åŒºè®¨è®ºï¼Œr/MachineLearningç­‰ï¼Œv10.0æ–°å¢)**
- **`github_trending`** â­ - **GitHub Trending (å¼€å‘è€…å…³æ³¨çƒ­ç‚¹ï¼Œv10.0æ–°å¢)**
- **`ai_news`** â­ - **AI News (é¡¶çº§AIæ–°é—»åª’ä½“ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`the_decoder`** â­ - **The Decoder (AIä¸“ä¸šæ–°é—»ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`qbitai`** â­ - **é‡å­ä½ (ä¸­æ–‡AIç¬¬ä¸€åª’ä½“ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`jiqizhixin`** â­ - **æœºå™¨ä¹‹å¿ƒ (æ·±åº¦AIæŠ¥é“ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`wired_ai_v2`** â­ - **Wired AI (AIä¸“é¢˜æ–°é—»ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`venturebeat_ai_v2`** â­ - **VentureBeat AI (AIå•†ä¸šæ–°é—»ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`google_ai_blog_v2`** â­ - **Google AI Blog (å®˜æ–¹AIåŠ¨æ€ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`deepmind_blog_v2`** â­ - **Google DeepMind (é¡¶çº§ç ”ç©¶ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`arxiv_cl`** â­ - **arXiv NLP (è‡ªç„¶è¯­è¨€å¤„ç†è®ºæ–‡ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`arxiv_cv`** â­ - **arXiv CV (è®¡ç®—æœºè§†è§‰è®ºæ–‡ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`arxiv_lg`** â­ - **arXiv ML (æœºå™¨å­¦ä¹ è®ºæ–‡ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`reddit_ml_rss`** â­ - **Reddit ML (æœºå™¨å­¦ä¹ ç¤¾åŒºï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`reddit_ai_rss`** â­ - **Reddit AI (AIè®¨è®ºç¤¾åŒºï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**
- **`towards_data_science`** â­ - **Towards Data Science (æ•°æ®ç§‘å­¦æ–‡ç« ï¼Œå…è´¹RSSï¼Œv10.1æ–°å¢)**

**Config Params** (`config/config.yaml:108-110`):
- `max_trends: 20` - Max trend count per source
- `min_heat_score: 60` - Minimum heat score
- `cache_ttl: 3600` - Cache TTL (seconds)

**Data Source Implementation**: Sources are integrated into `RealAITrendAnalyzerAgent` in `src/agents/ai_trend_analyzer_real.py`.

**Adding New Sources**:
```python
# Add new source logic in RealAITrendAnalyzerAgent._fetch_all_trends()
# Return format: [{"title": "...", "url": "...", ...}]
```

## Core Patterns

### Agent Implementation Pattern

All agents inherit from `BaseAgent` (`src/agents/base.py:22`), implementing `execute()`:

```python
from src.agents.base import BaseAgent
from typing import Dict, Any

class NewAgent(BaseAgent):
    def __init__(self, config: Dict[str, Any], prompts: Dict[str, Any]):
        super().__init__(config, prompts)

    def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        try:
            # Agent logic
            result = self._call_llm("Your prompt")
            return {**state, "new_field": result}
        except Exception as e:
            self.log(f"Error: {e}", "ERROR")
            return {
                **state,
                "error_message": str(e),
                "current_step": "new_agent_failed"
            }
```

**Key Methods**:
- `_call_llm(prompt: str) -> str` - Call LLM (internal)
- `log(message: str, level: str = "INFO")` - Log with loguru
- `_load_system_prompt() -> str` - Load system prompt (from `config/prompts.yaml`)
- `_init_llm() -> ChatOpenAI` - Initialize LLM (supports ZhipuAI/OpenAI)

### LLM Provider Switching

Multiple LLM providers supported via `config/config.yaml` `llm.provider`:

```yaml
llm:
  provider: "zhipuai"  # or "openai"
  zhipuai:
    model: "glm-4.7"  # Latest flagship
    # Other options: glm-4-flash (cheap fast), glm-4-plus (prev flagship)
    base_url: "https://open.bigmodel.cn/api/coding/paas/v4/"  # Coding endpoint
    thinking:
      enabled: false  # Enable deep thinking mode (GLM-4.7 exclusive)
      type: "auto"    # "auto" or "enabled"
  openai:
    model: "gpt-4o"
    base_url: "https://api.openai.com/v1"
```

**GLM-4.7 Thinking Mode** (`config/config.yaml:17-19`):
- `thinking.enabled`: Enable deep thinking mode (GLM-4.7 exclusive feature)
- `thinking.type`: "auto" (auto-trigger) or "enabled" (force enable)
- Improves reasoning quality for complex tasks

**Research Agent Options** (`config/config.yaml:95-100`):
- `search_provider`: "tavily" (default, paid service), "zhipuai" (included in annual plan, recommended), "mock" (offline)
- `max_results`: Maximum search results
- `search_depth`: "basic" or "advanced"
- `mock_mode`: Set to `true` to disable all search APIs

**API Config Management**: `src/utils/api_config.py` provides `APIConfigManager` for unified API key/endpoint management.

```python
from src.utils.api_config import get_api_config

api_config = get_api_config()
zhipu_key = api_config.get_api_key("zhipuai")
tavily_key = api_config.get_api_key("tavily")
base_url = api_config.get_endpoint("llm.zhipuai.base_url")

# Supports both env vars and config.yaml
# Priority: env vars > config.yaml > defaults
```

### Unified Storage System

`src/utils/storage_v2.py` provides unified storage based on factory pattern:

**Storage Structure**:
```
data/
â”œâ”€â”€ daily/                    # Auto mode (trends + digest)
â”‚   â””â”€â”€ YYYYMMDD/
â”‚       â”œâ”€â”€ raw/
â”‚       â””â”€â”€ digest/
â”‚
â””â”€â”€ series/                   # Series mode (100-episode blog series)
    â””â”€â”€ {series_id}/
        â”œâ”€â”€ episode_{xxx}/
        â”‚   â””â”€â”€ longform/
        â””â”€â”€ series_metadata.json
```

**Usage**:
```python
from src.utils.storage_v2 import StorageFactory

# Auto mode (daily trends)
daily_storage = StorageFactory.create_daily()
daily_storage.save_markdown("digest", "digest.md", content)

# Series mode (100-episode series)
series_storage = StorageFactory.create_series(
    series_id="series_1",  # ä½¿ç”¨åŸºç¡€IDï¼Œå†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†ç›®å½•å
    episode_number=1
)
series_storage.save_article(content, title="æ–‡ç« æ ‡é¢˜")  # ç›´æ¥ä¿å­˜åˆ°episodeç›®å½•
series_storage.save_episode_metadata(metadata)
```

**Note**: Custom and Refine modes are defined in storage_v2.py but are NOT used by the current codebase. Only Auto and Series modes are implemented.

**Series Metadata Management**:
```python
from src.utils.series_manager import get_series_metadata, print_progress_summary

metadata = get_series_metadata("config/blog_topics_100_complete.json")
topic = metadata.get_topic_by_episode(1)
series = metadata.get_series_by_id("series_1")
metadata.update_topic_status("topic_001", "completed")
print_progress_summary()
```

### File Naming Convention (TopicFormatter)

`TopicFormatter` (`src/utils/series_manager.py:201`) provides unified file naming:

```python
from src.utils.series_manager import TopicFormatter

prefix = TopicFormatter.generate_filename_prefix(topic)
# Returns: ep001_llm_transformer_attention_mechanism

filename = TopicFormatter.generate_markdown_filename(topic, "article")
# Returns: ep001_llm_transformer_attention_mechanism_article.md

summary = TopicFormatter.format_topic_summary(topic)
# Output: âœ… Episode 001 | LLMçš„Transformeræ¶æ„ä¸æ³¨æ„åŠ›æœºåˆ¶ [series_1]
```

### Series Path Management (SeriesPathManager)

`SeriesPathManager` (`src/utils/series_manager.py`) manages series folder naming:

```python
from src.utils.series_manager import SeriesPathManager

path = SeriesPathManager.get_series_path("series_1")
# Returns: "series_1_llm_foundation"

series_id = SeriesPathManager.get_series_id_from_path("series_1_llm_foundation")
# Returns: "series_1"
```

**Series Folder Format**: `series_X_descriptive_name` (v2.5 improvement for semantic paths)

**LLM Series List** (episodes 1-100):
- `series_1_llm_foundation` (1-10) - LLM Principles
- `series_2_rag_technique` (11-18) - RAG Practice
- `series_3_agent_development` (19-26) - Agent Development
- `series_4_prompt_engineering` (27-32) - Prompt Engineering
- `series_5_model_deployment` (33-40) - Model Deployment
- `series_6_multimodal_frontier` (41-50) - Multimodal Frontiers
- `series_7_ai_coding_tools` (51-60) - AI Coding Tools
- `series_8_ai_data_engineering` (61-70) - AI Data Engineering
- `series_9_ai_applications` (71-85) - AI Application Scenarios
- `series_10_ai_infrastructure` (86-100) - AI Infrastructure

**ML Series List** (episodes 1-100):
- `ml_series_1_ml_foundation` (1-10) - æœºå™¨å­¦ä¹ åŸºç¡€
- `ml_series_2_deep_learning_foundation` (11-20) - æ·±åº¦å­¦ä¹ åŸºç¡€
- `ml_series_3_computer_vision` (21-30) - è®¡ç®—æœºè§†è§‰
- `ml_series_4_natural_language_processing` (31-40) - è‡ªç„¶è¯­è¨€å¤„ç†
- `ml_series_5_reinforcement_learning` (41-50) - å¼ºåŒ–å­¦ä¹ 
- `ml_series_6_recommendation_systems` (51-60) - æ¨èç³»ç»Ÿ
- `ml_series_7_model_optimization` (61-70) - æ¨¡å‹ä¼˜åŒ–
- `ml_series_8_traditional_ml` (71-80) - ä¼ ç»Ÿæœºå™¨å­¦ä¹ 
- `ml_series_9_feature_engineering` (81-90) - ç‰¹å¾å·¥ç¨‹
- `ml_series_10_advanced_ml_topics` (91-100) - é«˜çº§MLä¸»é¢˜

**Series Path Mapping** (hardcoded): `src/utils/series_manager.py:156-179` (SeriesPathManager.SERIES_NAME_MAP)

**Important**: Adding new series requires updating both:
1. `config/blog_topics_100_complete.json` or `config/ml_topics_100_complete.json` - Add series info and topics
2. `SeriesPathManager.SERIES_NAME_MAP` - Add path mapping

**Category Detection**: `SeriesPathManager.get_series_category()` automatically detects whether a series is LLM or ML based on the `series_id` prefix:
- `series_*` â†’ "LLM_series"
- `ml_series_*` â†’ "ML_series"

### Claude Code Skills Directory

**`.claude/skills/`** - Custom Claude Code skills for enhanced functionality:

Skills are reusable capabilities that extend Claude Code's functionality. Each skill directory contains:
- `skill.md` - Skill definition and usage instructions
- Implementation code or configuration

**Available Skills** (from git status):
- `content-research-writer` - Research and citation assistance
- `copy-editing` - Marketing copy review and improvement
- `copywriting` - Marketing copy generation
- `email-sequence` - Email campaign automation
- `marketing-psychology` - Psychological principles for marketing
- `notebooklm` - Google NotebookLM integration
- `platform-adaptation` - Content adaptation for Chinese platforms
- `scriptwriting` - Screenplay and script writing
- `social-content` - Social media content management
- `writing-clearly-and-concisely` - Strunk's writing rules
- `x-article-publisher` - X (Twitter) Articles publishing

**Using Skills**:
```bash
# List available skills
ls .claude/skills/

# Skills are automatically loaded by Claude Code
# Invoke with /<skill-name> command in Claude Code
```

### LangGraph State Management

`WorkflowState` TypedDict (`src/state.py:61`) manages shared state between agents:

```python
from src.state import create_initial_state, update_state

state = create_initial_state(
    topic=None,  # or "AIæŠ€æœ¯" (file naming only)
    target_audience="æŠ€æœ¯ä»ä¸šè€…",
    content_type="å¹²è´§åˆ†äº«"
)

new_state = update_state(state, {"new_field": value})
```

**LangGraph Node Wrapper** (`src/auto_orchestrator.py:171-184`):
```python
def _create_agent_node(self, agent):
    def node_function(state):
        try:
            result = agent.execute(state)
            return add_agent_to_order(result, agent.name)
        except Exception as e:
            return update_state(state, {
                "error_message": str(e),
                "current_step": f"{agent.name}_failed"
            })
    return node_function
```

**Critical State Pattern**: All agents must return a complete state dict using the immutable pattern `{**state, **updates}`. The LangGraph workflow automatically merges each node's output into the shared state.

## Workflow Execution Order

**AutoContentOrchestrator** (LangGraph mode): Workflow defined in `src/auto_orchestrator.py:_build_workflow()`

**SeriesOrchestrator** (sequential mode): Workflow in `src/series_orchestrator.py:_execute_workflow()` with safety wrappers and delays

**SeriesOrchestrator Safe Execution** (`src/series_orchestrator.py:248-262`):
```python
def _call_agent_safely(agent_name: str, state: Dict[str, Any]) -> Dict[str, Any]:
    try:
        result = self.agents[agent_name].execute(state)
        time.sleep(2)  # Delay to avoid API rate limits
        return result
    except Exception as e:
        logger.error(f"[{agent_name}] Failed: {e}")
        time.sleep(2)
        return state  # Return original state, allow continuation
```

**Execution Order**:
- **Auto Mode** (v11.0): Concurrent fetch â†’ Time weight â†’ Auto fact check â†’ Content enhancer â†’ Translation refiner â†’ Trend categorizer â†’ News scoring â†’ World class digest
- **Series Mode**: Research â†’ Longform generation â†’ Code review â†’ Fact check â†’ Quality evaluation â†’ Consistency check â†’ Visualization â†’ Citation formatting

**Prompt Template System**: Each agent's system prompts stored in `config/prompts.yaml`, organized by lowercase agent class name

### Agent Dependencies

**Auto Mode Agents (v11.0)**:
| Agent | Deps On | Outputs | Description |
|-------|---------|---------|-------------|
| concurrent_fetch | - | trends_by_source | 26 data source concurrent aggregation (v11.0) |
| time_weight | trends_by_source | time_weighted_trends | Dynamic time-weighted scoring (v11.0) |
| auto_fact_check | time_weighted_trends | fact_checked_trends | Top 10 fact-checking using LLM (v11.0) |
| content_enhancer | fact_checked_trends | enhanced_trends | Background/impact analysis (v11.0) |
| translation_refiner | enhanced_trends | refined_trends | Strunk rules + terminology check (v11.0) |
| trend_categorizer | refined_trends | categorized_trends | 6-category organization (v9.2) |
| news_scoring | categorized_trends | scored_trends | 7-dimensional scoring (v11.0) |
| world_class_digest_v9 | scored_trends | news_digest | Chinese digest + JSON |

**Series Mode Agents**:
| Agent | Deps On | Outputs | Description |
|-------|---------|---------|-------------|
| research_agent | selected_ai_topic | research_data, research_summary | Web search background |
| longform_generator | selected_ai_topic, research_data | longform_article | Core content (staged) |
| code_review_agent | longform_article | code_review_result | Quality assurance |
| fact_check_agent | longform_article | fact_check_result | Fact verification |
| quality_evaluator_agent | longform_article | quality_report | Comprehensive evaluation |
| consistency_checker_agent | longform_article | consistency_report | Terminology/citation check |
| visualization_generator_agent | longform_article | mermaid_diagrams | Auto-generate diagrams |
| citation_formatter_agent | longform_article | formatted_citations | GB/T 7714-2015 format |

**Available Exported Agents** (from `src/agents/__init__.py`):
- BaseAgent
- RealAITrendAnalyzerAgent
- TrendsDigestAgent
- LongFormGeneratorAgent
- TitleOptimizerAgent
- ImageGeneratorAgent

**Note**: Many agent files exist in `src/agents/` (16 total) but are NOT exported in `__init__.py`. Agents like `XiaohongshuRefinerAgent` and `TwitterGeneratorAgent` were removed during Refine/Custom mode cleanup. To use additional agents, manually import them from their modules.

### Critical Notes

1. **Agent Import Requirement**: Only 6 agents are exported by default. To use quality assurance agents (code_review, fact_check, etc.), import directly: `from src.agents.code_review_agent import CodeReviewAgent`

2. **Longform Generator Needs Research Data**: `longform_generator` prioritizes `research_data`; if unavailable, generates based only on `selected_ai_topic`

3. **Series Mode State Field Special Handling**: Must set both `current_topic` and `selected_ai_topic` for compatibility (`src/series_orchestrator.py:_initialize_state()`)

4. **Staged Generation Avoids Timeout**: `LongFormGeneratorAgent` uses three-stage generation (outline â†’ section expansion â†’ summary), each stage independent LLM call (`src/agents/longform_generator.py:73`)

## Development Guide

### Adding New Agents

**AutoContentOrchestrator Mode**:
1. Create agent class (`src/agents/new_agent.py`) inheriting `BaseAgent`
2. Implement `execute(self, state: Dict[str, Any]) -> Dict[str, Any]`
3. Add config in `config/config.yaml` under `agents`
4. Initialize in `src/auto_orchestrator.py` `_init_agents()`
5. Add to LangGraph workflow in `_build_workflow()`

**SeriesOrchestrator Mode**:
1. Create agent class as above
2. Add to `agent_classes` dict in `src/series_orchestrator.py` `_init_agents()`
3. Add call logic in `_execute_workflow()`

**Important**: Agents must return complete state dict using `{**state, "new_field": value}` pattern.

### Common State Fields

| State Field | Written By | Read By | Description |
|-------------|------------|----------|-------------|
| `trends_by_source` | ai_trend_analyzer | trend_categorizer | Raw trends by source (Auto mode) |
| `categorized_trends` | trend_categorizer | news_scoring | 5-category organized trends |
| `scored_trends` | news_scoring | world_class_digest_v8 | Scored and filtered trends |
| `news_digest` | world_class_digest_v8 | - | Final Chinese digest |
| `research_data` | research_agent | longform_generator | Web search research data |
| `selected_ai_topic` | series_orchestrator | longform_generator | Selected AI topic |
| `current_topic` | series_orchestrator | - | Current topic (Series mode) |
| `longform_article` | longform_generator | quality agents | Longform article |
| `error_message` | Any agent | - | Error info |
| `current_step` | Any agent | - | Current step |
| `execution_time` | orchestrator | - | Execution time stats |
| `agent_execution_order` | orchestrator | - | Agent execution order |

**Note**: `WorkflowState` TypedDict defines possible fields, but actual usage is plain Dict. Auto mode uses `trends_by_source`â†’`categorized_trends`â†’`scored_trends` flow; Series mode uses `current_topic` and `selected_ai_topic`. State updates use immutable pattern: `{**state, **updates}`.

### Error Handling Pattern

**Agent-level Error Handling**:
```python
def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
    try:
        result = self._call_llm("Your prompt")
        return {**state, "new_field": result}
    except Exception as e:
        self.log(f"Error: {e}", "ERROR")
        return {
            **state,
            "error_message": str(e),
            "current_step": "new_agent_failed"
        }
```

**Series Mode Safe Execution** (`src/series_orchestrator.py:248`):
```python
def _call_agent_safely(agent_name: str, state: Dict[str, Any]) -> Dict[str, Any]:
    try:
        result = self.agents[agent_name].execute(state)
        time.sleep(2)
        return result
    except Exception as e:
        logger.error(f"[{agent_name}] Failed: {e}")
        time.sleep(2)
        return state  # Return original state, allow continuation
```

**Error Recovery Strategy**: Agents return original state on failure, allowing workflow to continue. Records `error_message` and `current_step` for debugging.

### Testing & Debugging

**Enable Verbose Logging**: Edit `config/config.yaml`
```yaml
logging:
  level: "DEBUG"
```

**Mock Mode Testing** (no API quota consumption):
```yaml
agents:
  ai_trend_analyzer:
    mock_mode: true
```

**Test Individual Agent**:
```bash
cd test
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_ai_trends.py --source hackernews
```

### Test Files

**Test Directory**: `test/`

| Test File | Purpose |
|-----------|---------|
| `test_ai_trends.py` | Test AI trend fetching from single data source |
| `test_storage.py` | Test storage system functionality |
| `test_topic_logic.py` | Test topic parameter handling across modes |
| `test_digest.py` | Test trend digest generation |
| `test_auto_topic.py` | Test auto mode topic handling |
| `test_new_sources.py` | Test new data source integration |
| `test_data_sources.py` | Test all data sources |
| `test_v9_categorization.py` | Test v9.2 6-category system |

**Test README**: `test/README.md` contains detailed documentation for test files.

**Running Tests**:
```bash
cd test
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_ai_trends.py --source hackernews
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_storage.py
```

**Test Single AI Trend Source**:
```bash
cd test
PYTHONPATH=/Users/z/Documents/work/content-forge-ai python test_ai_trends.py --source hackernews
# Sources: hackernews, arxiv, huggingface, stackoverflow, devto, pypi, github_topics, kaggle
```

**Note**: `src/data_sources/` directory removed in v2.5; data sources integrated into `src/agents/ai_trend_analyzer_real.py`.

## Code Standards

- Use type annotations (PEP 484)
- Follow PEP 8
- Add docstrings
- Use `self.log()` instead of `print()`
- Agent `execute()` must return complete state dict
- Exception handling must update `error_message` and `current_step` fields

## Architecture Highlights

### Staged Longform Generation

`LongFormGeneratorAgent` (`src/agents/longform_generator.py:73`) uses three-stage generation to avoid timeouts:

1. **Stage 1**: Generate article outline
2. **Stage 2**: Expand sections section-by-section (loop LLM calls, optional context window)
3. **Stage 3**: Generate summary

This enables 9000-13000 word professional in-depth analysis.

### Web Search Deep Research

`ResearchAgent` uses Tavily API for web search, collecting official docs, GitHub, tech blogs. Research data stored in `state["research_data"]`.

### Quality Assurance Triple Check

1. **CodeReviewAgent**: Reviews code examples for correctness and best practices
2. **FactCheckAgent**: Fact-checks statements, technical parameters, dates/times
3. **QualityEvaluatorAgent**: Comprehensive quality assessment (score 7-10)

## Performance Optimization

### Cost Reduction

- Use `glm-4-flash` instead of `glm-4.7` (~80% cost reduction)
- Reduce data sources (e.g., keep only hackernews + arxiv)
- Lower `max_tokens` settings
- Disable unnecessary agents (set `enabled: false`)

### Speed Up Execution

- Use mock mode for development testing
- Reduce data sources

## Common Issues

**Import Error**: Ensure running from project root with PYTHONPATH set
```bash
export PYTHONPATH=/Users/z/Documents/work/content-forge-ai  # Replace with your actual path
python src/main.py --mode auto --once
```

**API Key Error**: Check environment variables
```bash
echo $ZHIPUAI_API_KEY
# or
cat .env
```

**View Logs**: Logs stored by date in `logs/YYYYMMDD/app.log`
```bash
tail -f logs/$(date +%Y%m%d)/app.log
```

**Generate Only Partial Content**: Edit `config/config.yaml` to disable unwanted agents
```yaml
agents:
  longform_generator:
    enabled: false
```

**Debug Specific Agent**: Enable mock_mode to avoid API calls
```yaml
agents:
  ai_trend_analyzer:
    mock_mode: true
```

**NewsAPI Rate Limiting**: NewsAPI has a free tier limit. If you hit rate limits:
1. Reduce `max_trends` in config.yaml
2. Remove `newsapi` from sources list
3. Or upgrade to NewsAPI paid tier

## Important Architecture Gotchas

1. **Only 2 Modes Implemented**: Auto and Series modes work. Custom and Refine modes are documented in config.yaml but NOT coded.

2. **State Field Naming Confusion**: Auto mode uses `trends_by_source`/`categorized_trends`/`scored_trends`, but older code and Series mode use `trending_topics`. These are NOT compatible.

3. **Agent Name vs State Field**: The agent is named `ai_trend_analyzer` but outputs `trends_by_source`, not `trending_topics`.

4. **DailyStorage Only Creates Two Directories**: As of v4.0+, `DailyStorage` only creates `raw/` and `digest/` subdirectories. Other directories like `longform/` will NOT be created in Auto mode.

5. **Research Agent Provider**: The `research_agent` uses `search_provider: "tavily"` by default (paid service). You can change to "zhipuai" (included in annual plan) or "mock" (offline development) in config.yaml.

6. **Series ID vs Path**: Series use two different identifiers:
   - `series_id`: "series_1" (internal ID, used in JSON config)
   - `series_path`: "series_1_llm_foundation" (folder name, used in filesystem)
   - Always use `SeriesPathManager` to convert between them.

7. **LLM Provider Base URL**: ZhipuAI uses a special coding endpoint: `https://open.bigmodel.cn/api/coding/paas/v4/` (NOT the standard API endpoint). This is configured in `config.yaml`.

8. **Agent Import Limitation**: Only 6 agents are exported in `__init__.py`. Quality agents (code_review, fact_check, etc.) must be imported directly from their modules.

9. **Version Context**: `config/config.yaml` header shows v2.5 but actual implementation is v9.2. Features were added incrementally - verify actual implementation in source code.

10. **Data Source Integration**: Data sources are integrated directly into `RealAITrendAnalyzerAgent` in `src/agents/ai_trend_analyzer_real.py`. The `src/data_sources/` directory mentioned in some documentation was removed in v2.5.

11. **Config vs Implementation Mismatch**: `config.yaml` contains agent configurations for Xiaohongshu/Twitter/WeChat agents that were removed during Refine/Custom mode cleanup. These are NOT exported in `__init__.py` and NOT available for use.

## Key File Locations

### Core Files

| File | Purpose |
|------|---------|
| `src/main.py` | Unified entry (supports --mode switching) |
| `src/auto_orchestrator.py` | LangGraph workflow orchestration (auto mode) |
| `src/series_orchestrator.py` | Series mode orchestrator |
| `src/state.py` | State definition (WorkflowState TypedDict) |
| `src/utils/storage_v2.py` | Unified storage system (StorageFactory) |
| `src/utils/series_manager.py` | Series management tools |
| `src/utils/api_config.py` | API config management (APIConfigManager) |
| `config/config.yaml` | Main config (LLM, agents, workflow) |
| `config/blog_topics_100_complete.json` | 100-episode plan |
| `config/prompts.yaml` | Agent system prompt templates |
| `.env` | Environment variables (API keys) |
| `.env.example` | Environment variable examples |
| `run_and_commit.sh` | Automated deployment script |
| `.claude/skills/` | Custom Claude Code skills directory |

### Agent Classes (src/agents/)

**Exported Agents** (available via `from src.agents import ...`):
| Agent Class | File | Purpose |
|-------------|------|---------|
| `BaseAgent` | `base.py` | Agent base class |
| `RealAITrendAnalyzerAgent` | `ai_trend_analyzer_real.py` | AI trend analysis (14 data sources) |
| `TrendsDigestAgent` | `trends_digest_agent.py` | Trend digest generation |
| `LongFormGeneratorAgent` | `longform_generator.py` | Longform generation (staged) |
| `TitleOptimizerAgent` | `title_optimizer.py` | Title optimization |
| `ImageGeneratorAgent` | `image_generator.py` | Image prompt generation |

**Auto Mode Agents** (import directly):
| Agent Class | File | Purpose |
|-------------|------|---------|
| `TrendCategorizerAgent` | `trend_categorizer_agent.py` | 6-category organization (v9.2) |
| `NewsScoringAgent` | `news_scoring_agent.py` | 6-dimensional scoring |
| `WorldClassDigestAgentV9` | `world_class_digest_agent_v8.py` | Chinese digest + JSON |

**Note**: `world_class_digest_agent_v8.py` file name is legacy - it implements v9 functionality. Check file headers for actual version.

**Series Mode Quality Agents** (import directly):
| Agent Class | File | Purpose |
|-------------|------|---------|
| `ResearchAgent` | `research_agent.py` | Web search deep research |
| `CodeReviewAgent` | `code_review_agent.py` | Code quality review |
| `FactCheckAgent` | `fact_check_agent.py` | Fact verification |
| `QualityEvaluatorAgent` | `quality_evaluator_agent.py` | Comprehensive quality assessment |
| `ConsistencyCheckerAgent` | `consistency_checker_agent.py` | Terminology/citation check |
| `VisualizationGeneratorAgent` | `visualization_generator_agent.py` | Auto-generate Mermaid diagrams |
| `CitationFormatterAgent` | `citation_formatter_agent.py` | GB/T 7714-2015 format |

**Note**: Files for Xiaohongshu/Twitter/WeChat agents exist but were removed during Refine/Custom mode cleanup and are NOT exported.

## Related Documentation

- **README.md** - Project overview and quick start
- **test/README.md** - Test file documentation

---

**Version**: v11.0 (current implementation)
**Updated**: 2026-02-10

## Version Notes

**Important Version Context**:
- **v11.0** (current, 2026-02-10): **æ€§èƒ½ä¸è´¨é‡å¤§å¹…æå‡** - å¹¶å‘æ•°æ®è·å–ï¼ˆ10å€æ€§èƒ½æå‡ï¼‰ã€æ—¶æ•ˆæ€§æ™ºèƒ½åŠ æƒã€è½»é‡çº§äº‹å®æ ¸æŸ¥ã€å†…å®¹å¢å¼ºã€ç¿»è¯‘ç²¾ç‚¼ - **æ˜¾è‘—æå‡å†…å®¹è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦**
  - **ConcurrentFetchAgent**: å¹¶å‘è·å–26ä¸ªæ•°æ®æºï¼Œæ€§èƒ½æå‡10å€
  - **TimeWeightAgent**: åŠ¨æ€æ—¶é—´æƒé‡ï¼ˆdynamic/linear/exponentialï¼‰ï¼Œ72å°æ—¶ä»¥ä¸Šæ—¶æ•ˆåˆ†ä¸º0ï¼Œ1å°æ—¶å†…æ–°é—»2å€åŠ æˆ
  - **AutoFactCheckAgent**: è½»é‡çº§äº‹å®æ ¸æŸ¥Top 10æ–°é—»ï¼Œä½¿ç”¨LLMå†…ç½®çŸ¥è¯†ï¼ˆæ— éœ€Tavilyï¼‰
  - **ContentEnhancerAgent**: ä½¿ç”¨trafilaturaæå–å®Œæ•´å†…å®¹ï¼Œä¸ºé‡è¦æ€§>=70çš„æ–°é—»ç”ŸæˆèƒŒæ™¯å’Œå½±å“åˆ†æ
  - **TranslationRefinerAgent**: åº”ç”¨StrunkåŸåˆ™æå‡å¯è¯»æ€§ï¼Œæœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥ï¼Œç›®æ ‡å¯è¯»æ€§åˆ†æ•°60
  - **Updated Scoring Weights**: 7ç»´åº¦è¯„åˆ†ï¼ˆæ–°å¢fact_confidence 5%ï¼Œfreshnessæå‡è‡³25%ï¼Œcontent_qualityæå‡è‡³15%ï¼‰
- **v10.1** (2026-02-08): **æ–°å¢9ä¸ªå…è´¹RSSæ•°æ®æº** - AI News, The Decoder, é‡å­ä½, æœºå™¨ä¹‹å¿ƒ, Wired AI, VentureBeat AI, Google AI Blog, DeepMind Blog, arXiv CL/CV/LG, Reddit ML/AI RSS, Towards Data Science
- **v10.0** (2026-02-05): **æ–°å¢3ä¸ªå®æ—¶æ•°æ®æº** - NewsData.io (ç§’çº§æ–°é—»API), Reddit Stream (å®æ—¶ç¤¾åŒºè®¨è®º), GitHub Trending (å¼€å‘è€…å…³æ³¨çƒ­ç‚¹) - **æ˜¾è‘—å¢å¼ºæ–°é—»å®æ—¶æ€§**
- **v9.2** (2026-02-01): 6-category system, prioritize latest data, removed 24h restriction, guarantee 30 items daily
- **v9.1** (2026-02-01): Strict 24h time filtering, enhanced time format support
- **v9.0** (2026-02-01): 5-category â†’ 6-categoryé‡æ„, æ–°å¢ ğŸ¦¾ AI Agent åˆ†ç±», 30ä¸ªæ•°æ®æºåˆ†ç±»æ˜ å°„
- **v8.1** (2026-01-31): Added ML Series (100 episodes), batch generation scripts, dual-series architecture
- **v8.0** (2026-01-28): Auto and Series modes optimized, skills integration, 3x daily GitHub Actions
- `config/config.yaml` header shows v2.5 (outdated, not updated since early development)
- Features include v7.0 innovations (NewsScoringAgent, 6-dimensional scoring) plus v8.0-v11.0 improvements
- **Dual Series Architecture**: LLM Series (100 episodes) + ML Series (100 episodes) = 200 episodes total
- **Only 2 modes implemented**: Auto and Series. Custom/Refine modes documented in config but NOT coded
- **Always verify actual implementation in source code** - documented features may differ from deployed version

## Recent Changes

This CLAUDE.md has been improved with:

1. **v11.0 Performance & Quality Enhancement** (2026-02-10):
   - **Added ConcurrentFetchAgent**: å¹¶å‘è·å–26ä¸ªæ•°æ®æºï¼Œæ€§èƒ½æå‡10å€ï¼Œå¯é…ç½®å¹¶å‘æ•°å’Œè¶…æ—¶
   - **Added TimeWeightAgent**: åŠ¨æ€æ—¶é—´æƒé‡æ¨èï¼ˆdynamic/linear/exponentialï¼‰ï¼Œ72å°æ—¶ä»¥ä¸Šæ—¶æ•ˆåˆ†ä¸º0ï¼Œ1å°æ—¶å†…æ–°é—»2å€åŠ æˆ
   - **Added AutoFactCheckAgent**: è½»é‡çº§äº‹å®æ ¸æŸ¥Top 10æ–°é—»ï¼Œä½¿ç”¨LLMå†…ç½®çŸ¥è¯†ï¼ˆæ— éœ€Tavilyï¼‰ï¼Œç½®ä¿¡åº¦é˜ˆå€¼0.7
   - **Added ContentEnhancerAgent**: ä½¿ç”¨trafilaturaæå–å®Œæ•´å†…å®¹ï¼Œä¸ºé‡è¦æ€§>=70çš„æ–°é—»ç”ŸæˆèƒŒæ™¯å’Œå½±å“åˆ†æ
   - **Added TranslationRefinerAgent**: åº”ç”¨StrunkåŸåˆ™æå‡å¯è¯»æ€§ï¼Œæœ¯è¯­ä¸€è‡´æ€§æ£€æŸ¥ï¼Œç›®æ ‡å¯è¯»æ€§åˆ†æ•°60
   - **Updated Scoring Weights**: 7ç»´åº¦è¯„åˆ†ï¼ˆsource_authority 25%, engagement 15%, freshness 25%, category_balance 10%, content_quality 15%, diversity 5%, fact_confidence 5%ï¼‰
   - **Updated data sources count**: 17 â†’ 26 sources
   - **Updated Auto Mode workflow**: 4 agents â†’ 8 agents
   - **Updated Project Overview**: Reflects v11.0 architecture and features

2. **v10.1 Free RSS Data Sources** (2026-02-08):
   - **Added 9 free RSS sources**: AI News, The Decoder, é‡å­ä½, æœºå™¨ä¹‹å¿ƒ, Wired AI, VentureBeat AI, Google AI Blog, DeepMind Blog, arXiv CL/CV/LG, Reddit ML/AI RSS, Towards Data Science
   - **Updated data sources count**: 17 â†’ 26 sources

3. **v10.0 Real-time Data Sources** (2026-02-05):
   - **Added NewsData.io**: ç§’çº§æ›´æ–°æ–°é—»APIï¼Œå…è´¹200æ¬¡/å¤©ï¼Œæ˜¾è‘—æå‡æ–°é—»å®æ—¶æ€§
   - **Added Reddit Stream**: å®æ—¶ç¤¾åŒºè®¨è®ºç›‘æ§ (r/MachineLearning, r/artificial, r/ChatGPT, r/LocalLLaMA)
   - **Added GitHub Trending**: å¼€å‘è€…å…³æ³¨çƒ­ç‚¹ï¼Œå®æ—¶çƒ­é—¨AIé¡¹ç›®
   - **Updated data sources count**: 14 â†’ 17 sources
   - **Updated .env.example**: Added NEWSDATA_IO_API_KEY configuration
   - **Updated API keys section**: Documented new real-time data source API keys

2. **v9.2 Documentation Updates** (2026-02-03):
   - **Updated Core Files section**: Removed outdated `src/data_sources/` reference, added clarity on actual v9.2 implementation
   - **Updated Key Architecture Points**: Changed 5-category â†’ 6-category system, added data source integration clarification
   - **Updated Auto Mode documentation**: Added v9.2 time filtering changes (no 24h restriction)
   - **Updated Agent Dependencies**: Changed v8.0 â†’ v9.2, updated categorizer description
   - **Updated Data Flow section**: Added v9.2 categorizer details
   - **Added AI Insights sync**: Documented repository_dispatch trigger to external repo
   - **Updated Important Architecture Gotchas**: Added data source integration and config mismatch warnings
   - **Updated Version Notes**: Added v9.1 context, clarified v2.5 header issue

2. **v9.2 Updates** (2026-02-01):
   - **6-Category System**: ğŸ“š å­¦æœ¯å‰æ²¿, ğŸ› ï¸ å¼€å‘å·¥å…·, ğŸ¦¾ AI Agent, ğŸ’¼ ä¼ä¸šåº”ç”¨, ğŸŒ æ¶ˆè´¹äº§å“, ğŸ“° è¡Œä¸šèµ„è®¯
   - **30 Data Sources**: Integrated across 6 categories with comprehensive documentation
   - **Prioritize Latest Data**: Sort by timestamp (newest first), guarantee 30 items daily (6Ã—5)
   - **Removed 24h Restriction**: Allow older content to fill gaps, ensure daily output quota
   - **Enhanced Time Parsing**: Support for RSS/Atom/HTTP Date formats in `time_filter.py`
   - **New Data Sources**: Added 10 new sources (Semantic Scholar, Hugging Face, PyPI, npm, etc.)

3. **v8.1 Updates** (2026-01-31):
   - **Added ML Series documentation** - 100 episodes covering ML/DL topics
   - **Added batch generation scripts** - `batch_generate_ml_series.sh` for parallel execution
   - **Added workflow monitoring** - `monitor_and_launch_next.sh` for auto-launching episodes
   - **Updated Series Path Management** - ML series paths and category detection
   - **Updated command reference** - `--series-config` flag for switching between LLM/ML series

**Recommended Actions**:
1. Use `--series-config` flag to switch between LLM and ML series
2. Use batch generation scripts for parallel ML episode generation
3. Only use Auto and Series modes - Custom/Refine are not available
4. Import quality agents directly when needed: `from src.agents.code_review_agent import CodeReviewAgent`
5. Test in mock mode first before running with live APIs
6. Verify agent availability in `src/agents/__init__.py` before use
7. Check `docs/DATA_SOURCES.md` for complete 30 data source documentation (v9.2)
8. Be aware that `config.yaml` contains configurations for removed agents (Xiaohongshu/Twitter/WeChat)
9. Enable v11.0 agents in config.yaml for better performance and quality (concurrent_fetch, time_weight, auto_fact_check, content_enhancer, translation_refiner)
