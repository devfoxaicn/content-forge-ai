# 第3章：Pretraining——大模型的"小学阶段"

**阅读时间**：25分钟
**难度等级**：⭐⭐

---

## 开篇故事

想象一个孩子，从出生到6岁：

**第1年**：只会哭和笑
**第2年**：开始说单字（"妈妈"、"爸爸"）
**第3年**：能说简单句子（"我要吃"）
**第4年**：能讲故事（"今天去公园玩..."）
**第5年**：能问问题（"为什么天是蓝的？"）
**第6年**：准备上学，已经掌握了基本的语言能力

**这个孩子是怎么学会说话的？**

不是有人教他语法规则。
不是有人给他上语言课。
而是通过**大量的听和模仿**。

这就像大模型的"预训练"（Pretraining）：
- 不需要老师手把手教
- 自己从海量文本中学习
- 用比喻：像让学生"博览群书"，自己从中总结规律

[插图1：一个孩子从婴儿到6岁的成长，旁边是书堆得越来越高的画面]

---

## 3.1 什么是"预训练"？

### "预训练"vs "训练"

在AI领域，有两个概念：

**训练（Training）**：
- 一般的机器学习过程
- 有人类标注的"标准答案"
- 模型模仿标准答案
- 用比喻：老师给学生讲题，学生模仿老师的做法

**预训练（Pre-training）**：
- 在"真正使用"之前的训练
- 没有人工标注的答案
- 模型自己从数据中学习
- 用比喻：学生自己读万卷书，自己总结规律

**"预"的含义**：
- 预：预先、提前
- 预训练：在专门任务之前的基础训练
- 用比喻：上大学前的"基础教育"

[插图2：教育体系对比——左边是基础教育（预训练），右边是专业教育（微调）]

### 预训练的核心思想

**一句话总结：**
> 让模型在海量文本上自己学习语言的模式和规律。

**具体做法**：
1. 收集海量文本（互联网、书籍、文章...）
2. 让模型做一个简单的任务：预测下一个词
3. 重复这个任务万亿次
4. 模型在这个过程中"学会"了语言

**用比喻：婴儿学说话**

婴儿是怎么学会说话的？
- **大量听**：听父母、周围人说话
- **自己试**：咿呀学语，模仿
- **不断练**：日复一日的练习
- **自然学会**：不需要老师教语法

大模型预训练也是一样：
- **大量读**：读海量的文本
- **自己猜**：猜测下一个词
- **不断练**：重复万亿次
- **自然学会**：掌握语言规律

[插图3：婴儿学说话 vs 大模型预训练的对比图]

### 为什么预训练有效？

**原因1：语言有规律**

虽然语言看似复杂，但有内在规律：
- "我今天吃___" → 很可能是"饭"、"苹果"、"东西"
- "他去北京___" → 很可能是"了"、"的"、"出差"

这些规律不是人工设计的，而是语言使用中自然形成的。
用比喻：像游戏规则，虽然复杂，但有章可循。

**原因2：量变引起质变**

- 看很少文本：学不到规律
- 看很多文本：开始发现模式
- 看海量文本：掌握深层规律
- 用比喻：读一本书可能没什么感觉，读一千本书就会有"语感"

**原因3：简单的任务也能学到复杂的能力**

预训练的任务很简单："预测下一个词"
但这个简单任务让模型学会了：
- 语法
- 语义
- 推理
- 写作
- 用比喻：像学钢琴，只练习音阶，但最后能演奏复杂曲目

[插图4：量变到质变图——从很少数据到海量数据，能力曲线]

---

## 3.2 训练数据：大模型读了什么书？

### 大模型的"阅读清单"

假设GPT-3是一个学生，它读了什么？

**主要来源**：
1. **互联网网页**：Common Crawl（包含几乎所有公开网页）
2. **书籍**：Google Books（数百万本书）
3. **文章**：维基百科、新闻网站、博客
4. **代码**：GitHub（程序员写的代码）
5. **对话**：Reddit、论坛讨论

**数据量有多大？**

- GPT-3训练数据：约5000亿个词（token）
- 如果一个人每秒读1个词，需要**15,850年**才能读完
- 用比喻：像把整个国家图书馆的书都读一遍

[插图5：图书馆图示——一座巨大的图书馆，标注"GPT-3的训练数据"]

### 数据的"质量"很重要

**"垃圾进，垃圾出"（Garbage In, Garbage Out）**

如果训练数据不好，模型就会学到不好的东西：

**问题数据**：
- 错误信息（伪科学、谣言）
- 有害内容（暴力、歧视）
- 低质量文本（乱码、无意义）
- 用比喻：吃垃圾食品，身体会不好

**数据清洗**：
- 去重：删除重复内容
- 过滤：删除有害内容
- 质量筛选：优先选择高质量文本
- 用比喻：洗菜、择菜，把不好的部分去掉

**GPT系列的数据质量提升**：
- GPT-2：数据较少，质量一般
- GPT-3：数据量更大，质量提升
- GPT-4：精选高质量数据，规模也更大
- 用比喻：从吃快餐，到吃家常菜，再到吃营养餐

[插图6：数据质量对比——左边是杂乱的垃圾数据，右边是整洁的高质量数据]

### 中文大模型的数据

**中文数据从哪来？**

1. **中文网页**：百度、微博、知乎...
2. **中文书籍**：电子书、文学作品
3. **中文文章**：新闻报道、学术论文
4. **中文代码**：中国程序员的代码

**挑战**：
- 中文互联网数据比英文少
- 高质量中文文本更少
- 用比喻：英文像大海，中文像大湖，都很大，但大小不同

**解决方案**：
- 增加中文书籍比例
- 收集更多中文网页
- 翻译部分英文数据
- 用比喻：湖虽然小，但可以挖深一点

[插图7：中英文数据对比图]

---

## 3.3 学习任务：猜下一个字

### 预训练的核心任务

**任务名称**：Next Token Prediction（下一个词预测）

**任务描述**：给定前面的文本，预测下一个词是什么。

**简单例子**：

**例子1：日常对话**
```
输入：今天天气真___
可能的答案：好、不错、糟糕、热、冷...
最可能的：好（出现频率最高）
```

**例子2：古诗词**
```
输入：床前明月___
答案：光（固定搭配）
```

**例子3：逻辑推理**
```
输入：如果下雨，我就打___
答案：伞（根据常识推断）
```

**用比喻：填空题**

你做过这种题吗？
- "今天天气真（    ）"
- "床前明月（    ）"

预训练就是让模型做这种填空题，但做了**万亿次**！

[插图8：填空题示例图，像试卷一样]

### 这个任务为什么有效？

**表面上看**：
- 只是在"猜"下一个词
- 好像很简单

**实际上**：
- 要猜对下一个词，需要理解：
  - 语法规则
  - 词语搭配
  - 语义逻辑
  - 世界知识
  - 上下文关系

**例子分析**：

输入："法国的首都是___"

要填对这个空，需要知道：
- 什么是"首都"（概念理解）
- 法国的首都叫什么（世界知识）
- 首都通常是专有名词（语法知识）
- 应该填"巴黎"（综合所有知识）

**用比喻：要学会游泳，必须跳进水里**

不是在岸上学习游泳理论，
而是亲自下水，在水中摸索。

大模型也是，通过不断的"猜测"和"验证"，逐渐掌握语言。

[插图9：理解层次图——从表面猜测到深层理解]

### 训练过程：从随机到准确

**初始状态**：随机猜测

刚初始化的模型，什么都不会：
- 输入："我今天吃___"
- 可能猜："天空、桌子、跑..."
- 完全不靠谱

**训练过程**：不断调整

1. 模型做出猜测
2. 对比真实答案
3. 如果猜错了，调整参数
4. 下次猜得更准

**用比喻：学生做练习题**

- 第一次做：错很多
- 老师批改：指出错误
- 学生订正：理解正确答案
- 第二次做：错得少了
- 重复练习：越来越熟练

**训练后期**：准确率很高

经过海量训练：
- 输入："我今天吃___"
- 能准确猜："饭、苹果、东西..."
- 不仅准确，还能生成多种合理的答案

**GPT-3的训练规模**：
- 训练样本：约3000亿个"填空题"
- 训练时间：数千张GPU，跑几个月
- 训练成本：约460万美元
- 用比喻：几万个学生，做几万亿道题

[插图10：训练准确率曲线——从随机猜测到高准确率]

---

## 3.4 Transformer：大模型的"大脑结构"

### 为什么需要Transformer？

预训练任务确定了（预测下一个词），
但用什么"大脑结构"来完成这个任务呢？

早期的方法（RNN）有问题：
- 读得慢（一个一个词读）
- 记不住（前面读的容易忘）
- 难并行（不能同时处理）

**Transformer解决了这些问题**：
- 读得快（同时处理所有词）
- 记得住（所有词都在"视野"内）
- 易并行（可以同时计算）

**用比喻：RNN像逐个读单词，Transformer像一眼看到整句**

[插图11：RNN vs Transformer阅读方式对比]

### Transformer的三大核心组件

#### 组件1：自注意力机制（Self-Attention）

**作用**：理解词语之间的关系

**例子："他打球" vs "他打人"**

同样的"打"字，意思完全不同：
- "他打球" → "打" = 玩（娱乐）
- "他打人" → "打" = 攻击（暴力）

**怎么判断的？**

自注意力机制会让"打"字"注意"后面的字：
- 如果是"球" → 理解为"玩"
- 如果是"人" → 理解为"攻击"

**用比喻：读书时会重点关注某些词**

当你读"他打___"时，你会期待后面的词来理解"打"的意思。
Transformer也是这样，它会让词语之间"建立联系"。

[插图12：注意力可视化——"打"字与"球"、"人"的连接强度]

**更复杂的例子**：

句子："小明说他不去上学，因为他病了"

问题："他"指谁？是"小明"还是"别人"？

自注意力机制会让"他"和"小明"建立强联系，
因为逻辑上"他"应该指"小明"。

**用比喻：像理解复杂句子，需要记住主语**

[插图13：复杂句子的注意力图]

---

#### 组件2：位置编码（Positional Encoding）

**作用**：让模型知道词语的顺序

**为什么需要？**

Transformer是"并行"处理所有词的，
不像RNN那样"按顺序"处理。

如果不告诉模型每个词的位置，
它就无法区分顺序不同的句子。

**例子**：
- "我爱你" vs "你爱我"
- 词语完全相同，顺序不同，意思完全不同

**位置编码怎么做？**

给每个位置加一个"位置标记"：
- 第1个词：加标记1
- 第2个词：加标记2
- 第3个词：加标记3

这样模型就知道每个词在哪个位置了。

**用比喻：给每个人发个号码牌**

就像排队时，每个人手里有个号码，
外人一看就知道谁排在第几个。

[插图14：位置编码示意图——每个词带有位置标记]

---

#### 组件3：多层结构（Multi-Layer）

**作用**：从简单到复杂的理解

**单层的问题**：

如果只有一层，很难理解复杂内容：
- 第1层：只能看到字面
- 无法理解深层含义

**多层的好处**：

每一层提取不同层次的信息：
- **第1-5层**：基础理解（语法、词义）
- **第6-20层**：语义理解（句意、关系）
- **第21-40层**：深层理解（推理、知识）
- **第41-96层**：抽象理解（综合、整合）

**用比喻：从识字到理解文章的层次**

**第1层**：认字（认识"你"、"好"、"吗"）
**第10层**：理解短语（"你好吗"=问候）
**第50层**：理解句子（"你好吗？我很好"=对话）
**第96层**：理解篇章（整篇文章的含义）

**GPT模型的层数**：
- GPT-2：48层
- GPT-3：96层
- GPT-4：估计更多（未公开）
- 用比喻：楼越高，视野越广

[插图15：多层结构示意图——从底层到高层，理解层次递进]

---

### Transformer如何工作？

**完整流程**：

**输入**："今天天气真好"

**步骤1：词嵌入**
- 把每个词变成数字向量
- "今天" → [0.2, 0.5, -0.1, ...]
- "天气" → [0.8, -0.3, 0.6, ...]
- 用比喻：把每个字变成一个"指纹"

**步骤2：位置编码**
- 给每个词加上位置信息
- 第1个词："今天"+位置1
- 第2个词："天气"+位置2
- 用比喻：给每个人发号码牌

**步骤3：自注意力**
- 让词之间建立联系
- "今天"和"天气"相关
- "天气"和"真好"相关
- 用比喻：人物之间建立关系网

**步骤4：前馈计算**
- 处理和转换信息
- 提取特征和模式
- 用比喻：消化和吸收信息

**步骤5：多层处理**
- 重复步骤3-4，多次
- 每一层提取更高层次的信息
- 用比喻：多级加工，逐级提炼

**输出**：下一个词的预测
- 概率分布：
  - "啊"：30%
  - "。"：25%
  - "呀"：15%
  - 其他：30%
- 可以选择概率最高的，或者随机采样

[插图16：Transformer完整工作流程图]

---

## 3.5 训练过程：需要多少资源？

### 硬件需求

**训练一个GPT级别的大模型，需要什么？**

**GPU（图形处理器）**：
- GPT-3：使用了数千张A100 GPU
- A100 GPU价格：约1-1.5万美元/张
- 仅硬件成本：数千万美元
- 用比喻：像建工厂，需要很多机器

**为什么需要这么多GPU？**

- 单张GPU不够快
- 需要并行处理
- 用比喻：一个人搬砖很慢，需要很多人一起

**存储**：
- 模型参数：1750亿个（GPT-3）
- 每个参数4字节
- 需要约700GB存储
- 用比喻：像一个大仓库

[插图17：GPU集群图——多个机柜，每个装满GPU]

### 时间成本

**GPT-3训练用了多久？**

- 使用：1024张A100 GPU
- 时间：约1个月
- 总计算时间：约3640 petaflop/s-day
- 用比喻：像盖楼，需要很多人工作很长时间

**如果用单张GPU？**
- 需要：约30年
- 用比喻：一个人干30个人的活

**为什么这么久？**

- 数据量大：5000亿个词
- 计算量大：万亿级运算
- 迭代次数多：需要反复训练
- 用比喻：读万卷书，需要很多时间

[插图18：时间对比图——单GPU vs GPU集群]

### 经济成本

**GPT-3训练成本**：
- 硬件：数千万美元
- 电费：数十万美元
- 人力：数百万美元
- 总计：约460万美元（仅训练一次）

**为什么这么贵？**

- GPU租金贵：每小时数百美元
- 电费贵：GPU耗电巨大
- 人力贵：需要顶尖工程师
- 用比喻：像搞科研，需要大量投入

**后续模型更贵**：
- GPT-4估计训练成本：上亿美元
- 用比喻：从盖楼到盖摩天大楼

[插图19：成本增长图——从GPT-2到GPT-4的成本]

---

## 3.6 "涌现"：量变到质变

### 什么是"涌现"（Emergence）？

**定义**：当模型规模达到一定程度时，突然出现小模型没有的能力。

**用比喻：量变到质变**

- 水99度：只是热水
- 水100度：突然沸腾（相变）
- 用比喻：量积累到一定程度，突然产生质的飞跃

**GPT的涌现例子**：

**小模型（GPT-2，15亿参数）**：
- ❌ 不会算术："3+5=?" → 乱猜
- ❌ 不会写代码：写不出可用代码
- ❌ 不会推理：简单的逻辑推理都不会

**大模型（GPT-3，1750亿参数）**：
- ✅ 会算术："3+5=?" → "8"
- ✅ 会写代码：能写可用的Python代码
- ✅ 会推理：能做逻辑推理

**为什么？**

没人编程这些能力，
模型自己"学会"了！

**这就是"涌现"：规模大到一定程度，能力突然出现。**

[插图20：涌现曲线图——模型规模 vs 能力，突然跳跃]

### 涌现能力的例子

**算术能力**：

小模型：无法完成
大模型：可以完成

例子：
```
用户：345 + 234 = ?
GPT-3：579
```

**推理能力**：

小模型：无法推理
大模型：可以推理

例子：
```
用户：如果A>B，B>C，那么A和C谁大？
GPT-3：A > C，因为根据传递性，如果A大于B，B大于C，那么A一定大于C
```

**学习新任务**：

小模型：需要很多示例
大模型：看几个例子就会

例子：
```
用户：英语到法语翻译
I love you → Je t'aime
Hello world → Bonjour monde
Good morning → __________
GPT-3：Bonjour
```

### 为什么会涌现？

**理论1：压缩即智能**

数据被压缩得越好，模型越智能。
- 小模型：压缩不够，记不住规律
- 大模型：压缩充分，抓住了本质
- 用比喻：背书，记住了关键词就能举一反三

**理论2：规模带来组合能力**

小模型：能力有限
大模型：多种能力可以组合

例子：
- 单独A能力：翻译
- 单独B能力：推理
- 组合A+B：翻译+推理 = 高质量翻译

**理论3：临界点效应**

某些能力需要达到"临界规模"才会出现：
- 像水到100度才沸腾
- 模型大到一定程度，能力才会"涌现"

**用比喻：人多力量大**

一个人：力量有限
一百人：可以搬重物
一万人：可以建长城

[插图21：临界点图——规模积累到某点，能力突然出现]

---

## 3.7 大模型的"记忆"：参数是什么？

### 参数 = "学到的东西"

**什么是参数（Parameters）？**

简单说：参数就是模型"学到的东西"，存储在数字里。

**用比喻：人脑的神经元**

- 人脑：约860亿个神经元
- GPT-3：1750亿个参数
- 数量相近！

**但参数不是"存储数据"**

区别：
- **数据库**：存储具体信息（如"巴黎是法国首都"）
- **参数**：存储规律和模式（如"如何理解语言"）

**用比喻：**
- 数据库：像笔记，记录具体知识
- 参数：像技能，掌握思维方法

[插图22：数据库 vs 参数对比图]

### 参数如何存储知识？

**不是记住具体内容，而是记住模式**

例子："法国的首都是巴黎"

模型不是直接存储这个事实，
而是存储了"法国-首都-巴黎"的语言模式。

**证据**：

如果你问GPT："法国的首都是哪里？"
它会回答："巴黎"

但你也可以：
- 改写问法："法国哪个城市是首都？" → "巴黎"
- 反着问："哪个国家的首都是巴黎？" → "法国"
- 假设："如果巴黎不是法国首都，那会是哪？" → "它仍然是法国首都"

这说明：模型不是"背诵"答案，
而是真正"理解"了关系。

[插图23：知识存储方式对比——死记硬背 vs 理解模式]

### 参数的作用

**1750亿个参数，都干了什么？**

**语言知识**：
- 语法规则（主谓宾、时态...）
- 词语搭配
- 语言习惯

**世界知识**：
- 地理（国家、城市...）
- 历史（事件、人物...）
- 科学（物理、化学、生物...）
- 文化（文学、艺术、宗教...）

**推理能力**：
- 逻辑推理
- 因果关系
- 常识判断

**写作能力**：
- 文风模仿
- 结构组织
- 表达技巧

**用比喻：一个大百科全书+一个大作家**

[插图24：参数能力分解图——展示参数存储的各类知识]

---

## 本章小结

### Pretraining总结

**一句话总结：**
> Pretraining就是让大模型"博览群书"，通过做"填空题"自己学会语言。

**核心要素**：

1. **数据**：海量文本（5000亿词）
2. **任务**：预测下一个词
3. **架构**：Transformer（自注意力+位置编码+多层）
4. **资源**：大量GPU（数千张）
5. **结果**：涌现能力（算术、推理、代码...）

**用比喻：**
- 数据：图书馆的藏书
- 任务：做练习题
- 架构：大脑的结构
- 资源：学习的时间和环境
- 结果：学成的能力

### 从婴儿到学生

回顾一下大模型的"成长"：

**第2章（Tokenizer）**：学会"识字"
**第3章（Pretraining）**：学会"读书"

现在的大模型像：
- 一个读过很多书的学生
- 知识渊博
- 但不知道如何与人交流
- 用比喻：像个"书呆子"

**下一步（第4章 SFT）**：
让它学会"对话"

**用比喻：从读万卷书，到学会和人交流**

---

**本章思考题**：

1. 为什么简单的"预测下一个词"任务，能让大模型学会如此复杂的语言能力？
2. Transformer的自注意力机制、位置编码、多层结构，分别解决了什么问题？
3. 为什么大规模模型会出现"涌现"现象？你认为还有哪些能力可能会涌现？

---

*"读万卷书，行万里路。大模型通过预训练读完了'万卷书'，接下来要学会如何运用这些知识。"*
