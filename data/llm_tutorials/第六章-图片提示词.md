# 第六章图片提示词

---

## 插图1：游戏学习的进化过程

**位置**：开篇故事

**图片描述**：
进化图，从第1次游戏（得分0，撞障碍物）→第10次游戏（得分10，收集一些金币）→第100次游戏（得分1000，熟练通关），展示学习进步。

**画面风格**：
- 水平时间轴或上升曲线
- 游戏场景
- 进步感
- 明亮色彩

**提示词（英文）**：
```
Game learning evolution, horizontal timeline or ascending curve, 1st game (score 0, crashed into obstacle), 10th game (score 10, collected some coins), 100th game (score 1000, mastered), game scene, sense of progress, bright colors
```

**提示词（中文）**：
```
游戏学习演化，水平时间轴或上升曲线，第1次游戏(得分0，撞障碍物)，第10次游戏(得分10，收集一些金币)，第100次游戏(得分1000，精通)，游戏场景，进步感，明亮色彩
```

---

## 插图2：状态-动作-奖励三要素

**位置**：6.1 强化学习的直觉理解

**图片描述**：
三个圆形卡片，分别展示：
1. 状态：游戏场景截图
2. 动作：控制手柄图标
3. 奖励：得分数字

**画面风格**：
- 三个圆形
- 游戏元素
- 蓝绿红色
- 清晰标注

**提示词（英文）**：
```
RL three elements circular cards, 1. State: game scene screenshot, 2. Action: game controller icon, 3. Reward: score numbers, game elements, blue-green-red colors, clear labels
```

**提示词（中文）**：
```
强化学习三要素圆形卡片，1.状态：游戏场景截图，2.动作：游戏手柄图标，3.奖励：得分数字，游戏元素，蓝绿红色，清晰标签
```

---

## 插图3：强化学习循环图

**位置**：6.1 强化学习的直觉理解

**图片描述**：
循环流程图：观察状态→选择动作→获得奖励→调整策略→回到观察状态，用循环箭头连接。

**画面风格**：
- 循环图
- 箭头连接
- 四个主要步骤
- 动态感

**提示词（英文）**：
```
RL cycle flowchart, Observe State → Select Action → Get Reward → Adjust Strategy → back to Observe State, circular arrows connecting, four main steps, dynamic feel
```

**提示词（中文）**：
```
强化学习循环流程图，观察状态→选择动作→获得奖励→调整策略→回到观察状态，循环箭头连接，四个主要步骤，动态感
```

---

## 插图4：AlphaGo训练过程

**位置**：6.2 经典案例：训练AlphaGo

**图片描述**：
三阶段流程：第1阶段模仿人类（看棋谱）→第2阶段自我对弈（自己下棋）→第3阶段优化策略（总结经验），用箭头连接。

**画面风格**：
- 水平流程图
- 围棋元素
- 进步感
- 蓝色主题

**提示词（英文）**：
```
AlphaGo training three-stage flow, Stage 1: Imitate Humans (watching games), Stage 2: Self-Play (playing self), Stage 3: Optimize Strategy (learning from experience), arrows connecting, go game elements, progress feel, blue theme
```

**提示词（中文）**：
```
AlphaGo训练三阶段流程，第1阶段：模仿人类(看棋谱)，第2阶段：自我对弈(自己下棋)，第3阶段：优化策略(从经验中学习)，箭头连接，围棋元素，进步感，蓝色主题
```

---

## 插图5：AlphaGo成功原因

**位置**：6.2 经典案例：训练AlphaGo

**图片描述**：
三个要点卡片：明确规则、自我对弈、计算能力强，每个有图标和说明。

**画面风格**：
- 三个卡片
- 图标+文字
- 蓝绿橙色
- 清晰要点

**提示词（英文）**：
```
AlphaGo success factors three cards, each with icon and text: 1. Clear Rules (gavel icon), 2. Self-Play (mirror icon), 3. Strong Computation (chip icon), blue-green-orange colors, clear key points
```

**提示词（中文）**：
```
AlphaGo成功因素三个卡片，每个带图标和文字：1.明确规则(法槌图标)，2.自我对弈(镜子图标)，3.计算能力强(芯片图标)，蓝绿橙色，清晰要点
```

---

## 插图6：下棋 vs 写作对比

**位置**：6.3 RL在大模型中的应用

**图片描述**：
对比图，左边是下棋（棋盘、棋子），右边是写作（文档、文字），都标注"选择"动作。

**画面风格**：
- 左右对比
- 不同场景
- 选择元素突出
- 类比关系

**提示词（英文）**：
```
Go vs Writing comparison, left: go board with pieces, right: document with text, both highlighting "choice" action, different scenes, analogy relationship, selection element highlighted
```

**提示词（中文）**：
```
下棋vs写作对比，左边：围棋棋盘和棋子，右边：文档和文字，都突出"选择"动作，不同场景，类比关系，选择元素突出
```

---

## 插图7：长期高分文本示意

**位置**：6.3 RL在大模型中的应用

**图片描述**：
文本生成示例，显示如何从短期的词选择到长期的文本质量，用评分标注整体质量。

**画面风格**：
- 文本展示
- 评分标注
- 进度条
- 质量感

**提示词（英文）**：
```
Long-term high-quality text example, showing how individual word choices lead to overall text quality, with score labels showing overall quality, text display, progress bar, quality feel
```

**提示词（中文）**：
```
长期高质量文本示例，展示单个词选择如何影响整体文本质量，用评分标签显示整体质量，文本展示，进度条，质量感
```

---

## 插图8：奖励延迟示意

**位置**：6.4 为什么RL很难？

**图片描述**：
时间线图，展示动作和奖励之间的延迟，早期动作...很久之后...才得到奖励。

**画面风格**：
- 时间轴
- 延迟突出
- 问号元素
- 挑战感

**提示词（英文）**：
```
Reward delay timeline, showing delay between action and reward, early action...long time later...finally get reward, timeline format, delay highlighted, question marks, challenge feel
```

**提示词（中文）**：
```
奖励延迟时间线，展示动作和奖励之间的延迟，早期动作...很久之后...才得到奖励，时间轴格式，延迟突出，问号元素，挑战感
```

---

## 插图9：探索 vs 利用平衡

**位置**：6.4 为什么RL很难？

**图片描述**：
天平图，左边是探索（分岔路口，冒险），右边是利用（安全路径），中间平衡，标注80-90%利用，10-20%探索。

**画面风格**：
- 天平或平衡图
- 道路或路径
- 比例标注
- 平衡感

**提示词（英文）**：
```
Explore vs Exploit balance, scale or balance diagram, left: exploration (fork in road, adventure), right: exploitation (safe path), middle balance, labeled 80-90% exploitation, 10-20% exploration, road or path elements
```

**提示词（中文）**：
```
探索vs利用平衡，天平或平衡图，左边：探索(分岔路口，冒险)，右边：利用(安全路径)，中间平衡，标注80-90%利用，10-20%探索，道路或路径元素
```

---

## 插图10：训练不稳定示意

**位置**：6.4 为什么RL很难？

**图片描述**：
训练曲线，显示性能波动，有时好有时坏，最终可能崩溃或收敛到次优策略。

**画面风格**：
- 波动曲线
- 不稳定感
- 红色警告区
- 问题突出

**提示词（英文）**：
```
Training instability curve, showing performance fluctuation, sometimes good sometimes bad, eventually crashes or converges to suboptimal strategy, wavy line, instability feel, red warning zone, problem highlighted
```

**提示词（中文）**：
```
训练不稳定曲线，显示性能波动，有时好有时坏，最终崩溃或收敛到次优策略，波浪线，不稳定感，红色警告区，问题突出
```

---

## 插图11：学习方式对比

**位置**：6.5 RL vs 传统机器学习

**图片描述**：
对比图，左边是有监督学习（模仿标准答案），右边是强化学习（根据分数调整），清晰对比。

**画面风格**：
- 左右对比
- 不同背景色
- 学习动作
- 教育主题

**提示词（英文）**：
```
Learning method comparison, left: supervised learning (imitating standard answers), right: reinforcement learning (adjusting based on scores), different background colors, learning actions, educational theme
```

**提示词（中文）**：
```
学习方式对比，左边：有监督学习(模仿标准答案)，右边：强化学习(根据分数调整)，不同背景色，学习动作，教育主题
```

---

## 插图12：为什么需要RL

**位置**：6.5 RL vs 传统机器学习

**图片描述**：
三个原因卡片：标准答案不一定最优、需要长期目标、需要适应性，每个有图标和说明。

**画面风格**：
- 三个垂直卡片
- 图标+文字
- 蓝色主题
- 清晰要点

**提示词（英文）**：
```
Three reasons for needing RL cards, vertical layout, each with icon and text: 1. Standard Answers Not Optimal (lightbulb icon), 2. Need Long-term Goals (target icon), 3. Need Adaptability (chameleon icon), blue theme, clear points
```

**提示词（中文）**：
```
需要RL的三个原因卡片，垂直布局，每个带图标和文字：1.标准答案不一定最优(灯泡图标)，2.需要长期目标(靶子图标)，3.需要适应性(变色龙图标)，蓝色主题，清晰要点
```

---

## 插图13：PPO vs 其他算法对比

**位置**：6.6 大模型中的RL技术

**图片描述**：
对比图，PPO是稳定上升的曲线，其他算法是剧烈波动或崩溃的曲线，显示PPO的稳定性。

**画面风格**：
- 曲线对比图
- 稳定vs波动
- 蓝色vs红色
- 清晰对比

**提示词（英文）**：
```
PPO vs other algorithms comparison curve, PPO shows stable ascent, other algorithms show violent fluctuation or crash, stability vs instability, blue vs red colors, clear contrast
```

**提示词（中文）**：
```
PPO vs其他算法对比曲线，PPO显示稳定上升，其他算法显示剧烈波动或崩溃，稳定vs不稳定，蓝色vs红色，清晰对比
```

---

## 插图14：REINFORCE算法示意

**位置**：6.6 大模型中的RL技术

**图片描述**：
简单的循环图，显示REINFORCE的基本流程：动作→奖励→调整概率，简单直接。

**画面风格**：
- 简单流程图
- 循环箭头
- 绿色调
- 简洁清晰

**提示词（英文）**：
```
REINFORCE algorithm simple cycle, showing basic flow: action → reward → adjust probability, simple loop arrows, green tone, clean and clear
```

**提示词（中文）**：
```
REINFORCE算法简单循环，显示基本流程：动作→奖励→调整概率，简单循环箭头，绿色调，简洁清晰
```

---

## 图片生成建议

### 第6章特点

**主题**：强化学习基础原理

**关键概念**：
- 状态-动作-奖励
- 试错学习
- 时间延迟
- 探索vs利用

**视觉策略**：
- 使用游戏化元素（游戏、棋类）
- 清晰的循环和流程图
- 对比图（传统vs RL）
- 曲线图展示训练过程

**颜色建议**：
- 学习进步：蓝色→绿色
- 奖励/正反馈：绿色、金色
- 惩罚/负反馈：红色、橙色
- 探索：紫色
- 利用：蓝色

### 推荐工具

1. **Midjourney**：游戏场景、角色
2. **DALL-E 3**：流程图、概念图
3. **Canva**：后期编辑和文字

---

**提示**：第6章是理论章节，图片需要帮助读者理解抽象的强化学习概念，尽量使用游戏化、生活化的比喻。
