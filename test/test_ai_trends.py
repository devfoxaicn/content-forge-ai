"""
æµ‹è¯•AIçƒ­ç‚¹åˆ†æAgentï¼ˆçœŸå®APIç‰ˆæœ¬ï¼‰
å•ç‹¬æµ‹è¯•çƒ­ç‚¹è·å–åŠŸèƒ½
"""

import sys
import yaml
import argparse
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from ..src.agents.ai_trend_analyzer_real import RealAITrendAnalyzerAgent
from loguru import logger


def load_config(config_path: str = "config/config.yaml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def test_ai_trends(topic: str = "AIå·¥å…·", show_details: bool = True):
    """
    æµ‹è¯•AIçƒ­ç‚¹åˆ†æ

    Args:
        topic: ä¸»é¢˜é¢†åŸŸï¼ˆAIå·¥å…·ã€å¤§æ¨¡å‹åº”ç”¨ã€æ•ˆç‡æå‡ï¼‰
        show_details: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    logger.info(f"å¼€å§‹æµ‹è¯•AIçƒ­ç‚¹åˆ†æAgent")
    logger.info(f"ä¸»é¢˜é¢†åŸŸ: {topic}")

    # åŠ è½½é…ç½®
    config = load_config()
    prompts = {"prompts": {}}

    # åˆ›å»ºAgent
    agent = RealAITrendAnalyzerAgent(config, prompts)

    # åˆ›å»ºåˆå§‹çŠ¶æ€
    state = {
        "topic": topic,
        "target_audience": "æŠ€æœ¯ä»ä¸šè€…",
        "content_type": "å¹²è´§åˆ†äº«",
        "keywords": []
    }

    # æ‰§è¡Œåˆ†æ
    logger.success("=" * 60)
    result = agent.execute(state)

    # æ£€æŸ¥ç»“æœ
    if "error_message" in result:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {result['error_message']}")
        return

    # æ˜¾ç¤ºç»“æœ
    hot_topics = result.get("ai_hot_topics", [])
    selected_topic = result.get("selected_ai_topic", {})

    logger.success(f"âœ… æˆåŠŸè·å– {len(hot_topics)} ä¸ªçƒ­ç‚¹è¯é¢˜")
    logger.success(f"âœ… é€‰æ‹©è¯é¢˜: {selected_topic.get('title', 'N/A')}")
    logger.success("=" * 60)

    if show_details:
        print("\n" + "=" * 80)
        print("ğŸ“Š çƒ­ç‚¹è¯é¢˜è¯¦æƒ…")
        print("=" * 80)

        for i, topic_data in enumerate(hot_topics, 1):
            print(f"\nã€çƒ­ç‚¹ {i}ã€‘")
            print(f"æ ‡é¢˜: {topic_data.get('title', 'N/A')}")
            print(f"æ¥æº: {topic_data.get('source', 'N/A')}")
            print(f"æ—¶é—´: {topic_data.get('timestamp', 'N/A')}")
            print(f"çƒ­åº¦è¯„åˆ†: {topic_data.get('heat_score', 0)}")
            print(f"æè¿°: {topic_data.get('description', 'N/A')[:150]}...")
            print(f"URL: {topic_data.get('url', 'N/A')}")

            metrics = topic_data.get('metrics', {})
            if metrics:
                print(f"æŒ‡æ ‡: {metrics}")

            tags = topic_data.get('tags', [])
            if tags:
                print(f"æ ‡ç­¾: {', '.join(tags)}")

        print("\n" + "=" * 80)
        print("ğŸ“Š æ•°æ®æºç»Ÿè®¡")
        print("=" * 80)

        # ç»Ÿè®¡å„æ•°æ®æºæ•°é‡
        source_counts = {}
        for topic_data in hot_topics:
            source = topic_data.get('source', 'Unknown')
            source_counts[source] = source_counts.get(source, 0) + 1

        for source, count in source_counts.items():
            print(f"  {source}: {count} æ¡")

        print("=" * 80)


def test_single_source(source: str):
    """æµ‹è¯•å•ä¸ªæ•°æ®æº"""
    logger.info(f"æµ‹è¯•å•ä¸ªæ•°æ®æº: {source}")

    config = load_config()

    # ä¸´æ—¶é…ç½®ï¼šåªå¯ç”¨ä¸€ä¸ªæ•°æ®æº
    sources_map = {
        "hackernews": ["hackernews"],
        "arxiv": ["arxiv"],
        "github": ["github"],
        "reddit": ["reddit"],
        "huggingface": ["huggingface"],
        "stackoverflow": ["stackoverflow"],
        "kaggle": ["kaggle"],
        "newsapi": ["newsapi"],
        "devto": ["devto"],
        "pypi": ["pypi"],
        "github_topics": ["github_topics"]
    }

    if source not in sources_map:
        logger.error(f"æœªçŸ¥çš„æ•°æ®æº: {source}")
        logger.info("å¯ç”¨æ•°æ®æº: hackernews, arxiv, github, reddit, huggingface, stackoverflow, kaggle, newsapi, devto, pypi, github_topics")
        return

    config["agents"]["ai_trend_analyzer"]["sources"] = sources_map[source]

    # åˆ›å»ºAgentå¹¶æµ‹è¯•
    prompts = {"prompts": {}}
    agent = RealAITrendAnalyzerAgent(config, prompts)

    state = {
        "topic": "AIå·¥å…·",
        "target_audience": "æŠ€æœ¯ä»ä¸šè€…",
        "content_type": "å¹²è´§åˆ†äº«",
        "keywords": []
    }

    result = agent.execute(state)

    if "error_message" in result:
        logger.error(f"âŒ {source} æ•°æ®æºæµ‹è¯•å¤±è´¥: {result['error_message']}")
    else:
        hot_topics = result.get("ai_hot_topics", [])
        logger.success(f"âœ… {source} æ•°æ®æºæµ‹è¯•æˆåŠŸï¼Œè·å– {len(hot_topics)} æ¡çƒ­ç‚¹")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æµ‹è¯•AIçƒ­ç‚¹åˆ†æAgent")
    parser.add_argument("--topic", type=str, default="AIå·¥å…·",
                       choices=["AIå·¥å…·", "å¤§æ¨¡å‹åº”ç”¨", "æ•ˆç‡æå‡"],
                       help="ä¸»é¢˜é¢†åŸŸ")
    parser.add_argument("--source", type=str, default=None,
                       choices=["hackernews", "arxiv", "github", "reddit", "huggingface", "stackoverflow", "kaggle", "newsapi", "devto", "pypi", "github_topics"],
                       help="æµ‹è¯•å•ä¸ªæ•°æ®æº")
    parser.add_argument("--brief", action="store_true",
                       help="ç®€è¦è¾“å‡ºï¼ˆä¸æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰")

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(sys.stderr, level="INFO")

    if args.source:
        # æµ‹è¯•å•ä¸ªæ•°æ®æº
        test_single_source(args.source)
    else:
        # æµ‹è¯•å®Œæ•´åŠŸèƒ½
        test_ai_trends(args.topic, show_details=not args.brief)


if __name__ == "__main__":
    main()
