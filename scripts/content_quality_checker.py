"""
å†…å®¹è´¨é‡æ£€æŸ¥å™¨
é€æœŸæ£€æŸ¥ ML Series æ–‡ç« è´¨é‡ï¼Œç”Ÿæˆè´¨é‡æŠ¥å‘Š
"""

import os
import re
import json
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional
from datetime import datetime


@dataclass
class QualityReport:
    """å•ç¯‡æ–‡ç« è´¨é‡æŠ¥å‘Š"""
    episode: int
    series_id: str
    title: str
    file_path: str
    word_count: int
    code_blocks: int
    headers: int
    references: int
    has_introduction: bool
    has_core_principle: bool
    has_practice: bool
    has_summary: bool
    score: float
    grade: str
    issues: List[str]
    recommendations: List[str]
    needs_improvement: bool


class ContentQualityChecker:
    """å†…å®¹è´¨é‡æ£€æŸ¥å™¨"""

    # è´¨é‡æ ‡å‡†
    STANDARDS = {
        "min_word_count": 8000,
        "ideal_word_count": 12000,
        "min_code_blocks": 3,
        "ideal_code_blocks": 5,
        "min_headers": 8,
        "ideal_headers": 12,
        "min_references": 3,
        "ideal_references": 5,
        "passing_score": 80  # ç”¨æˆ·è®¾å®šçš„ä¼˜ç§€çº¿
    }

    # æƒé‡é…ç½®
    WEIGHTS = {
        "content_depth": 0.25,
        "code_quality": 0.20,
        "structure": 0.20,
        "completeness": 0.20,
        "references": 0.15
    }

    def __init__(self, base_path: str = "/Users/z/Documents/work/content-forge-ai/data/series/ML_series"):
        self.base_path = Path(base_path)

    def check_episode(self, episode: int, series_id: Optional[str] = None) -> Optional[QualityReport]:
        """
        æ£€æŸ¥æŒ‡å®šæœŸçš„æ–‡ç« è´¨é‡

        Args:
            episode: æœŸå· (1-100)
            series_id: ç³»åˆ—IDï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰

        Returns:
            QualityReport æˆ– Noneï¼ˆå¦‚æœæ–‡ç« ä¸å­˜åœ¨ï¼‰
        """
        # æŸ¥æ‰¾æ–‡ç« æ–‡ä»¶
        article_path = self._find_article(episode, series_id)
        if not article_path:
            return None

        # è¯»å–æ–‡ç« å†…å®¹
        with open(article_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–å…ƒæ•°æ®
        title = self._extract_title(content)
        detected_series = self._detect_series(article_path)

        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        word_count = len(content)
        code_blocks = len(re.findall(r'```[\s\S]*?```', content))
        headers = len(re.findall(r'^#{1,3}\s+.+$', content, re.MULTILINE))
        references = len(re.findall(r'\[.*?\]\(https?://', content))

        # æ£€æŸ¥å¿…è¦ç« èŠ‚ï¼ˆæ›´çµæ´»çš„åŒ¹é…ï¼‰
        has_introduction = bool(re.search(r'#+\s*(\d+\.?\s*)?(ç¬¬.*ç« .*å¼•è¨€|å¼•è¨€|ç®€ä»‹|èƒŒæ™¯|æ¦‚è¿°|å¯¼è¯»)', content))
        has_core_principle = bool(re.search(r'#+\s*(\d+\.?\s*)?(ç¬¬.*ç« .*åŸç†|ç¬¬.*ç« .*æ ¸å¿ƒ|åŸç†|æ ¸å¿ƒ|æ¶æ„|åŸºç¡€|æ¦‚å¿µ|æŠ€æœ¯æ¶æ„|æŠ€æœ¯åŸç†)', content))
        has_practice = bool(re.search(r'#+\s*(\d+\.?\s*)?(ç¬¬.*ç« .*å®è·µ|ç¬¬.*ç« .*å®ç°|ç¬¬.*ç« .*ä»£ç |å®è·µ|å®ç°|ä»£ç |åº”ç”¨|ç¤ºä¾‹|å®æˆ˜|ä»£ç ç¤ºä¾‹)', content))
        has_summary = bool(re.search(r'#+\s*(\d+\.?\s*)?(ç¬¬.*ç« .*æ€»ç»“|ç¬¬.*ç« .*ç»“è®º|æ€»ç»“|ç»“è®º|å±•æœ›|å°ç»“|ç»“è¯­)', content))

        # è®¡ç®—åˆ†æ•°
        score, issues = self._calculate_score(
            word_count, code_blocks, headers, references,
            has_introduction, has_core_principle, has_practice, has_summary
        )

        # ç”Ÿæˆç­‰çº§
        grade = self._get_grade(score)

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        recommendations = self._generate_recommendations(issues)

        return QualityReport(
            episode=episode,
            series_id=detected_series,
            title=title,
            file_path=str(article_path),
            word_count=word_count,
            code_blocks=code_blocks,
            headers=headers,
            references=references,
            has_introduction=has_introduction,
            has_core_principle=has_core_principle,
            has_practice=has_practice,
            has_summary=has_summary,
            score=score,
            grade=grade,
            issues=issues,
            recommendations=recommendations,
            needs_improvement=score < self.STANDARDS["passing_score"]
        )

    def _find_article(self, episode: int, series_id: Optional[str]) -> Optional[Path]:
        """æŸ¥æ‰¾æ–‡ç« æ–‡ä»¶"""
        ep_str = f"episode_{episode:03d}"

        # å¦‚æœæŒ‡å®šäº†series_idï¼Œç›´æ¥æŸ¥æ‰¾
        if series_id:
            series_path = self.base_path / series_id / ep_str
            if series_path.exists():
                articles = list(series_path.glob("*_article.md"))
                if articles:
                    return max(articles, key=lambda p: p.stat().st_size)

        # å¦åˆ™æœç´¢æ‰€æœ‰ç³»åˆ—
        for series_dir in sorted(self.base_path.iterdir()):
            if not series_dir.is_dir():
                continue
            ep_dir = series_dir / ep_str
            if ep_dir.exists():
                articles = list(ep_dir.glob("*_article.md"))
                if articles:
                    return max(articles, key=lambda p: p.stat().st_size)

        return None

    def _detect_series(self, article_path: Path) -> str:
        """ä»è·¯å¾„æ£€æµ‹ç³»åˆ—ID"""
        parts = article_path.parts
        for part in parts:
            if part.startswith("ml_series_"):
                return part
        return "unknown"

    def _extract_title(self, content: str) -> str:
        """æå–æ–‡ç« æ ‡é¢˜"""
        match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        return match.group(1) if match else "æœªå‘½åæ–‡ç« "

    def _calculate_score(
        self,
        word_count: int,
        code_blocks: int,
        headers: int,
        references: int,
        has_intro: bool,
        has_core: bool,
        has_practice: bool,
        has_summary: bool
    ) -> tuple:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        issues = []
        score = 0

        # 1. å†…å®¹æ·±åº¦ (25%)
        if word_count >= self.STANDARDS["ideal_word_count"]:
            depth_score = 25
        elif word_count >= self.STANDARDS["min_word_count"]:
            depth_score = 20
        else:
            depth_score = int(word_count / self.STANDARDS["min_word_count"] * 20)
            issues.append(f"âŒ å­—æ•°ä¸è¶³: {word_count:,}å­— (å»ºè®®{self.STANDARDS['min_word_count']:,}+)")
        score += depth_score

        # 2. ä»£ç è´¨é‡ (20%)
        if code_blocks >= self.STANDARDS["ideal_code_blocks"]:
            code_score = 20
        elif code_blocks >= self.STANDARDS["min_code_blocks"]:
            code_score = 15
        elif code_blocks > 0:
            code_score = 10
            issues.append(f"âš ï¸ ä»£ç ç¤ºä¾‹åå°‘: {code_blocks}ä¸ª (å»ºè®®{self.STANDARDS['ideal_code_blocks']}+)")
        else:
            code_score = 0
            issues.append(f"âŒ ç¼ºå°‘ä»£ç ç¤ºä¾‹")
        score += code_score

        # 3. ç»“æ„å®Œæ•´æ€§ (20%)
        if headers >= self.STANDARDS["ideal_headers"]:
            struct_score = 20
        elif headers >= self.STANDARDS["min_headers"]:
            struct_score = 15
        else:
            struct_score = int(headers / self.STANDARDS["min_headers"] * 15)
            issues.append(f"âŒ ç« èŠ‚ç»“æ„ä¸è¶³: {headers}ä¸ª (å»ºè®®{self.STANDARDS['ideal_headers']}+)")
        score += struct_score

        # 4. å®Œæ•´æ€§ (20%)
        completeness = sum([has_intro, has_core, has_practice, has_summary])
        complete_score = completeness * 5

        if not has_intro:
            issues.append("âŒ ç¼ºå°‘å¼•è¨€ç« èŠ‚")
        if not has_core:
            issues.append("âŒ ç¼ºå°‘æ ¸å¿ƒåŸç†ç« èŠ‚")
        if not has_practice:
            issues.append("âŒ ç¼ºå°‘å®è·µåº”ç”¨ç« èŠ‚")
        if not has_summary:
            issues.append("âŒ ç¼ºå°‘æ€»ç»“ç« èŠ‚")

        score += complete_score

        # 5. å¼•ç”¨æ¥æº (15%)
        if references >= self.STANDARDS["ideal_references"]:
            ref_score = 15
        elif references >= self.STANDARDS["min_references"]:
            ref_score = 10
        elif references > 0:
            ref_score = 5
            issues.append(f"âš ï¸ å¼•ç”¨æ¥æºåå°‘: {references}ä¸ª (å»ºè®®{self.STANDARDS['ideal_references']}+)")
        else:
            ref_score = 0
            issues.append(f"âŒ ç¼ºå°‘å¼•ç”¨æ¥æº")
        score += ref_score

        return score, issues

    def _get_grade(self, score: float) -> str:
        """è·å–ç­‰çº§"""
        if score >= 90:
            return "A+ (ä¼˜ç§€)"
        elif score >= 85:
            return "A (è‰¯å¥½)"
        elif score >= 80:
            return "B+ (è¾ƒå¥½)"
        elif score >= 75:
            return "B (è¾¾æ ‡)"
        elif score >= 70:
            return "C+ (åŠæ ¼)"
        elif score >= 60:
            return "C (å‹‰å¼º)"
        else:
            return "D (ä¸åŠæ ¼)"

    def _generate_recommendations(self, issues: List[str]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []

        for issue in issues:
            if "å­—æ•°ä¸è¶³" in issue:
                recommendations.append("ğŸ“ å¢åŠ å†…å®¹æ·±åº¦ï¼šè¡¥å……ç†è®ºè§£é‡Šã€æ¡ˆä¾‹åˆ†ææˆ–æ‰©å±•è®¨è®º")
            elif "ä»£ç ç¤ºä¾‹" in issue:
                recommendations.append("ğŸ’» æ·»åŠ ä»£ç ç¤ºä¾‹ï¼šå¢åŠ å¯è¿è¡Œçš„ä»£ç ç‰‡æ®µå’Œæ³¨é‡Šè¯´æ˜")
            elif "ç« èŠ‚ç»“æ„" in issue:
                recommendations.append("ğŸ“š å®Œå–„ç« èŠ‚ç»“æ„ï¼šå¢åŠ å­ç« èŠ‚ï¼Œç»†åŒ–å†…å®¹ç»„ç»‡")
            elif "å¼•è¨€" in issue:
                recommendations.append("ğŸ“– æ·»åŠ å¼•è¨€ï¼šè¯´æ˜èƒŒæ™¯ã€å­¦ä¹ ç›®æ ‡å’Œå‰ç½®çŸ¥è¯†")
            elif "æ ¸å¿ƒåŸç†" in issue:
                recommendations.append("ğŸ”¬ è¡¥å……æ ¸å¿ƒåŸç†ï¼šè¯¦ç»†è§£é‡Šç®—æ³•/æ¨¡å‹çš„å·¥ä½œæœºåˆ¶")
            elif "å®è·µåº”ç”¨" in issue:
                recommendations.append("ğŸ› ï¸ æ·»åŠ å®è·µåº”ç”¨ï¼šåŒ…å«ä»£ç ç¤ºä¾‹ã€ä½¿ç”¨åœºæ™¯å’Œæœ€ä½³å®è·µ")
            elif "æ€»ç»“" in issue:
                recommendations.append("ğŸ“‹ æ·»åŠ æ€»ç»“ï¼šå›é¡¾è¦ç‚¹ã€å±•æœ›æœªæ¥æ–¹å‘")
            elif "å¼•ç”¨æ¥æº" in issue:
                recommendations.append("ğŸ”— æ·»åŠ å¼•ç”¨ï¼šè¡¥å……è®ºæ–‡ã€å®˜æ–¹æ–‡æ¡£ç­‰æŠ€æœ¯å‚è€ƒé“¾æ¥")

        return recommendations

    def print_report(self, report: QualityReport):
        """æ‰“å°è´¨é‡æŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ç¬¬ {report.episode:03d} æœŸè´¨é‡æŠ¥å‘Š")
        print(f"{'='*60}")
        print(f"æ ‡é¢˜: {report.title}")
        print(f"ç³»åˆ—: {report.series_id}")
        print(f"æ–‡ä»¶: {report.file_path}")
        print(f"\nğŸ“ˆ åŸºç¡€æŒ‡æ ‡:")
        print(f"  â€¢ å­—æ•°: {report.word_count:,}")
        print(f"  â€¢ ä»£ç å—: {report.code_blocks}")
        print(f"  â€¢ ç« èŠ‚æ•°: {report.headers}")
        print(f"  â€¢ å¼•ç”¨æ•°: {report.references}")

        print(f"\nğŸ“‹ ç« èŠ‚å®Œæ•´æ€§:")
        print(f"  â€¢ å¼•è¨€: {'âœ…' if report.has_introduction else 'âŒ'}")
        print(f"  â€¢ æ ¸å¿ƒåŸç†: {'âœ…' if report.has_core_principle else 'âŒ'}")
        print(f"  â€¢ å®è·µåº”ç”¨: {'âœ…' if report.has_practice else 'âŒ'}")
        print(f"  â€¢ æ€»ç»“: {'âœ…' if report.has_summary else 'âŒ'}")

        print(f"\n{'='*60}")
        print(f"ğŸ¯ æ€»åˆ†: {report.score:.1f}/100 ({report.grade})")
        print(f"{'='*60}")

        if report.needs_improvement:
            print(f"\nâš ï¸  éœ€è¦æ”¹è¿› (ä½äº{self.STANDARDS['passing_score']}åˆ†)")
            print(f"\nâŒ å‘ç°çš„é—®é¢˜:")
            for issue in report.issues:
                print(f"  {issue}")
            print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
            for rec in report.recommendations:
                print(f"  {rec}")
        else:
            print(f"\nâœ… è´¨é‡è¾¾æ ‡ï¼")

        print(f"\n")


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ML Series å†…å®¹è´¨é‡æ£€æŸ¥")
    parser.add_argument("--episode", type=int, help="æ£€æŸ¥æŒ‡å®šæœŸå·")
    parser.add_argument("--start", type=int, default=1, help="èµ·å§‹æœŸå·")
    parser.add_argument("--end", type=int, default=100, help="ç»“æŸæœŸå·")
    parser.add_argument("--report-only", action="store_true", help="ä»…ç”ŸæˆæŠ¥å‘Šï¼Œä¸æç¤ºæ”¹è¿›")
    parser.add_argument("--json", type=str, help="è¾“å‡ºJSONæŠ¥å‘Šåˆ°æ–‡ä»¶")

    args = parser.parse_args()

    checker = ContentQualityChecker()

    if args.episode:
        # æ£€æŸ¥å•æœŸ
        report = checker.check_episode(args.episode)
        if report:
            checker.print_report(report)
        else:
            print(f"âŒ æœªæ‰¾åˆ°ç¬¬ {args.episode} æœŸçš„æ–‡ç« ")
    else:
        # æ£€æŸ¥èŒƒå›´
        reports = []
        needs_improvement = []

        for ep in range(args.start, args.end + 1):
            report = checker.check_episode(ep)
            if report:
                reports.append(report)
                if report.needs_improvement:
                    needs_improvement.append(report)

        # æ‰“å°æ‘˜è¦
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ML Series è´¨é‡æ£€æŸ¥æ‘˜è¦")
        print(f"{'='*60}")
        print(f"æ£€æŸ¥èŒƒå›´: ç¬¬{args.start}-{args.end}æœŸ")
        print(f"æ€»æ–‡ç« æ•°: {len(reports)}")
        print(f"è¾¾æ ‡æ–‡ç« : {len(reports) - len(needs_improvement)}")
        print(f"å¾…æ”¹è¿›: {len(needs_improvement)}")

        if needs_improvement:
            print(f"\nâš ï¸  ä»¥ä¸‹æ–‡ç« éœ€è¦æ”¹è¿›:")
            for r in needs_improvement:
                print(f"  â€¢ ç¬¬{r.episode:03d}æœŸ: {r.score:.1f}åˆ† - {r.title[:30]}...")

        # è¾“å‡ºJSONæŠ¥å‘Š
        if args.json:
            with open(args.json, 'w', encoding='utf-8') as f:
                json.dump([asdict(r) for r in reports], f, ensure_ascii=False, indent=2)
            print(f"\nğŸ“„ JSONæŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.json}")


if __name__ == "__main__":
    main()
